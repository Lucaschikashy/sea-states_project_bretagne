{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Wind turbine project\n",
    "\n",
    "This notebook is a brief example of the possibilities offered by the toolbox for modeling extreme values, adapted from the tools provided from the ResourceCode website.\n",
    "\n",
    "It relies on the `pyextreme` library which get installed with the Resourcecode toolbox. Here we demonstrate 2 examples of univariate modeling as shown in class. For more information, see https://georgebv.github.io/pyextremes/."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "# I. Wave Dynamics\n",
    "\n",
    "## I.A. Characterizing the study site mean wave conditions\n",
    "\n",
    "This notebook covers Part I.A of the wind turbine project: Characterizing the mean wave conditions and seasonal variability at the selected study site. The goal is to analyze long-term hindcast data to understand the typical and seasonal wave climate.\n",
    "\n",
    "---\n",
    "\n",
    "### Import Required Libraries\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.api.types import CategoricalDtype\n",
    "import matplotlib.pyplot as plt\n",
    "import pymannkendall as mk\n",
    "from scipy import stats\n",
    "from pathlib import Path\n",
    "from pyextremes import (\n",
    "    plot_mean_residual_life,\n",
    "    plot_parameter_stability, \n",
    "    EVA\n",
    ")\n",
    "import resourcecode\n",
    "from IPython import get_ipython\n",
    "\n",
    "from resourcecode.eva import (\n",
    "    get_fitted_models,\n",
    "    get_gpd_parameters,\n",
    ")\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "os.makedirs('fig', exist_ok=True)\n",
    "plt.savefig('fig/diagnostic_plot_bm.png', dpi=200, bbox_inches='tight')\n",
    "\n",
    "# Enable inline plotting for Jupyter notebooks\n",
    "get_ipython().run_line_magic(\"matplotlib\", \"inline\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "---\n",
    "### I.A.1. Mean Wave Conditions\n",
    "\n",
    "Please download the variables corresponding to the significant wave height, mean wave period (Tm02), and mean wave direction. Then plot the time series of these variables during the 26-year period from 1994 to 2020, and calculate the mean significant wave height, period, and direction over the entire available time series."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "### Chosen Study Site\n",
    "\n",
    "**Site:** Bretagne Sud 1\n",
    "**Coordinates:** $(47.3236111, -3.5522222)$. These were obtained by downloading the implementation zone KML file from https://www.eoliennesenmer.fr/facades-maritimes-en-france/facade-nord-atlantique-manche-ouest/projet-en-bretagne-sud/bretagne-sud-1 . We then went on Google Earth, picked a point at the centre of the implementation zone, and used those coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = resourcecode.Client()\n",
    "# load the resourcecode dataset from Bretagne Sud 1\n",
    "# find the closest point to the coordinates\n",
    "lat = 47.3236111\n",
    "long = -3.5522222\n",
    "point_id, dist_m = resourcecode.data.get_closest_point(latitude=lat, longitude=long)\n",
    "print(point_id, dist_m)\n",
    "\n",
    "# get the data from the closest point\n",
    "data = client.get_dataframe_from_criteria(\n",
    "    \"\"\"\n",
    "{\n",
    "    \"node\": 117231,\n",
    "    \"start\": 0,\n",
    "    \"end\": 99999903600,\n",
    "    \"parameter\": [\"hs\",\"t02\",\"dir\",\"uwnd\",\"vwnd\",\"ucur\",\"vcur\",\"dpt\"]\n",
    "}\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "### Data Source\n",
    "\n",
    "The analysis will use long-term (1994-2020) hindcast simulations from the **ResourceCode wave database**.\n",
    "\n",
    "**Variables to download**:\n",
    "* Significant wave height ($H_{m0}$)\n",
    "* Mean wave period ($T_{m02}$)\n",
    "* Mean wave direction\n",
    "* Wind velocity\n",
    "* Current velocity\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Derive only what ResourceCode does not already provide\n",
    "# Assumes your download included: hs, t02, dir, uwnd, vwnd (and optionally ucur, vcur, dpt)\n",
    "\n",
    "# Wind: speed (m/s) and coming-from direction (deg)\n",
    "data[\"wspd\"], data[\"wdir\"] = resourcecode.utils.zmcomp2metconv(data[\"uwnd\"], data[\"vwnd\"])\n",
    "\n",
    "# Currents (optional)\n",
    "if {\"ucur\", \"vcur\"}.issubset(data.columns):\n",
    "    data[\"cspd\"], data[\"cdir\"] = resourcecode.utils.zmcomp2metconv(data[\"ucur\"], data[\"vcur\"])\n",
    "\n",
    "# Waves: use provided mean zero-crossing period\n",
    "if \"t02\" in data.columns:\n",
    "    data[\"Tm02\"] = data[\"t02\"]\n",
    "else:\n",
    "    raise KeyError(\"Missing 't02' in the request. Add 't02' to parameter list.\")\n",
    "\n",
    "# Keep dataset wave direction as-is; document convention once in the notebook.\n",
    "# Do NOT overwrite 'dir' or try to recompute Tm02 from hs/dir.\n",
    "\n",
    "data = data.sort_index()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "### Variables: definitions and units\n",
    "\n",
    "**Core met-ocean time series**\n",
    "\n",
    "| name   | meaning                                   | units |\n",
    "|--------|-------------------------------------------|-------|\n",
    "| `hs`   | significant wave height $H_{m0}=4\\sqrt{m_0}$ | m     |\n",
    "| `t02`  | mean zero-crossing period $T_{m02}=2\\pi\\sqrt{m_0/m_2}$ | s     |\n",
    "| `dir`  | mean wave direction                       | °     |\n",
    "| `spr`  | directional spreading                     | °     |\n",
    "| `fp`   | spectral peak frequency                   | Hz    |\n",
    "| `Tp`   | peak period $=1/fp$                     | s     |\n",
    "| `uwnd` | eastward wind component                   | m·s⁻¹ |\n",
    "| `vwnd` | northward wind component                  | m·s⁻¹ |\n",
    "| `wspd` | wind speed $\\sqrt{uwnd^2+vwnd^2}$       | m·s⁻¹ |\n",
    "| `wdir` | wind direction                            | °     |\n",
    "| `ucur` | eastward surface current                  | m·s⁻¹ |\n",
    "| `vcur` | northward surface current                 | m·s⁻¹ |\n",
    "| `cspd` | current speed $\\sqrt{ucur^2+vcur^2}$    | m·s⁻¹ |\n",
    "| `cdir` | current direction                         | °     |\n",
    "| `dpt`  | water depth                               | m     |\n",
    "\n",
    "**Spectral moments**\n",
    "\n",
    "| name | meaning                               | units  |\n",
    "|------|----------------------------------------|--------|\n",
    "| `m0` | zeroth moment $\\int S(\\omega)\\,d\\omega$ | m²     |\n",
    "| `m1` | first moment $\\int \\omega S(\\omega)\\,d\\omega$ | m²·s⁻¹ |\n",
    "| `m2` | second moment $\\int \\omega^2 S(\\omega)\\,d\\omega$ | m²·s⁻² |\n",
    "\n",
    "**Extreme value analysis (pyextremes)**\n",
    "\n",
    "| item     | meaning                                  |\n",
    "|----------|------------------------------------------|\n",
    "| BM       | block-maxima extraction                  |\n",
    "| POT      | peaks-over-threshold with declustering   |\n",
    "| GEV $\\mu,\\sigma,\\xi$ | location, scale, shape for BM     |\n",
    "| GPD $\\sigma,\\xi$     | scale, shape for POT at a threshold |\n",
    "| `r`      | min time separation between clusters     |\n",
    "| `alpha`  | confidence level for intervals           |\n",
    "| $z_T$  | return level for period $T$ years      |\n",
    "\n",
    "**Direction conventions**\n",
    "\n",
    "All directions are expressed **clockwise from North**.\n",
    "\n",
    "| Variable | Convention | Notes |\n",
    "|-----------|-------------|-------|\n",
    "| `wdir` | *coming-from* | Derived from (`uwnd`, `vwnd`) using `resourcecode.utils.zmcomp2metconv`. |\n",
    "| `dir_from` | *coming-from* | Use if dataset `dir` is *going-to*: convert by `dir_from = (dir + 180) % 360`. |\n",
    "| `cdir_to` | *going-to* | Derived from (`ucur`, `vcur`); use as-is for current flow direction. |\n",
    "| `cdir_from` | *coming-from* (optional) | For comparison with wave/wind directions, compute `cdir_from = (cdir_to + 180) % 360`. |\n",
    "\n",
    "> Always state the convention in figure captions and keep it consistent across the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IA.1 — Mean wave conditions (1994–2020): time series, means, linear trends\n",
    "\n",
    "def circmean_deg(x_deg):\n",
    "    \"\"\"Circular mean of degrees in [0, 360).\"\"\"\n",
    "    x = pd.Series(x_deg).dropna().values\n",
    "    if x.size == 0:\n",
    "        return np.nan\n",
    "    r = np.deg2rad(x)\n",
    "    s = np.sin(r).sum()\n",
    "    c = np.cos(r).sum()\n",
    "    return (np.degrees(np.arctan2(s, c)) + 360.0) % 360.0\n",
    "\n",
    "def verdict(p):\n",
    "    return \"significant\" if p < 0.05 else \"not significant\"\n",
    "\n",
    "# helper\n",
    "def wrap360(a):\n",
    "    return (a % 360.0 + 360.0) % 360.0\n",
    "\n",
    "# Select analysis window\n",
    "start = pd.Timestamp(\"1994-01-01\")\n",
    "end   = pd.Timestamp(\"2020-12-31 23:59:59\")\n",
    "needed = [\"hs\", \"Tm02\", \"dir\"]\n",
    "missing = [v for v in needed if v not in data.columns]\n",
    "if missing:\n",
    "    raise KeyError(f\"Missing variables for IA.1: {missing}\")\n",
    "\n",
    "df = data.loc[start:end, needed].copy()\n",
    "\n",
    "# Monthly means (direction handled circularly)\n",
    "monthly = pd.DataFrame({\n",
    "    \"hs\":   df[\"hs\"].resample(\"M\").mean(),\n",
    "    \"Tm02\": df[\"Tm02\"].resample(\"M\").mean(),\n",
    "})\n",
    "monthly[\"dir\"] = df[\"dir\"].resample(\"M\").apply(circmean_deg)\n",
    "\n",
    "# Overall means (direction: circular mean)\n",
    "mean_hs   = df[\"hs\"].mean()\n",
    "mean_tm02 = df[\"Tm02\"].mean()\n",
    "mean_dir  = circmean_deg(df[\"dir\"])\n",
    "\n",
    "# Linear trends on monthly means\n",
    "t_years = (monthly.index - monthly.index[0]).days / 365.2425\n",
    "\n",
    "# Hs trend\n",
    "hs_ok = monthly[\"hs\"].dropna()\n",
    "t_hs = t_years[hs_ok.index.get_indexer(hs_ok.index)]\n",
    "hs_reg = stats.linregress(t_hs, hs_ok.values)\n",
    "hs_slope_dec = hs_reg.slope * 10.0      # m per decade\n",
    "hs_delta_30  = hs_reg.slope * 30.0      # m over 30 years\n",
    "\n",
    "# Tm02 trend\n",
    "tm_ok = monthly[\"Tm02\"].dropna()\n",
    "t_tm = t_years[tm_ok.index.get_indexer(tm_ok.index)]\n",
    "tm_reg = stats.linregress(t_tm, tm_ok.values)\n",
    "tm_slope_dec = tm_reg.slope * 10.0      # s per decade\n",
    "tm_delta_30  = tm_reg.slope * 30.0      # s over 30 years\n",
    "\n",
    "# Direction trend: unwrap, regress, report slope in deg/dec\n",
    "dir_ok = monthly[\"dir\"].dropna()\n",
    "t_dir = t_years[dir_ok.index.get_indexer(dir_ok.index)]\n",
    "dir_unwrap = np.degrees(np.unwrap(np.deg2rad(dir_ok.values)))\n",
    "dir_reg = stats.linregress(t_dir, dir_unwrap)\n",
    "dir_slope_dec = dir_reg.slope * 10.0    # deg per decade\n",
    "dir_delta_30  = dir_reg.slope * 30.0    # deg over 30 years\n",
    "\n",
    "# Plot monthly series (1994–2020)\n",
    "fig, axes = plt.subplots(3, 1, figsize=(12, 9), sharex=True)\n",
    "\n",
    "# Hs with fitted line\n",
    "axes[0].plot(monthly.index, monthly[\"hs\"], lw=0.8)\n",
    "yhat_hs = hs_reg.intercept + hs_reg.slope * t_years\n",
    "axes[0].plot(monthly.index, yhat_hs, lw=1.2)\n",
    "axes[0].set_ylabel(\"Hs (m)\")\n",
    "axes[0].grid(alpha=0.3)\n",
    "axes[0].set_title(f\"Hs monthly mean | {hs_slope_dec:.3f} m/dec, p={hs_reg.pvalue:.3f} ({verdict(hs_reg.pvalue)})\")\n",
    "\n",
    "# Tm02 with fitted line\n",
    "axes[1].plot(monthly.index, monthly[\"Tm02\"], lw=0.8)\n",
    "yhat_tm = tm_reg.intercept + tm_reg.slope * t_years\n",
    "axes[1].plot(monthly.index, yhat_tm, lw=1.2)\n",
    "axes[1].set_ylabel(\"Tm02 (s)\")\n",
    "axes[1].grid(alpha=0.3)\n",
    "axes[1].set_title(f\"Tm02 monthly mean | {tm_slope_dec:.3f} s/dec, p={tm_reg.pvalue:.3f} ({verdict(tm_reg.pvalue)})\")\n",
    "\n",
    "# Direction (circular monthly mean) with fitted line\n",
    "axes[2].plot(monthly.index, monthly[\"dir\"], lw=0.8)\n",
    "yhat_dir_unwrap = dir_reg.intercept + dir_reg.slope * t_years\n",
    "yhat_dir = wrap360(yhat_dir_unwrap)\n",
    "axes[2].plot(monthly.index, yhat_dir, lw=1.2)  # add fit\n",
    "axes[2].set_ylabel(\"Dir (deg, coming-from)\")\n",
    "axes[2].grid(alpha=0.3)\n",
    "axes[2].set_title(\n",
    "    f\"Direction monthly circular mean | {dir_slope_dec:.2f}°/dec, \"\n",
    "    f\"p={dir_reg.pvalue:.3f} ({verdict(dir_reg.pvalue)})\"\n",
    ")\n",
    "axes[2].set_xlabel(\"Year\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"fig/IA1_mean_wave_conditions_timeseries.png\", dpi=200, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "# Printed summary for the report\n",
    "print(\"IA.1 — Mean conditions over 1994–2020\")\n",
    "print(f\"  Mean Hs   : {mean_hs:.3f} m\")\n",
    "print(f\"  Mean Tm02 : {mean_tm02:.3f} s\")\n",
    "print(f\"  Mean Dir  : {mean_dir:.1f}° (coming-from)\")\n",
    "\n",
    "print(\"\\nLinear trends on monthly means (least squares):\")\n",
    "print(f\"  Hs   : {hs_slope_dec:.3f} m/dec  (p={hs_reg.pvalue:.3f}, n={hs_ok.size}), Δ30y={hs_delta_30:.3f} m\")\n",
    "print(f\"  Tm02 : {tm_slope_dec:.3f} s/dec  (p={tm_reg.pvalue:.3f}, n={tm_ok.size}), Δ30y={tm_delta_30:.3f} s\")\n",
    "print(f\"  Dir  : {dir_slope_dec:.2f} °/dec (p={dir_reg.pvalue:.3f}, n={dir_ok.size}), Δ30y={dir_delta_30:.2f} °\")\n",
    "\n",
    "print(\"\\nInterpretation rule-of-thumb: treat p<0.05 as evidence of a trend. Use Δ30y to state expected change over a turbine lifetime.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_hs  = mk.original_test(hs_ok.values, alpha=0.05)\n",
    "result_period = mk.original_test(tm_ok.values, alpha=0.050)\n",
    "result_direction = mk.original_test(dir_ok.values, alpha=0.05)\n",
    "\n",
    "print(\"\\nResults for Significant Wave Height (Hs):\")\n",
    "print(f\"  Trend: {result_hs.trend}\")\n",
    "print(f\"  H (Test Statistic): {result_hs.h}\")\n",
    "print(f\"  P-value: {result_hs.p:.4f}\")\n",
    "print(f\"  Z-Score: {result_hs.z:.4f}\")\n",
    "print(f\"  Tau: {result_hs.Tau:.4f}\")\n",
    "print(f\"  Sen's Slope: {result_hs.slope:.4f}\")\n",
    "print(f\"  Intercept: {result_hs.intercept:.4f}\")\n",
    "\n",
    "print(\"\\nResults for Wave Period (Tm02):\")\n",
    "print(f\"  Trend: {result_period.trend}\")\n",
    "print(f\"  H (Test Statistic): {result_period.h}\")\n",
    "print(f\"  P-value: {result_period.p:.4f}\")\n",
    "print(f\"  Z-Score: {result_period.z:.4f}\")\n",
    "print(f\"  Tau: {result_period.Tau:.4f}\")\n",
    "print(f\"  Sen's Slope: {result_period.slope:.4f}\")\n",
    "print(f\"  Intercept: {result_period.intercept:.4f}\")\n",
    "\n",
    "print(\"\\nResults for Wave Direction:\")\n",
    "print(f\"  Trend: {result_direction.trend}\")\n",
    "print(f\"  H (Test Statistic): {result_direction.h}\")\n",
    "print(f\"  P-value: {result_direction.p:.4f}\")\n",
    "print(f\"  Z-Score: {result_direction.z:.4f}\")\n",
    "print(f\"  Tau: {result_direction.Tau:.4f}\")\n",
    "print(f\"  Sen's Slope: {result_direction.slope:.4f}\")\n",
    "print(f\"  Intercept: {result_direction.intercept:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "**Q: Do any trends in the wave height, period, or direction exist over the 26 year time period? Do you expect there to be changes in the mean conditions during the 30-year lifetime of the wind turbine? If so, why?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "**Answer:** No statistically significant trends were detected in wave height ($H_s$), period ($T_{m02}$), or direction using either Ordinary Least Squares (OLS) or the Mann-Kendall (MK) test on monthly mean data. Expected 30-year changes in mean conditions remain negligible relative to natural variability.\n",
    "\n",
    "---\n",
    "### Mean Conditions and Trend Analysis (1994-2020)\n",
    "\n",
    "**Mean conditions**\n",
    "-   $\\overline{H_s} = 2.092\\ \\text{m}$\n",
    "-   $\\overline{T_{m02}} = 5.785\\ \\text{s}$\n",
    "-   Mean direction $= 275.5^\\circ$ (coming from W)\n",
    "\n",
    "---\n",
    "**Trend Analysis Methods**\n",
    "-   Aggregate hourly data to monthly means to reduce noise while retaining seasonal information influence.\n",
    "-   **Method 1: Ordinary Least Squares (OLS)**: Perform regression vs time in years. Direction handled with circular monthly mean, then unwrapped.\n",
    "-   **Method 2: Mann-Kendall (MK) Test**: Apply the non-parametric test to detect monotonic trends in the monthly mean time series.\n",
    "-   Significance for both methods assessed at $\\alpha=0.05$.\n",
    "\n",
    "---\n",
    "**OLS Results** (slope per decade; $\\Delta 30\\text{y}$ is implied 30-year change; $n=324$ monthly means)\n",
    "-   $H_s$: $+0.015\\ \\text{m/dec}$, $p=0.776$, $\\Delta 30\\text{y}\\approx +0.046\\ \\text{m}$. (No significant trend)\n",
    "-   $T_{m02}$: $+0.086\\ \\text{s/dec}$, $p=0.150$, $\\Delta 30\\text{y}\\approx +0.259\\ \\text{s}$. (No significant trend)\n",
    "-   Direction: $+0.75^\\circ/\\text{dec}$, $p=0.349$, $\\Delta 30\\text{y}\\approx +2.26^\\circ$. (No significant trend)\n",
    "\n",
    "---\n",
    "**MK Results (on monthly means)**\n",
    "-   $H_s$: $p=0.8098$ (no significant trend); Sen's slope $\\approx +1.0\\times10^{-4}$ m/month ($\\approx +0.012$ m/decade).\n",
    "-   $T_{m02}$: $p=0.1957$ (no significant trend); Sen's slope $\\approx +7.0\\times10^{-4}$ s/month ($\\approx +0.084$ s/decade).\n",
    "-   Direction: $p=0.4405$ (no significant trend); Sen's slope $\\approx +5.5\\times10^{-3}$ deg/month ($\\approx +0.66^\\circ$/decade).\n",
    "\n",
    "*(Note: Sen's slopes converted approximately from per-month to per-decade for comparison with OLS results)*\n",
    "\n",
    "---\n",
    "**Interpretation**\n",
    "-   Both OLS and Mann-Kendall analyses performed on monthly mean data consistently indicate no statistically significant secular trends in mean $H_s$, $T_{m02}$, or direction over the 1994-2020 period.\n",
    "-   The magnitudes of the calculated slopes (both OLS and Sen's slope) are very small, suggesting that any potential underlying linear or monotonic change over the 26 years is minimal compared to the observed variability.\n",
    "-   Expected 30-year changes based on these negligible trends are small compared to the substantial seasonal and interannual variability present in the data.\n",
    "-   For design purposes over the next 30 years, emphasis should likely remain on characterizing the existing variability (seasonal, interannual) and extreme conditions rather than adjusting significantly for potential drifts in mean conditions.\n",
    "\n",
    "---\n",
    "*Figure:* `fig/IA1_mean_wave_conditions_timeseries.png`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "### I.A.2. Most Common Wave Conditions\n",
    "\n",
    "To identify the most common operating conditions, we will create a 2D histogram (scatter diagram) of significant wave height ($H_{m0}$) versus mean wave period ($T_{m02}$). We will also plot a wave rose to identify the most common wave incidence direction(s).\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "plt.hist2d(data['hs'], data['t02'], bins=100, cmap='plasma', density=True)\n",
    "plt.colorbar(label='Density')\n",
    "plt.xlabel('Significant Wave Height $H_s$ [m]')\n",
    "plt.ylabel('Mean Wave Period $T_{m02}$ [s]')\n",
    "plt.title('Wave Height vs Period Density Plot')\n",
    "plt.savefig('graphs/wave_height_period_density.png')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "**Q: What is the water depth at this location? Indicate on the histrogram for what wave conditions the waves are considered deep water waves? linear waves?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data['dpt'].std())\n",
    "\n",
    "mean_water_depth = data['dpt'].mean()\n",
    "print(f'mean water depth at location (lat, long) = ({lat}, {long}) is {mean_water_depth:.2f} m')\n",
    "\n",
    "# Calculating wave length using the linear wave theory\n",
    "# wave length = g * T^2 / (2 * pi)\n",
    "g = 9.81 # m/s^2\n",
    "wave_length = g * (data['t02']**2) / (2 * np.pi)\n",
    "water_depth = data['dpt']\n",
    "\n",
    "# check condition for deep water waves\n",
    "deep_water_length_condition = 2 * mean_water_depth\n",
    "transition_water_length_condition = 25 * mean_water_depth\n",
    "\n",
    "deep_water_condition = wave_length < deep_water_length_condition\n",
    "# calculate the percentage of deep water waves\n",
    "deep_water_percentage = deep_water_condition.mean()\n",
    "print(f'percentage of deep water waves: {deep_water_percentage:.2%}')\n",
    "\n",
    "# Compute corresponding period for deep water waves\n",
    "deep_water_period_condition = 4 * np.sqrt(mean_water_depth / g)\n",
    "transition_water_period_condition = 25 * np.sqrt(mean_water_depth / g)\n",
    "\n",
    "print(f'deep water period: {deep_water_period_condition:.2f} s')\n",
    "# check condition for linear waves\n",
    "#linear_waves_condition = wave_length > 20 * mean_water_depth\n",
    "\n",
    "### plot the wave length distribution ###\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Corrected plt.hist call: remove wave_length.count\n",
    "plt.hist(wave_length, bins=50, density=True, alpha=0.7, label='Wave Length Distribution')\n",
    "\n",
    "# Add the threshold line (assuming L < 2h for deep water)\n",
    "plt.axvline(x=deep_water_length_condition, color='r', linestyle='--',\n",
    "            label=f'Deep Water Threshold (L < {deep_water_length_condition:.1f}m)')\n",
    "plt.axvline(x=transition_water_length_condition, color='g', linestyle='--',\n",
    "            label=f'Upper Transition Threshold to Linear Waves (L < {transition_water_length_condition:.1f}m)')\n",
    "plt.xlabel('Wave Length (m)')\n",
    "plt.ylabel('Density') # Changed label to Density since density=True\n",
    "plt.title('Wave Length Distribution')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "plt.close() # Close after showing\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "### plot the wave period distribution ###\n",
    "plt.hist(data['t02'], bins=50, density=True, alpha=0.7, label='Wave Period Distribution')\n",
    "\n",
    "# Add the threshold line (assuming L < 2h for deep water)\n",
    "plt.axvline(x=deep_water_period_condition, color='r', linestyle='--',\n",
    "            label=f'Deep Water Threshold (T < {deep_water_period_condition:.1f}s)')\n",
    "plt.axvline(x=transition_water_period_condition, color='g', linestyle='--',\n",
    "            label=f'Transition to Linear Waves (T < {transition_water_period_condition:.1f}s)')\n",
    "plt.xlabel('Wave Period (s)')\n",
    "plt.xscale('log')\n",
    "plt.ylabel('Density') # Changed label to Density since density=True\n",
    "plt.title('Wave Period Distribution')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# --- 6. Result Summary ---\n",
    "print(\"\\n--- Result Summary ---\")\n",
    "print(f\"Analysis based on Mean Depth h = {mean_water_depth:.2f} m\")\n",
    "\n",
    "print(\"\\nThresholds:\")\n",
    "print(f\"  Deep Water:     L < {deep_water_length_condition:.1f} m   |   T < {deep_water_period_condition:.2f} s\")\n",
    "print(f\"  Intersection of Deep and Shallow Water:  L > {transition_water_length_condition:.1f} m  |   T > {transition_water_period_condition:.2f} s\")\n",
    "\n",
    "# Compute the percentage of deep water waves based on the approximate wavelength\n",
    "is_deep_water_wave = wave_length < deep_water_length_condition\n",
    "is_transition_zone_wave = (\n",
    "    (deep_water_length_condition < wave_length) &\n",
    "    (wave_length < transition_water_length_condition)\n",
    ")\n",
    "\n",
    "is_deep_water_period = data['t02'] < deep_water_period_condition\n",
    "is_transition_zone_period = (\n",
    "    (deep_water_period_condition < data['t02']) &\n",
    "    (data['t02'] < transition_water_period_condition)\n",
    ")\n",
    "# get a percentage of the boolean series of true and false\n",
    "deep_water_percentage_L_approx = is_deep_water_wave.mean()\n",
    "transition_percentage_L_approx = is_transition_zone_wave.mean()\n",
    "deep_water_percentage_T_approx = is_deep_water_period.mean()\n",
    "transition_percentage_T_approx = is_transition_zone_period.mean()\n",
    "\n",
    "print(\"\\nClassification based on Approximate Wavelength (L_approx = gT² / 2π):\")\n",
    "print(f\"  Percentage Deep Water Wave Lenghts: {deep_water_percentage_L_approx:.2%}\")\n",
    "print(f\"  Percentage Transition Zone Wave Lenghts: {transition_percentage_L_approx:.2%}\")\n",
    "\n",
    "# Characterizing the transition band for T\n",
    "print(\"\\nClassification based on Approximate Wavelength (L_approx = gT² / 2π):\")\n",
    "print(f\"  Percentage Deep Water Wave Periods: {deep_water_percentage_T_approx:.2%}\")\n",
    "print(f\"  Percentage Transition Zone Wave Periods: {transition_percentage_T_approx:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "### Wave Regime Classification\n",
    "\n",
    "**Method**\n",
    "-   The wave conditions represented by the hourly significant wave height ($H_s$) and mean period ($T_{m02}$) were classified into deep, transitional, and shallow water regimes.\n",
    "-   Classification was based on standard non-dimensional criteria involving water depth ($h$), wavelength ($L$), and period ($T$).\n",
    "-   A **mean water depth of $h = 31.50$ m** was used for calculating the thresholds. This simplification is justified by the low standard deviation observed in the depth data ($\\sigma_h = 1.2$ m), indicating relatively consistent depth at the site.\n",
    "-   Wavelength ($L_{approx}$) was estimated using the deep water approximation $L_{approx} = gT_{m02}^2 / (2\\pi)$ for initial classification.\n",
    "-   Classification was also performed directly using the period $T_{m02}$.\n",
    "\n",
    "---\n",
    "**Thresholds** (based on $h = 31.50$ m)\n",
    "-   **Deep Water:** $h/L > 1/2 \\implies L < 63.0$ m; or $T\\sqrt{g/h} < 4 \\implies T < 7.17$ s.\n",
    "-   **Shallow Water:** $h/L < 1/25 \\implies L > 787.6$ m; or $T\\sqrt{g/h} > 25 \\implies T > 44.80$ s.\n",
    "-   **Transition Zone:** Conditions falling between the deep and shallow water limits.\n",
    "\n",
    "---\n",
    "**Results**\n",
    "-   Using the **period-based classification ($T_{m02}$)**:\n",
    "    -   Deep Water ($T < 7.17$ s): **93.71%**\n",
    "    -   Transition Zone ($7.17 \\text{ s} \\le T \\le 44.81$ s): **6.29%**\n",
    "    -   Shallow Water ($T > 44.81$ s): **0.00%**\n",
    "-   Using the **approximate wavelength classification ($L_{approx}$)**:\n",
    "    -   Deep Water ($L_{approx} < 63.0$ m): **86.70%**\n",
    "    -   Transition Zone ($63.0 \\text{ m} \\le L_{approx} \\le 630.0$ m): **13.30%**\n",
    "    -   Shallow Water ($L_{approx} > 630.0$ m): **0.00%**\n",
    "\n",
    "---\n",
    "**Interpretation**\n",
    "-   The vast majority of wave conditions at this site fall within the **deep water regime** based on both period and approximate wavelength classifications, although the period-based method indicates a higher percentage.\n",
    "-   A smaller fraction (6-13%) operates within the **transition zone**.\n",
    "-   **Shallow water conditions are negligible** according to these criteria and the dataset.\n",
    "-   The difference between the period and approximate wavelength classifications highlights the limitation of using the deep water formula ($L_{approx}$) for all conditions; the period-based classification using $T\\sqrt{g/h}$ is more direct."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "### I.A.3. Seasonal Variability\n",
    "\n",
    "Next, we will evaluate temporal variability by calculating and plotting the mean wave height, period, and direction as a function of the month of the year (e.g., mean for January, February, etc.).\n",
    "\n",
    "**Data and method.** Hourly hindcast at coordinates. Monthly climatology across all years.  \n",
    "- Height and period: arithmetic mean with interquartile range (IQR).  \n",
    "- Direction: circular mean with circular standard deviation, expressed as *coming-from* degrees.  \n",
    "- Angles unwrapped around the overall mean for continuity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- IA.3 Seasonal variability: monthly climatology of Hs, Tm02, and direction (mean ± IQR) ---\n",
    "\n",
    "# inputs\n",
    "need  = {\"hs\", \"Tm02\", \"dir\"}\n",
    "if not need.issubset(data.columns):\n",
    "    raise KeyError(f\"IA.3 needs columns {sorted(need)} in `data`.\")\n",
    "\n",
    "df3 = data.loc[start:end, [\"hs\", \"Tm02\", \"dir\"]].copy()\n",
    "if not isinstance(df3.index, pd.DatetimeIndex):\n",
    "    raise TypeError(\"`data` index must be a DatetimeIndex.\")\n",
    "\n",
    "# group by calendar month across all years\n",
    "g = df3.groupby(df3.index.month)  # 1..12\n",
    "\n",
    "# numeric climatology for Hs and Tm02\n",
    "hs_mean = g[\"hs\"].mean()\n",
    "hs_q25  = g[\"hs\"].quantile(0.25)\n",
    "hs_q75  = g[\"hs\"].quantile(0.75)\n",
    "\n",
    "tm_mean = g[\"Tm02\"].mean()\n",
    "tm_q25  = g[\"Tm02\"].quantile(0.25)\n",
    "tm_q75  = g[\"Tm02\"].quantile(0.75)\n",
    "\n",
    "n_samples = g.size()\n",
    "\n",
    "# circular climatology for direction (vectorised; stable across pandas versions)\n",
    "dd = df3[[\"dir\"]].copy()\n",
    "m = dd[\"dir\"].notna()\n",
    "dd.loc[m, \"sin\"] = np.sin(np.deg2rad(dd.loc[m, \"dir\"]))\n",
    "dd.loc[m, \"cos\"] = np.cos(np.deg2rad(dd.loc[m, \"dir\"]))\n",
    "\n",
    "dg = dd.groupby(dd.index.month)\n",
    "sin_mean = dg[\"sin\"].mean()\n",
    "cos_mean = dg[\"cos\"].mean()\n",
    "n_dir    = dg[\"dir\"].count()\n",
    "\n",
    "R = np.hypot(sin_mean, cos_mean)                                  # mean resultant length\n",
    "dir_mean = (np.degrees(np.arctan2(sin_mean, cos_mean)) + 360) % 360\n",
    "dir_cstd = np.degrees(np.sqrt(np.maximum(0.0, -2.0 * np.log(np.clip(R, 1e-12, 1.0)))))  # circular std (deg)\n",
    "\n",
    "# unwrap monthly direction around overall circular mean to avoid 0/360 jump\n",
    "sin_all = np.sin(np.deg2rad(df3[\"dir\"].dropna())).mean()\n",
    "cos_all = np.cos(np.deg2rad(df3[\"dir\"].dropna())).mean()\n",
    "overall_dir = (np.degrees(np.arctan2(sin_all, cos_all)) + 360) % 360\n",
    "dir_mean_unwrapped = overall_dir + ((dir_mean - overall_dir + 540.0) % 360.0 - 180.0)\n",
    "\n",
    "# assemble single DataFrame and ensure months 1..12 exist and in order\n",
    "clim = pd.DataFrame({\n",
    "    \"hs_mean\": hs_mean,\n",
    "    \"hs_q25\":  hs_q25,\n",
    "    \"hs_q75\":  hs_q75,\n",
    "    \"Tm02_mean\": tm_mean,\n",
    "    \"Tm02_q25\":  tm_q25,\n",
    "    \"Tm02_q75\":  tm_q75,\n",
    "    \"N_samples\": n_samples,\n",
    "    \"dir_mean\": dir_mean,\n",
    "    \"R\": R,\n",
    "    \"dir_cstd\": dir_cstd,\n",
    "    \"n_dir\": n_dir,\n",
    "    \"dir_mean_unwrapped\": dir_mean_unwrapped,\n",
    "}).reindex(range(1, 13))\n",
    "clim.index.name = \"month\"\n",
    "clim[\"month_name\"] = pd.to_datetime(clim.index, format=\"%m\").month_name().str.slice(0, 3)\n",
    "\n",
    "# save numeric table\n",
    "clim.to_csv(\"fig/IA3_seasonal_climatology.csv\", float_format=\"%.3f\")\n",
    "\n",
    "# plot\n",
    "fig, axes = plt.subplots(3, 1, figsize=(12, 9), sharex=True)\n",
    "x = np.arange(1, 13)\n",
    "labels = clim[\"month_name\"].values\n",
    "\n",
    "# Hs: mean ± IQR\n",
    "ax = axes[0]\n",
    "ax.plot(x, clim[\"hs_mean\"].values, lw=1.8)\n",
    "ax.fill_between(x, clim[\"hs_q25\"].values, clim[\"hs_q75\"].values, alpha=0.25)\n",
    "ax.set_ylabel(\"Hs (m)\")\n",
    "ax.grid(alpha=0.3)\n",
    "ax.set_title(\"Monthly climatology: Hs (mean ± IQR)\")\n",
    "\n",
    "# Tm02: mean ± IQR\n",
    "ax = axes[1]\n",
    "ax.plot(x, clim[\"Tm02_mean\"].values, lw=1.8)\n",
    "ax.fill_between(x, clim[\"Tm02_q25\"].values, clim[\"Tm02_q75\"].values, alpha=0.25)\n",
    "ax.set_ylabel(\"Tm02 (s)\")\n",
    "ax.grid(alpha=0.3)\n",
    "ax.set_title(\"Monthly climatology: Tm02 (mean ± IQR)\")\n",
    "\n",
    "# Direction: circular mean ± circular std (unwrapped for continuity)\n",
    "ax = axes[2]\n",
    "y = clim[\"dir_mean_unwrapped\"].values\n",
    "yerr = clim[\"dir_cstd\"].values\n",
    "ax.errorbar(x, y, yerr=yerr, fmt=\"-o\", lw=1.5, capsize=3)\n",
    "pad = 5.0\n",
    "ymin, ymax = np.nanmin(y - yerr), np.nanmax(y + yerr)\n",
    "ax.set_ylim(ymin - pad, ymax + pad)\n",
    "ax.set_ylabel(\"Direction (deg, coming-from)\")\n",
    "ax.grid(alpha=0.3)\n",
    "ax.set_title(\"Monthly climatology: wave direction (circular mean ± circular std)\")\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"fig/IA3_seasonal_climatology.png\", dpi=200, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "# quick textual summary\n",
    "hs_max_mo = int(clim[\"hs_mean\"].idxmax())\n",
    "hs_min_mo = int(clim[\"hs_mean\"].idxmin())\n",
    "tm_max_mo = int(clim[\"Tm02_mean\"].idxmax())\n",
    "tm_min_mo = int(clim[\"Tm02_mean\"].idxmin())\n",
    "print(\"IA.3 — Seasonal climatology (1994–2020)\")\n",
    "print(f\"  Hs peaks in {pd.to_datetime(hs_max_mo, format='%m').month_name()} \"\n",
    "      f\"and is lowest in {pd.to_datetime(hs_min_mo, format='%m').month_name()}.\")\n",
    "print(f\"  Tm02 peaks in {pd.to_datetime(tm_max_mo, format='%m').month_name()} \"\n",
    "      f\"and is lowest in {pd.to_datetime(tm_min_mo, format='%m').month_name()}.\")\n",
    "print(f\"  Direction mean (overall) ≈ {overall_dir:.1f}° (coming-from).\")\n",
    "print(\"  Saved: fig/IA3_seasonal_climatology.png and fig/IA3_seasonal_climatology.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "\n",
    "**Q: Do you observe any seasonal trends in wave height, period, or direction? If so, why?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "### Results\n",
    "\n",
    "**Significant wave height, $H_s$.** Clear winter maximum and summer minimum. IQR widens in winter and narrows in summer.  \n",
    "**Interpretation.** Boreal-winter extratropical cyclones increase wind speed and fetch over the open North Atlantic, augmenting wind-sea and incoming swell towards south Brittany. Summer conditions are dominated by weaker winds and shorter fetch, so mean $H_s$ decreases and variability contracts. Because wave energy density scales as\n",
    "$$\n",
    "E=\\tfrac{1}{8}\\,\\rho g\\,H_s^2,\n",
    "$$\n",
    "higher winter $H_s$ implies markedly greater wave energy arriving at the site.\n",
    "\n",
    "**Mean zero-crossing period, $T_{m02}$.** Co-varies with $H_s$: longer in winter, shorter in summer.  \n",
    "**Interpretation.** Winter storms generate longer-period swell over long fetches. Deep-water dispersion $\\big(L\\approx gT^2/2\\pi,\\ c_g \\approx gT/4\\pi\\big)$ favours the far-field propagation of longer-period energy into the Bay of Biscay. In summer, local wind-sea contribution increases and typical periods shorten.\n",
    "\n",
    "### Wave direction (coming-from, clockwise from North)\n",
    "\n",
    "**Convention.** $0^\\circ=\\mathrm{N},\\ 90^\\circ=\\mathrm{E},\\ 180^\\circ=\\mathrm{S},\\ 270^\\circ=\\mathrm{W}$.\n",
    "\n",
    "**Seasonal pattern.** The monthly circular mean increases from winter ($\\sim 240^\\circ$) to summer ($\\sim 255^\\circ$), then decreases again in autumn.\n",
    "\n",
    "**Interpretation** Larger angles imply a more westerly approach. Thus, waves are slightly more **W–WSW** in summer and shift a little toward **SW** in winter.\n",
    "\n",
    "**Regional context.** Along the southern Brittany–Bay of Biscay sector, the summer expansion of the Azores High favours a more zonal (westerly) approach at the shelf break. In winter, frequent lows entering the Bay introduce a modest southerly component in the incident swell, yielding the observed decrease in direction angle.\n",
    "\n",
    "**Dispersion note.** The vertical bars are circular standard deviations (spread of hourly directions), not standard errors. They are of similar magnitude across months, so the dataset does **not** support a strong seasonal change in directional spread.\n",
    "\n",
    "## Implications\n",
    "\n",
    "- **Operations.** Highest loads and sea states occur in winter months; scheduling for installation or maintenance is more feasible in late spring–summer.  \n",
    "- **Variability.** Broad winter IQRs indicate stronger interannual modulation of sea states; design and planning should not rely on a single “typical” winter value.  \n",
    "- **Directionality.** The prevailing W–WSW approach is stable enough to justify directional binning around that sector for further analyses and for extreme value modelling in Part II.\n",
    "\n",
    "## Notes and caveats\n",
    "\n",
    "- Monthly means smooth synoptic extremes; use EVA for design loads.  \n",
    "- Direction statistics use circular metrics; reported means reflect modal approach rather than arithmetic averages near $0/360^\\circ$.  \n",
    "- The site is predominantly deep water, so seasonal patterns reflect atmospheric forcing and basin geometry rather than depth-limited effects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "### I.A.4. Mean Wind and Current Conditions\n",
    "\n",
    "We will also evaluate the wind and current conditions by plotting rose diagrams of their respective velocities and directions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- IA.4 Mean wind and current conditions: roses + means (overall, seasonal) ---\n",
    "# -----------------------\n",
    "# Config\n",
    "# -----------------------\n",
    "# Calm thresholds used for ROSES only (kept in means table for reference)\n",
    "CALM_WIND = 0.5    # m/s\n",
    "CALM_CURR = 0.05   # m/s\n",
    "\n",
    "# Speed bins\n",
    "# Wind: [0.5–2), 2–4, 4–6, …, ≥16 m/s\n",
    "WIND_BINS = np.r_[0.5, np.arange(2, 18, 2), np.inf]\n",
    "# Currents: [0.05–0.1), 0.1–0.2, 0.2–0.3, 0.3–0.5, ≥0.5 m/s\n",
    "CURR_BINS = np.array([0.05, 0.10, 0.15, 0.2, np.inf])\n",
    "\n",
    "# Direction sectors\n",
    "WIND_SECTORS = 16   # 22.5°\n",
    "CURR_SECTORS = 36   # 10°\n",
    "\n",
    "# Date window to match the project\n",
    "# -----------------------\n",
    "# Helpers\n",
    "# -----------------------\n",
    "def season_label(month):\n",
    "    # DJF, MAM, JJA, SON\n",
    "    if month in (12, 1, 2):\n",
    "        return \"DJF\"\n",
    "    if month in (3, 4, 5):\n",
    "        return \"MAM\"\n",
    "    if month in (6, 7, 8):\n",
    "        return \"JJA\"\n",
    "    return \"SON\"\n",
    "\n",
    "def rose_counts(dir_deg, spd, spd_bins, sectors=16, calm_thresh=0.0):\n",
    "    \"\"\"\n",
    "    Return stacked counts per direction sector and speed bin, plus metadata.\n",
    "    Directions: degrees, 0°=N, clockwise positive.\n",
    "    Excludes values with spd <= calm_thresh.\n",
    "    \"\"\"\n",
    "    mask = np.isfinite(dir_deg) & np.isfinite(spd) & (spd > calm_thresh)\n",
    "    d = np.asarray(dir_deg)[mask] % 360.0\n",
    "    s = np.asarray(spd)[mask]\n",
    "\n",
    "    if d.size == 0:\n",
    "        counts = np.zeros((sectors, len(spd_bins)-1), dtype=int)\n",
    "        return counts, np.array([]), 0\n",
    "\n",
    "    width = 360.0 / sectors\n",
    "    sector_idx = np.floor(d / width).astype(int)\n",
    "    sector_idx[sector_idx == sectors] = sectors - 1\n",
    "\n",
    "    bin_idx = np.digitize(s, spd_bins) - 1\n",
    "    bin_idx = np.clip(bin_idx, 0, len(spd_bins)-2)\n",
    "\n",
    "    counts = np.zeros((sectors, len(spd_bins)-1), dtype=int)\n",
    "    for k in range(d.size):\n",
    "        counts[sector_idx[k], bin_idx[k]] += 1\n",
    "\n",
    "    return counts, mask, d.size  # d.size = included samples after calm filter\n",
    "\n",
    "def plot_rose(dir_deg, spd, spd_bins, fname, title, calm_thresh=0.0, sectors=16):\n",
    "    \"\"\"\n",
    "    Polar stacked-bar rose. Heights are percentages of included samples.\n",
    "    Direction convention: 0° at North, clockwise positive.\n",
    "    \"\"\"\n",
    "    counts, mask, n_used = rose_counts(dir_deg, spd, spd_bins, sectors, calm_thresh)\n",
    "    if n_used == 0:\n",
    "        print(f\"{title}: no data above calm threshold.\")\n",
    "        return\n",
    "\n",
    "    sector_totals = counts.sum(axis=1).astype(float)\n",
    "    sector_totals[sector_totals == 0] = 1.0\n",
    "    frac = counts / sector_totals[:, None]\n",
    "    pct_sector = 100.0 * counts.sum(axis=1) / n_used\n",
    "\n",
    "    theta = np.deg2rad(np.arange(0, 360, 360/sectors))\n",
    "    width = 2.0 * np.pi / sectors\n",
    "\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    ax = plt.subplot(111, polar=True)\n",
    "    ax.set_theta_zero_location(\"N\")\n",
    "    ax.set_theta_direction(-1)\n",
    "\n",
    "    bottoms = np.zeros(sectors)\n",
    "    labels = []\n",
    "    for j in range(len(spd_bins)-1):\n",
    "        label = f\"{spd_bins[j]:g}–{spd_bins[j+1]:g} m/s\" if np.isfinite(spd_bins[j+1]) else f\"{spd_bins[j]:g}+ m/s\"\n",
    "        labels.append(label)\n",
    "        heights = pct_sector * frac[:, j]\n",
    "        ax.bar(theta, heights, width=width, bottom=bottoms, align=\"edge\",\n",
    "               edgecolor=\"black\", linewidth=0.3)\n",
    "        bottoms += heights\n",
    "\n",
    "    ax.set_rlabel_position(225)\n",
    "    rmax = max(5.0, np.ceil(bottoms.max() / 5.0) * 5.0)\n",
    "    ax.set_ylim(0, rmax)\n",
    "    ax.set_yticks(np.linspace(0, rmax, 5))\n",
    "    ax.set_yticklabels([f\"{v:.0f}%\" for v in np.linspace(0, rmax, 5)])\n",
    "\n",
    "    ax.set_title(title + f\"\\n(calms ≤ {calm_thresh} m/s excluded; n={n_used})\",\n",
    "                 va=\"bottom\", fontsize=11)\n",
    "    ax.legend(labels, loc=\"lower left\", bbox_to_anchor=(0.9, -0.02),\n",
    "              frameon=True, fontsize=9)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(fname, dpi=200, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "def mean_table(dir_deg, spd, label, calm_thresh=None):\n",
    "    \"\"\"\n",
    "    Mean speed (arithmetic) and mean direction (circular) overall and by season.\n",
    "    Directions in degrees [0, 360).\n",
    "    calm_thresh listed for reference; does not alter means.\n",
    "    \"\"\"\n",
    "    idx = data.loc[start:end].index\n",
    "    df = pd.DataFrame({\"spd\": spd.loc[idx], \"dir\": dir_deg.loc[idx]})\n",
    "    df[\"season\"] = df.index.month.map(season_label)\n",
    "\n",
    "    def agg(g):\n",
    "        return pd.Series({\n",
    "            \"mean_speed_mps\": g[\"spd\"].mean(),\n",
    "            \"mean_dir_deg\": circmean_deg(g[\"dir\"]),\n",
    "            \"n\": g[\"dir\"].count()\n",
    "        })\n",
    "\n",
    "    overall = agg(df)\n",
    "    by_season = df.groupby(\"season\", sort=False).apply(agg)\n",
    "\n",
    "    overall.name = label\n",
    "    out = {\"overall\": overall.to_frame().T, \"season\": by_season}\n",
    "    out[\"meta\"] = {\"calm_threshold_listed_only_mps\": calm_thresh}\n",
    "    return out\n",
    "\n",
    "# -----------------------\n",
    "# Prepare series and conventions\n",
    "# -----------------------\n",
    "# Wind: already \"coming-from\" via zmcomp2metconv\n",
    "wspd = data[\"wspd\"].copy()\n",
    "wdir_from = data[\"wdir\"].copy()  # coming-from, 0°=N, clockwise\n",
    "\n",
    "# Currents: convert to \"going-to\" for the rose\n",
    "if {\"cspd\", \"cdir\"}.issubset(data.columns):\n",
    "    cspd = data[\"cspd\"].copy()\n",
    "    cdir_to = (data[\"cdir\"] + 180.0) % 360.0\n",
    "else:\n",
    "    cspd = None\n",
    "    cdir_to = None\n",
    "\n",
    "# Restrict to analysis window\n",
    "sel = slice(start, end)\n",
    "wspd = wspd.loc[sel]\n",
    "wdir_from = wdir_from.loc[sel]\n",
    "if cspd is not None:\n",
    "    cspd = cspd.loc[sel]\n",
    "    cdir_to = cdir_to.loc[sel]\n",
    "\n",
    "# -----------------------\n",
    "# 1) Full-period roses\n",
    "# -----------------------\n",
    "plot_rose(\n",
    "    dir_deg=wdir_from, spd=wspd, spd_bins=WIND_BINS,\n",
    "    fname=\"fig/IA4_wind_rose.png\",\n",
    "    title=\"Wind rose (coming-from; 0°=N, clockwise)\",\n",
    "    calm_thresh=CALM_WIND, sectors=WIND_SECTORS\n",
    ")\n",
    "\n",
    "if cspd is not None:\n",
    "    plot_rose(\n",
    "        dir_deg=cdir_to, spd=cspd, spd_bins=CURR_BINS,\n",
    "        fname=\"fig/IA4_current_rose.png\",\n",
    "        title=\"Current rose (going-to; 0°=N, clockwise)\",\n",
    "        calm_thresh=CALM_CURR, sectors=CURR_SECTORS\n",
    "    )\n",
    "\n",
    "# -----------------------\n",
    "# 2) Seasonal roses (DJF, MAM, JJA, SON)\n",
    "# -----------------------\n",
    "def plot_rose_seasons(dir_series, spd_series, spd_bins, calm_thresh, sectors, title_base, fname):\n",
    "    seasons = [\"DJF\", \"MAM\", \"JJA\", \"SON\"]\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 10), subplot_kw=dict(polar=True))\n",
    "    axes = axes.ravel()\n",
    "    for i, s in enumerate(seasons):\n",
    "        sel = dir_series.index.map(lambda t: season_label(t.month) == s)\n",
    "        d = dir_series[sel]\n",
    "        v = spd_series[sel]\n",
    "        counts, mask, n_used = rose_counts(d.values, v.values, spd_bins, sectors, calm_thresh)\n",
    "        theta = np.deg2rad(np.arange(0, 360, 360/sectors))\n",
    "        width = 2.0 * np.pi / sectors\n",
    "\n",
    "        ax = axes[i]\n",
    "        ax.set_theta_zero_location(\"N\")\n",
    "        ax.set_theta_direction(-1)\n",
    "\n",
    "        if n_used == 0:\n",
    "            ax.set_title(f\"{s} (n=0)\")\n",
    "            continue\n",
    "\n",
    "        sector_totals = counts.sum(axis=1).astype(float)\n",
    "        sector_totals[sector_totals == 0] = 1.0\n",
    "        frac = counts / sector_totals[:, None]\n",
    "        pct_sector = 100.0 * counts.sum(axis=1) / n_used\n",
    "\n",
    "        bottoms = np.zeros(sectors)\n",
    "        for j in range(len(spd_bins)-1):\n",
    "            heights = pct_sector * frac[:, j]\n",
    "            ax.bar(theta, heights, width=width, bottom=bottoms, align=\"edge\",\n",
    "                   edgecolor=\"black\", linewidth=0.3)\n",
    "            bottoms += heights\n",
    "\n",
    "        ax.set_rlabel_position(225)\n",
    "        rmax = max(5.0, np.ceil(bottoms.max() / 5.0) * 5.0)\n",
    "        ax.set_ylim(0, rmax)\n",
    "        ax.set_yticks(np.linspace(0, rmax, 5))\n",
    "        ax.set_yticklabels([f\"{v:.0f}%\" for v in np.linspace(0, rmax, 5)])\n",
    "        ax.set_title(f\"{s} (calms ≤ {calm_thresh} m/s; n={n_used})\", fontsize=10)\n",
    "\n",
    "    fig.suptitle(title_base, y=0.98)\n",
    "    plt.tight_layout(rect=[0, 0.02, 1, 0.95])\n",
    "    plt.savefig(fname, dpi=200, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "plot_rose_seasons(\n",
    "    wdir_from, wspd, WIND_BINS, CALM_WIND, WIND_SECTORS,\n",
    "    \"Wind roses by season (coming-from; 0°=N, clockwise)\",\n",
    "    \"fig/IA4_wind_rose_seasons.png\"\n",
    ")\n",
    "\n",
    "if cspd is not None:\n",
    "    plot_rose_seasons(\n",
    "        cdir_to, cspd, CURR_BINS, CALM_CURR, CURR_SECTORS,\n",
    "        \"Current roses by season (going-to; 0°=N, clockwise)\",\n",
    "        \"fig/IA4_current_rose_seasons.png\"\n",
    "    )\n",
    "\n",
    "# -----------------------\n",
    "# 3) Mean conditions tables and CSV\n",
    "# -----------------------\n",
    "wind_stats = mean_table(wdir_from, wspd, label=\"wind\", calm_thresh=CALM_WIND)\n",
    "if cspd is not None:\n",
    "    curr_stats = mean_table(cdir_to, cspd, label=\"current\", calm_thresh=CALM_CURR)\n",
    "\n",
    "frames = []\n",
    "wind_overall = wind_stats[\"overall\"].assign(kind=\"wind\")\n",
    "wind_season  = wind_stats[\"season\"].assign(kind=\"wind\", level=\"season\").reset_index().rename(columns={\"season\":\"group\"})\n",
    "frames += [wind_overall.assign(level=\"overall\", group=\"all\"), wind_season]\n",
    "\n",
    "if cspd is not None:\n",
    "    curr_overall = curr_stats[\"overall\"].assign(kind=\"current\")\n",
    "    curr_season  = curr_stats[\"season\"].assign(kind=\"current\", level=\"season\").reset_index().rename(columns={\"season\":\"group\"})\n",
    "    frames += [curr_overall.assign(level=\"overall\", group=\"all\"), curr_season]\n",
    "\n",
    "stats_df = pd.concat(frames, ignore_index=True)\n",
    "stats_df = stats_df[[\"kind\", \"level\", \"group\", \"mean_speed_mps\", \"mean_dir_deg\", \"n\"]]\n",
    "stats_df.to_csv(\"fig/IA4_mean_wind_current_stats.csv\", index=False, float_format=\"%.3f\")\n",
    "\n",
    "# Print seasonal values for wind and current\n",
    "\n",
    "season_order = CategoricalDtype([\"DJF\", \"MAM\", \"JJA\", \"SON\"], ordered=True)\n",
    "\n",
    "def print_seasonals(kind_label, dir_note):\n",
    "    df = stats_df.query(\"kind == @kind_label and level == 'season'\").copy()\n",
    "    df[\"group\"] = df[\"group\"].astype(season_order)\n",
    "    df = df.sort_values(\"group\")\n",
    "    print(f\"\\nIA.4 — Seasonal means, {kind_label} ({dir_note})\")\n",
    "    print(df[[\"group\", \"mean_speed_mps\", \"mean_dir_deg\", \"n\"]]\n",
    "          .rename(columns={\"group\": \"season\"})\n",
    "          .to_string(index=False,\n",
    "                     formatters={\n",
    "                         \"mean_speed_mps\": lambda v: f\"{v:.3f}\",\n",
    "                         \"mean_dir_deg\":  lambda v: f\"{v:.1f}\",\n",
    "                         \"n\":             lambda v: f\"{int(v)}\"\n",
    "                     }))\n",
    "\n",
    "print_seasonals(\"wind\", \"coming-from\")\n",
    "print_seasonals(\"current\", \"going-to\")\n",
    "\n",
    "print(\"IA.4 — Mean conditions (1994–2020)\")\n",
    "print(stats_df.query(\"level == 'overall'\"))\n",
    "print(\"\\nSaved figures:\")\n",
    "print(\"  fig/IA4_wind_rose.png\")\n",
    "if cspd is not None:\n",
    "    print(\"  fig/IA4_current_rose.png\")\n",
    "print(\"  fig/IA4_wind_rose_seasons.png\")\n",
    "if cspd is not None:\n",
    "    print(\"  fig/IA4_current_rose_seasons.png\")\n",
    "print(\"Saved table: fig/IA4_mean_wind_current_stats.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "**Q: What are the mean conditions (e.g. velocity and direction)? (if you have time: do you observe any seasonal variability?)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "### IA.4  Interpretation of wind and current conditions\n",
    "\n",
    "\n",
    "**Answer.** Winds are W-WNW year-round and strongest in winter (overall mean 7.22 m/s; DJF mean 8.67 m/s). Currents are weak (about 0.10 m/s) and dominantly tidal along a NE-SW axis, so the overall mean direction is not physically representative.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "### Data basis and conventions\n",
    "\n",
    "\n",
    "- Period analysed: 1994-2020.  \n",
    "- Calms excluded in roses: wind $<0.5$ m/s, current $<0.05$ m/s.  \n",
    "- Wind: **coming-from**; Current: **going-to**; $0^\\circ=\\text{N}$, clockwise.  \n",
    "- Bins used: wind speeds $[0.5,2),[2,4),\\ldots,\\ge 16$ m/s; current speeds $[0.05,0.10),[0.10,0.15),[0.15,0.20),\\ge 0.20$ m/s; wind sectors $22.5^\\circ$; current sectors $10^\\circ$.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "### Summary statistics\n",
    "\n",
    "\n",
    "**Overall means (1994-2020)**\n",
    "\n",
    "\n",
    "| Variable | Mean speed | Mean direction |\n",
    "|---|---:|---:|\n",
    "| Wind (coming-from) | 7.22 m/s | 296.6 |\n",
    "| Current (going-to) | 0.096 m/s | 285.2* |\n",
    "\n",
    "\n",
    "\\*For reversing tidal currents, a single circular mean direction is not physically informative.\n",
    "\n",
    "\n",
    "**Seasonal means**\n",
    "\n",
    "\n",
    "| Season | Wind speed (m/s) | Wind dir (deg) | Current speed (m/s) | Current dir (deg)* |\n",
    "|---|---:|---:|---:|---:|\n",
    "| DJF | 8.67 | 266.3 | 0.096 | 211.3 |\n",
    "| MAM | 6.95 | 321.1 | 0.096 | 28.3 |\n",
    "| JJA | 6.00 | 302.6 | 0.096 | 228.5 |\n",
    "| SON | 7.31 | 287.5 | 0.096 | 19.0 |\n",
    "\n",
    "\n",
    "\\*Seasonal current means are shown for completeness but the roses indicate a bidirectional tidal regime.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "### Wind climate: what the roses show\n",
    "\n",
    "\n",
    "- **Directionality.** Dominant **W-WNW** approach. Seasonal veer is modest: closer to **W** in winter (DJF $\\sim266^\\circ$), rotating towards **WNW** in spring and summer (MAM-JJA $\\sim321^\\circ$ to $\\sim303^\\circ$), then easing back in autumn (SON $\\sim288^\\circ$).\n",
    "- **Intensity.** Clear seasonal cycle: **DJF > SON > MAM > JJA** by mean speed. The full-period rose shows most occurrences in the **4-12 m/s** bands, with winter contributing the higher **8-14 m/s** fractions.\n",
    "- **Variability.** Sectoral spread remains broader in MAM/SON than in DJF/JJA, consistent with synoptic variability during shoulder seasons.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "### Current climate: what the roses show\n",
    "\n",
    "\n",
    "- **Regime.** Two narrow, opposing **going-to** headings dominate, approximately **NE (30^\\circ)** and **SW (210^\\circ)**, confirming a reversing tidal signal.\n",
    "- **Magnitudes.** Most occurrences lie **below 0.30 m/s**; the highest occupied bin is typically **0.15-0.20 m/s**, with scarce excursions beyond. The mean speed of **0.096 m/s** reflects the prevalence of weak flows.\n",
    "- **Seasonality.** The **axis does not shift** with season, and the speed distribution changes little between DJF and JJA in the roses, highlighting tide-dominated currents with weak seasonal modulation.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "### Site context notes\n",
    "\n",
    "\n",
    "- The study area is **south of Lorient (southern Brittany)**, exposed to the **open North Atlantic**. The prevailing **W-WNW** winds align with the basin-scale westerlies and frequent winter cyclones.  \n",
    "- The **NE-SW** tidal current axis is consistent with coastal geometry that channels reversing flows; without detailed bathymetry/harmonic analysis, treat this as a qualitative inference from the roses.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "### Caveats and suggested refinements\n",
    "\n",
    "\n",
    "- **Currents:** Do not use circular means for direction. Prefer a **principal axis** metric and report the **two modal headings** with their shares.  \n",
    "- **Quantiles:** Add $P_{50}$, $P_{90}$, $P_{95}$ for wind and current speeds to complement the means (e.g., $P_{90}$ wind speed $\\approx$ x m/s).  \n",
    "- **Calms:** Roses exclude calms by design; if calm frequency is relevant to operations, report the calm fraction separately.  \n",
    "- **Next step:** If needed for design or logistics, compute a tidal ellipse or principal-component axis for the currents, and provide **hour-of-tide** roses to expose phase dependence.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "### I.A.5. Comparison to Wave Buoy Measurements\n",
    "\n",
    "We can validate the ResourceCode hindcast data against observations from a nearby wave buoy, for example, from the Candhis website.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "**Q: Comparing the hindcast data from ResourceCode to the observations during the time period with overlapping data, what is the RMSD in the wave height, period, and direction between the observations and simulations?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- IA.5 — Candhis buoy validation (Belle-Île 05602, year 2020) ---\n",
    "# Goal: RMSD between ResourceCode hindcast and Candhis observations for Hs, Tm02, and mean direction.\n",
    "# Notes:\n",
    "# - Candhis direction: use THETAM (mean, coming-from, true north, clockwise).\n",
    "# - ResourceCode wave direction assumed coming-from in `data['dir']`. If not, set RC_IS_COMING_FROM=False.\n",
    "# - Time matching: nearest within ±30 min.\n",
    "# - QC: drop sentinels (999.*), non-numeric, |SKEW|>0.3, KURT>5, and (if present) non-valid QUALITE.\n",
    "\n",
    "# ---------- Config ----------\n",
    "RC_IS_COMING_FROM = True          # set to False if your ResourceCode 'dir' is going-to\n",
    "TOL = pd.Timedelta(\"30min\")       # matching tolerance\n",
    "CSV_PATHS = [\n",
    "    Path(\"data/Candhis_05602_2020_arch.csv\"),     # preferred relative path\n",
    "    Path(\"/mnt/data/Candhis_05602_2020_arch.csv\") # fallback (chat attachment)\n",
    "]\n",
    "\n",
    "# ---------- Utilities ----------\n",
    "def _first_existing(paths):\n",
    "    for p in paths:\n",
    "        if p.exists():\n",
    "            return p\n",
    "    raise FileNotFoundError(\"Candhis 2020 CSV not found at any known path.\")\n",
    "\n",
    "def circ_diff_deg(a_deg, b_deg):\n",
    "    \"\"\"Minimal angular difference a-b in degrees in [-180, 180).\"\"\"\n",
    "    d = (a_deg - b_deg + 180.0) % 360.0 - 180.0\n",
    "    return d\n",
    "\n",
    "def rmse(a, b):\n",
    "    a = np.asarray(a, float)\n",
    "    b = np.asarray(b, float)\n",
    "    m = np.isfinite(a) & np.isfinite(b)\n",
    "    if m.sum() == 0:\n",
    "        return np.nan, 0\n",
    "    return float(np.sqrt(np.mean((a[m] - b[m])**2))), int(m.sum())\n",
    "\n",
    "def circ_rmse_deg(a_deg, b_deg):\n",
    "    \"\"\"RMS of circular differences in degrees.\"\"\"\n",
    "    d = circ_diff_deg(np.asarray(a_deg, float), np.asarray(b_deg, float))\n",
    "    m = np.isfinite(d)\n",
    "    if m.sum() == 0:\n",
    "        return np.nan, 0\n",
    "    return float(np.sqrt(np.mean(d[m]**2))), int(m.sum())\n",
    "\n",
    "# ---------- Load Candhis 2020 ----------\n",
    "candhis_csv = _first_existing(CSV_PATHS)\n",
    "\n",
    "cand = pd.read_csv(\n",
    "    candhis_csv,\n",
    "    sep=\";\", engine=\"python\",\n",
    "    parse_dates=[\"DateHeure\"]\n",
    ")\n",
    "\n",
    "# Keep only fields needed + QC fields\n",
    "need_cols = [\"DateHeure\", \"HM0\", \"T02\", \"THETAM\", \"SKEW\", \"KURT\", \"QUALITE\"]\n",
    "for c in need_cols:\n",
    "    if c not in cand.columns:\n",
    "        # QUALITE may be absent; others must exist\n",
    "        if c == \"QUALITE\":\n",
    "            cand[\"QUALITE\"] = np.nan\n",
    "        else:\n",
    "            raise KeyError(f\"Missing '{c}' in Candhis CSV.\")\n",
    "\n",
    "# Convert to numeric and mark sentinels (e.g., 999.*) as NaN\n",
    "num_cols = [\"HM0\", \"T02\", \"THETAM\", \"SKEW\", \"KURT\"]\n",
    "for c in num_cols:\n",
    "    cand[c] = pd.to_numeric(cand[c], errors=\"coerce\")\n",
    "    # Drop obvious sentinels like 999, 999.999, etc.\n",
    "    cand.loc[cand[c] >= 999.0, c] = np.nan\n",
    "\n",
    "# QC filters\n",
    "qc = pd.Series(True, index=cand.index)\n",
    "\n",
    "# 1) Required numeric fields present\n",
    "qc &= cand[\"HM0\"].notna() & cand[\"T02\"].notna() & cand[\"THETAM\"].notna()\n",
    "\n",
    "# 2) Physical sanity\n",
    "qc &= (cand[\"HM0\"] > 0) & (cand[\"T02\"] > 0)\n",
    "\n",
    "# 3) Distribution checks\n",
    "#    Drop timestamps with |SKEW| > 0.3 or KURT > 5 (when available)\n",
    "skew_ok = cand[\"SKEW\"].abs() <= 0.3\n",
    "kurt_ok = cand[\"KURT\"] <= 5.0\n",
    "# If SKEW/KURT missing at a row, do not auto-drop for that reason\n",
    "skew_ok = skew_ok | cand[\"SKEW\"].isna()\n",
    "kurt_ok = kurt_ok | cand[\"KURT\"].isna()\n",
    "qc &= skew_ok & kurt_ok\n",
    "\n",
    "# 4) QUALITE (if present): keep only rows with non-empty labels considered valid\n",
    "#    Many archive files have QUALITE empty; when populated, typical \"good\" tags include letters.\n",
    "if cand[\"QUALITE\"].notna().any():\n",
    "    # Keep non-empty, non-null strings that are not \"M\", \"NA\", or \"ERR\"\n",
    "    q = cand[\"QUALITE\"].astype(str).str.strip().str.upper()\n",
    "    good = ~(q.isna() | (q == \"\") | q.isin({\"M\", \"NA\", \"ERR\"}))\n",
    "    qc &= good\n",
    "\n",
    "cand_qc = cand.loc[qc, [\"DateHeure\", \"HM0\", \"T02\", \"THETAM\"]].copy()\n",
    "cand_qc = cand_qc.rename(columns={\"DateHeure\": \"time\", \"HM0\": \"hs_obs\", \"T02\": \"Tm02_obs\", \"THETAM\": \"dir_obs_deg\"})\n",
    "cand_qc[\"time\"] = pd.to_datetime(cand_qc[\"time\"], utc=True)  # TU = UTC\n",
    "cand_qc = cand_qc.set_index(\"time\").sort_index()\n",
    "\n",
    "# Restrict strictly to 2020 UTC\n",
    "start_utc = pd.Timestamp(\"2020-01-01 00:00:00\", tz=\"UTC\")\n",
    "end_utc   = pd.Timestamp(\"2020-12-31 23:59:59\", tz=\"UTC\")\n",
    "cand_qc = cand_qc.loc[start_utc:end_utc]\n",
    "\n",
    "print(f\"Candhis 2020 after QC: {len(cand_qc)} rows\")\n",
    "\n",
    "# ---------- Prepare ResourceCode subset for 2020 ----------\n",
    "# Assumes your earlier cells defined `data` with columns: 'hs', 'Tm02', 'dir' and a DatetimeIndex in UTC or naive-UTC.\n",
    "if not {\"hs\", \"Tm02\", \"dir\"}.issubset(data.columns):\n",
    "    raise KeyError(\"ResourceCode `data` must include ['hs','Tm02','dir'].\")\n",
    "\n",
    "rc = data[[\"hs\", \"Tm02\", \"dir\"]].copy()\n",
    "\n",
    "# Ensure datetime is tz-aware UTC to compare with Candhis TU\n",
    "if rc.index.tz is None:\n",
    "    rc.index = rc.index.tz_localize(\"UTC\")\n",
    "\n",
    "rc_2020 = rc.loc[start_utc:end_utc].copy()\n",
    "rc_2020 = rc_2020.sort_index()\n",
    "\n",
    "# Direction convention alignment\n",
    "if RC_IS_COMING_FROM:\n",
    "    rc_2020[\"dir_from_deg\"] = rc_2020[\"dir\"] % 360.0\n",
    "else:\n",
    "    # Convert going-to -> coming-from to match THETAM\n",
    "    rc_2020[\"dir_from_deg\"] = (rc_2020[\"dir\"] + 180.0) % 360.0\n",
    "\n",
    "rc_2020 = rc_2020.rename(columns={\"hs\": \"hs_mod\", \"Tm02\": \"Tm02_mod\"})\n",
    "\n",
    "# Time matching (nearest within ±30 min)\n",
    "left  = cand_qc.reset_index().rename(columns={\"time\": \"t_obs\"})\n",
    "right = rc_2020.reset_index().rename(columns={\"index\": \"t_mod\"})\n",
    "\n",
    "pairs = pd.merge_asof(\n",
    "    left.sort_values(\"t_obs\"),\n",
    "    right.sort_values(\"t_mod\"),\n",
    "    left_on=\"t_obs\",\n",
    "    right_on=\"t_mod\",\n",
    "    tolerance=TOL,\n",
    "    direction=\"nearest\",\n",
    ")\n",
    "\n",
    "# Drop non-matches (NaN where no model within tolerance)\n",
    "pairs = pairs.dropna(subset=[\"hs_mod\", \"Tm02_mod\", \"dir_from_deg\"])\n",
    "\n",
    "# ---------- Metrics ----------\n",
    "hs_rmse, n_hs = rmse(pairs[\"hs_mod\"], pairs[\"hs_obs\"])\n",
    "t02_rmse, n_t = rmse(pairs[\"Tm02_mod\"], pairs[\"Tm02_obs\"])\n",
    "dir_rmse, n_d = circ_rmse_deg(pairs[\"dir_from_deg\"], pairs[\"dir_obs_deg\"])\n",
    "\n",
    "summary = pd.DataFrame({\n",
    "    \"metric\": [\"RMSD_Hs (m)\", \"RMSD_Tm02 (s)\", \"RMSD_Dir_THETAM (deg)\"],\n",
    "    \"value\": [hs_rmse, t02_rmse, dir_rmse],\n",
    "    \"N_pairs\": [n_hs, n_t, n_d]\n",
    "})\n",
    "\n",
    "print(\"\\nIA.5 — Candhis vs ResourceCode (2020, Belle-Île 05602)\")\n",
    "print(summary.to_string(index=False, float_format=lambda v: f\"{v:.3f}\"))\n",
    "\n",
    "# Save outputs\n",
    "out_dir = Path(\"fig\")\n",
    "out_dir.mkdir(exist_ok=True)\n",
    "summary.to_csv(out_dir / \"IA5_rmsd_2020_candhis05602.csv\", index=False)\n",
    "\n",
    "# Optional quick-look plots\n",
    "fig, ax = plt.subplots(3, 1, figsize=(12, 9), sharex=True)\n",
    "ax[0].plot(pairs[\"t_obs\"], pairs[\"hs_obs\"], label=\"Buoy HM0\", lw=0.9)\n",
    "ax[0].plot(pairs[\"t_obs\"], pairs[\"hs_mod\"], label=\"Model Hs\", lw=0.9)\n",
    "ax[0].set_ylabel(\"Hs (m)\")\n",
    "ax[0].grid(alpha=0.3)\n",
    "ax[0].legend()\n",
    "\n",
    "ax[1].plot(pairs[\"t_obs\"], pairs[\"Tm02_obs\"], label=\"Buoy T02\", lw=0.9)\n",
    "ax[1].plot(pairs[\"t_obs\"], pairs[\"Tm02_mod\"], label=\"Model Tm02\", lw=0.9)\n",
    "ax[1].set_ylabel(\"Tm02 (s)\")\n",
    "ax[1].grid(alpha=0.3)\n",
    "ax[1].legend()\n",
    "\n",
    "# Direction as coming-from; plot circularly unwrapped about buoy direction to visualise differences\n",
    "d_err = circ_diff_deg(pairs[\"dir_from_deg\"], pairs[\"dir_obs_deg\"])\n",
    "ax[2].plot(pairs[\"t_obs\"], d_err, lw=0.8)\n",
    "ax[2].axhline(0, color=\"k\", lw=0.8)\n",
    "ax[2].set_ylabel(\"Dir error (deg)\")\n",
    "ax[2].set_xlabel(\"2020 UTC\")\n",
    "ax[2].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(out_dir / \"IA5_timeseries_2020.png\", dpi=200, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "# Scatter diagnostics (optional)\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4.5))\n",
    "axes[0].scatter(pairs[\"hs_obs\"], pairs[\"hs_mod\"], s=4, alpha=0.5)\n",
    "mx = np.nanmax([pairs[\"hs_obs\"].max(), pairs[\"hs_mod\"].max()])\n",
    "axes[0].plot([0, mx], [0, mx], 'k:', lw=1)\n",
    "axes[0].set_xlabel(\"Buoy HM0 (m)\")\n",
    "axes[0].set_ylabel(\"Model Hs (m)\")\n",
    "axes[0].set_title(f\"RMSD={hs_rmse:.2f} m\")\n",
    "\n",
    "axes[1].scatter(pairs[\"Tm02_obs\"], pairs[\"Tm02_mod\"], s=4, alpha=0.5)\n",
    "mx = np.nanmax([pairs[\"Tm02_obs\"].max(), pairs[\"Tm02_mod\"].max()])\n",
    "axes[1].plot([0, mx], [0, mx], 'k:', lw=1)\n",
    "axes[1].set_xlabel(\"Buoy T02 (s)\")\n",
    "axes[1].set_ylabel(\"Model Tm02 (s)\")\n",
    "axes[1].set_title(f\"RMSD={t02_rmse:.2f} s\")\n",
    "\n",
    "axes[2].hist(d_err, bins=72)\n",
    "axes[2].set_xlabel(\"Dir error (deg, THETAM)\")\n",
    "axes[2].set_ylabel(\"Count\")\n",
    "axes[2].set_title(f\"circ-RMSD={dir_rmse:.1f}°\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(out_dir / \"IA5_scatter_2020.png\", dpi=200, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "### IA.5 — Buoy–model comparison (Belle-Île 05602 vs ResourceCode), year 2020\n",
    "\n",
    "**RMSD results** (±30 min pairing; QC applied; direction uses Candhis **THETAM**, coming-from):\n",
    "- $H_s$: **0.39 m**  \n",
    "- $T_{m02}$: **0.84 s**  \n",
    "- Mean direction: **21.2°** (circular RMSD)  \n",
    "Pairs used: **15 947** half-hours.\n",
    "\n",
    "---\n",
    "\n",
    "#### Interpretation\n",
    "\n",
    "**Wave height.** Agreement is good over the 0–8 m range. Most error accrues during storms, as expected when model and buoy are not co-located.\n",
    "\n",
    "**Period.** Consistent overall. The scatter indicates a mild mismatch at the longest periods.\n",
    "\n",
    "**Direction.** A 21° circular RMSD is reasonable near a coast with mixed sea–swell and turning fronts. Spikes coincide with weak seas or multi-modal spectra where mean direction is less stable.\n",
    "\n",
    "---\n",
    "\n",
    "#### Spatial representativeness and depth effects\n",
    "\n",
    "- **Positions.** Buoy: $(47.3111^\\circ,\\,-3.3111^\\circ)$ at **45 m** depth.  \n",
    "  Model point: $(47.3236^\\circ,\\,-3.5522^\\circ)$ at **93.32 m** depth.  \n",
    "  Horizontal offset ≈ **18 km**.\n",
    "\n",
    "- **Depth regime difference.** Using the deep-water proxy $T_\\text{deep}\\approx 4\\sqrt{h/g}$:\n",
    "  - At **45 m**: $T_\\text{deep}\\approx 8.6$ s. Longer swell can enter transitional depth, with refraction and depth-induced transformation before reaching the buoy.\n",
    "  - At **93.32 m**: $T_\\text{deep}\\approx 12.3$ s. The offshore model point remains deep for a larger share of the spectrum.\n",
    "\n",
    "- **Implications.** Between 93 m and 45 m the wave field rotates and re-distributes energy. This raises direction error and can alter spectral shape enough to shift $T_{m02}$ slightly. Height differences during energetic events also reflect unmodelled small-scale sheltering by Belle-Île and local bathymetry not captured by the point-to-point comparison.\n",
    "\n",
    "---\n",
    "\n",
    "#### February–March 2020 gap\n",
    "\n",
    "The ~**1-month** hole is from the **observations**, not the model. After QC (sentinels removed; $|SKEW|\\le 0.3$; KURT $\\le 5$; QUALITE filter when present), many half-hours in late winter drop out. Typical causes are buoy maintenance, telemetry loss, or spectra failing distribution checks. The line plots bridge over missing points; no data were used there.\n",
    "\n",
    "---\n",
    "\n",
    "#### Answer to the study question\n",
    "\n",
    "For the 2020 overlap, the RMSD between ResourceCode and the Candhis Belle-Île buoy is **0.39 m** for $H_s$, **0.84 s** for $T_{m02}$, and **21.2°** for mean direction (THETAM, circular RMSD). Given the **18 km** separation and **93 m vs 45 m** depths, these errors are consistent with expected coastal transformation between the offshore model point and the nearer-shore buoy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "## I.B. Estimating the extreme wave conditions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "### Block Maxima (BM) Method\n",
    "\n",
    "**Approach:**  \n",
    "This approach involves dividing the long-term time series of significant wave heights into non-overlapping blocks of equal duration, typically one year.\n",
    "\n",
    "**Process:**  \n",
    "The single highest significant wave height (Hₘ₀) is taken from each block (e.g., the annual maximum).\n",
    "\n",
    "**Distribution:**  \n",
    "These maximum values are then fitted to a *Generalized Extreme Value (GEV)* distribution.\n",
    "\n",
    "**Outcome:**  \n",
    "This model allows you to estimate the wave height corresponding to a specific return period, such as the 1-year or 50-year storm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Create EVA object\n",
    "model_bm = EVA(data.hs)\n",
    "\n",
    "# Step 2: Extract extremes\n",
    "model_bm.get_extremes(\n",
    "    method=\"BM\",\n",
    "    block_size=\"365.2425D\",\n",
    "    extremes_type=\"high\",\n",
    "    errors=\"raise\",\n",
    "    min_last_block=0.9\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {},
   "source": [
    "Lets check the directions of the extreme heights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets find the directions of the extremes from the data\n",
    "extremes_indices = model_bm.extremes.index\n",
    "data_extreme_directions = data.loc[extremes_indices, \"dir\"]\n",
    "data_extreme_tm02 = data.loc[extremes_indices, \"Tm02\"]\n",
    "data_extreme_wspd = data.loc[extremes_indices, \"wspd\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "extremes_df = (\n",
    "    pd.DataFrame({'timestamp': extremes_indices, 'hs': model.extremes.values})\n",
    "    .merge(\n",
    "        data[['dir','wspd','Tm02']].reset_index().rename(columns={'index':'timestamp'}),\n",
    "        on='timestamp',\n",
    "        how='left'\n",
    "    )\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "extremes_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extremes\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10))\n",
    "\n",
    "# Plot 1: Time series with extremes highlighted\n",
    "ax1.plot(data.index, data.hs, 'b-', alpha=0.3, linewidth=0.5, label='Full time series')\n",
    "ax1.scatter(model.extremes.index, model.extremes.values, color='red', s=20, alpha=0.8, label='Extremes (Block Maxima)')\n",
    "ax1.set_xlabel('Date')\n",
    "ax1.set_ylabel('Significant Wave Height (m)')\n",
    "ax1.set_title('Time Series with One-year Block Extremes')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Histogram of extremes\n",
    "ax2.hist(model.extremes.values, bins=15, alpha=0.7, color='red', edgecolor='black')\n",
    "ax2.set_xlabel('Extreme Wave Height (m)')\n",
    "ax2.set_ylabel('Frequency')\n",
    "ax2.set_title('Distribution of Block Maxima Extremes')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print some statistics about the extremes\n",
    "print(f\"Number of extremes: {len(model.extremes)}\")\n",
    "print(f\"Mean extreme value: {model.extremes.mean():.3f} m\")\n",
    "print(f\"Maximum extreme value: {model.extremes.max():.3f} m\")\n",
    "print(f\"Minimum extreme value: {model.extremes.min():.3f} m\")\n",
    "print(f\"Standard deviation: {model.extremes.std():.3f} m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# More detailed manual plotting of extremes\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 4))\n",
    "\n",
    "# Plot the full time series\n",
    "ax.plot(data.index, data.hs, 'b-', alpha=0.2, linewidth=0.3, label='Full time series')\n",
    "\n",
    "# Highlight extremes with different colors based on magnitude\n",
    "extremes = model.extremes\n",
    "colors = plt.cm.Reds(np.linspace(0.3, 1, len(extremes)))\n",
    "scatter = ax.scatter(extremes.index, extremes.values, c=extremes.values, \n",
    "                    cmap='Reds', s=30, alpha=0.8, edgecolors='black', linewidth=0.5)\n",
    "\n",
    "# Add colorbar\n",
    "cbar = plt.colorbar(scatter, ax=ax)\n",
    "cbar.set_label('Wave Height (m)')\n",
    "\n",
    "# Customize the plot\n",
    "ax.set_xlabel('Date', fontsize=12)\n",
    "ax.set_ylabel('Significant Wave Height (m)', fontsize=12)\n",
    "ax.set_title('Block Maxima Extremes Over Time\\n(Red dots show annual maximum wave heights)', fontsize=14)\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets execute GEV fit on the extremes\n",
    "model_bm.fit_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate return values for 1-year and 50-year period\n",
    "return_period = [1.01,1.1, 1.2, 1.3, 1.4,1.5, 2, 5, 10, 25, 50]\n",
    "summary_bm = model_bm.get_summary(return_period=return_period, alpha=0.95)\n",
    "print(summary_bm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot with correct empirical return periods\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Get correct empirical return periods\n",
    "sorted_extremes = np.sort(model.extremes.values)[::-1]  # Sort descending\n",
    "n_extremes = len(sorted_extremes)\n",
    "\n",
    "# Correct empirical return period calculation\n",
    "# For block maxima, empirical return period = (n + 1) / (rank)\n",
    "empirical_return_periods = (n_extremes + 1) / np.arange(1, n_extremes + 1)\n",
    "\n",
    "# Plot your observed data with correct empirical return periods\n",
    "ax.semilogx(empirical_return_periods, sorted_extremes, 'ko', markersize=4, alpha=0.7, label='Observed Extremes (Empirical)')\n",
    "\n",
    "# Add fitted model for comparison\n",
    "summary = model.get_summary([0, 1, 2, 5, 10, 25, 50, 100], return_period_size=\"365.2425D\", alpha=0.90)\n",
    "ax.semilogx(summary.index, summary['return value'], 'r-', linewidth=2, label='Fitted Model')\n",
    "\n",
    "# Add confidence intervals\n",
    "ax.semilogx(summary.index, summary['upper ci'], 'r--', linewidth=1, alpha=0.7, label='Upper 90% CI')\n",
    "ax.semilogx(summary.index, summary['lower ci'], 'r--', linewidth=1, alpha=0.7, label='Lower 90% CI')\n",
    "\n",
    "# Fill between confidence intervals\n",
    "ax.fill_between(summary.index, summary['lower ci'], summary['upper ci'], alpha=0.2, color='red')\n",
    "\n",
    "# Highlight 50-year point\n",
    "ax.semilogx(50, summary.loc[50, 'return value'], 'ro', markersize=8, label='50-year Return Period')\n",
    "\n",
    "ax.set_xlabel('Return Period (years)')\n",
    "ax.set_ylabel('Significant Wave Height (m)')\n",
    "ax.set_title('Empirical vs Fitted Return Values')\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot with extended model to 1 year\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Get correct empirical return periods\n",
    "sorted_extremes = np.sort(model.extremes.values)[::-1]  # Sort descending\n",
    "n_extremes = len(sorted_extremes)\n",
    "\n",
    "# Correct empirical return period calculation\n",
    "empirical_return_periods = (n_extremes + 1) / np.arange(1, n_extremes + 1)\n",
    "\n",
    "# Plot your observed data with correct empirical return periods\n",
    "ax.semilogx(empirical_return_periods, sorted_extremes, 'ko', markersize=4, alpha=0.7, label='Observed Extremes (Empirical)')\n",
    "\n",
    "# Add fitted model with extended range to 1 year\n",
    "summary = model.get_summary([1, 1.5, 2, 3, 5, 10, 25, 50, 100], return_period_size=\"365.2425D\", alpha=0.90)\n",
    "ax.semilogx(summary.index, summary['return value'], 'r-', linewidth=2, label='Fitted Model')\n",
    "\n",
    "# Add confidence intervals\n",
    "ax.semilogx(summary.index, summary['upper ci'], 'r--', linewidth=1, alpha=0.7, label='Upper 90% CI')\n",
    "ax.semilogx(summary.index, summary['lower ci'], 'r--', linewidth=1, alpha=0.7, label='Lower 90% CI')\n",
    "\n",
    "# Fill between confidence intervals\n",
    "ax.fill_between(summary.index, summary['lower ci'], summary['upper ci'], alpha=0.2, color='red')\n",
    "\n",
    "# Highlight 50-year point\n",
    "ax.semilogx(50, summary.loc[50, 'return value'], 'ro', markersize=8, label='50-year Return Period')\n",
    "\n",
    "ax.set_xlabel('Return Period (years)')\n",
    "ax.set_ylabel('Significant Wave Height (m)')\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the threshold for the POT method\n",
    "# an empricial threshold is used here based on the data's return period\n",
    "threshold = 2.5  # meters\n",
    "print(f'Threshold: {threshold} m')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44",
   "metadata": {},
   "source": [
    "### Modelling univariate time series: Block maxima + GEVD (Generalized Extreme Value Distribution)\n",
    "\n",
    "We show as an example here a **BM** (block maxima) model fitted to the $H_s$ time series. In this approach, the maximum value is identified within a \"block\" or fixed period in time, and then a GEVP distribution is fit to the data to estimate the return values.  \n",
    "\n",
    "The same plot can readily be obtained for the other sea-state parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_pot = model_pot.get_summary(\n",
    "    return_period=[1, 2, 5, 10, 25, 50],\n",
    "    return_period_size=\"365.2425D\",\n",
    "    alpha=0.95\n",
    ")\n",
    "print(summary_pot)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46",
   "metadata": {},
   "source": [
    "After loading the data, apply the block method approach with a block size of 1 year (365.2425 days), where each data block must be at least 90% full to take into account in the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(summary_bm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(summary_pot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.plot_extremes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51",
   "metadata": {},
   "source": [
    "The parameter alpha specifies the confidence limits (default = 0.95)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pot.plot_diagnostic(alpha=0.95)\n",
    "plt.savefig('graphs/diagnostic_plot_pot.png', dpi=200, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53",
   "metadata": {},
   "source": [
    "The parameter n_samples indicates the number of bootstrap samples used to estimate the confidence bounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = model.get_summary(\n",
    "        return_period=[1, 2, 5, 10, 25, 50, 100, 250, 500, 1000],\n",
    "        alpha=0.95,\n",
    "        n_samples=1000,\n",
    "    )\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55",
   "metadata": {},
   "source": [
    "### Modelling univariate time series: Peaks over threshold (POT) + GPD (Generalized Pareto Distribution)\n",
    "\n",
    "We show as example here a **POT** (peaks over threshold) model fitted to the $H_s$ time series. This analysis first finds values over a specified threshold and then declusters these values using a predefined clustering distance, and finally finds the maximum value within each cluster. \n",
    "\n",
    "The same plot can readily be obtained for the other sea-state parameters.\n",
    "\n",
    "We first can have a look at the quality of the fitted model, and to the corresponding return levels as a function of the selected wave height threshold. The parameters r and alpha specify the minimum time distance (duration) between adjacent clusters and the confidence limits (default = 0.95), respectively.\n",
    "\n",
    "The shape and modified scale parameters define the Generalized Pareto Distribution, and they depend on the threshold value, but should be stable within a range of valid thresholds (e.g. less than ~3m here)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_parameter_stability(ts=data.hs, r='72H', alpha=0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57",
   "metadata": {},
   "source": [
    "The mean residual life plots the average excess value over a given threshold, and it should be approcimately linear above the threshold for which the GPD model is valid (e.g. <~3m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mean_residual_life(data.hs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59",
   "metadata": {},
   "source": [
    "The analysis is completed for both Hs and the wind speed, specifying a window of 72 hours and a quantile of 0.98 for determining the threshold to specify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60",
   "metadata": {},
   "outputs": [],
   "source": [
    "quant=0.98\n",
    "models = get_fitted_models(data[[\"hs\",\"wspd\"]],quantile=quant,r=\"72H\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61",
   "metadata": {},
   "outputs": [],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62",
   "metadata": {},
   "outputs": [],
   "source": [
    "models[0].plot_diagnostic(alpha=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63",
   "metadata": {},
   "outputs": [],
   "source": [
    "models[1].plot_diagnostic(alpha=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(get_gpd_parameters(models),columns=[\"mu\",\"sigma\",\"xi\"],index=[\"Hs\",\"Wspd\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_Hs = models[0].get_summary(\n",
    "    return_period=[1, 2, 5, 10, 25, 50, 100],\n",
    "    alpha=0.95,\n",
    "    n_samples=1000,\n",
    ")\n",
    "summary_Wspd = models[1].get_summary(\n",
    "    return_period=[1, 2, 5, 10, 25, 50, 100],\n",
    "    alpha=0.95,\n",
    "    n_samples=1000,\n",
    ")\n",
    "print(summary_Hs)\n",
    "print(summary_Wspd)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

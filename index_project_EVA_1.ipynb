{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Wind turbine project\n",
    "\n",
    "This notebook is a brief example of the possibilities offered by the toolbox for modeling extreme values, adapted from the tools provided from the ResourceCode website.\n",
    "\n",
    "It relies on the `pyextreme` library which get installed with the Resourcecode toolbox. Here we demonstrate 2 examples of univariate modeling as shown in class. For more information, see https://georgebv.github.io/pyextremes/."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "# I. Wave Dynamics\n",
    "\n",
    "## I.A. Characterizing the study site mean wave conditions\n",
    "\n",
    "This notebook covers Part I.A of the wind turbine project: Characterizing the mean wave conditions and seasonal variability at the selected study site. The goal is to analyze long-term hindcast data to understand the typical and seasonal wave climate.\n",
    "\n",
    "---\n",
    "\n",
    "### Import Required Libraries\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pymannkendall as mk\n",
    "from scipy import stats\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from statsmodels.tsa.stattools import acf\n",
    "from pyextremes import (\n",
    "    plot_mean_residual_life,\n",
    "    plot_parameter_stability, \n",
    "    EVA\n",
    ")\n",
    "import resourcecode\n",
    "\n",
    "from resourcecode.eva import (\n",
    "    censgaussfit,\n",
    "    get_fitted_models,\n",
    "    get_gpd_parameters,\n",
    "    run_simulation,\n",
    "    huseby,\n",
    ")\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "os.makedirs('fig', exist_ok=True)\n",
    "plt.savefig('fig/diagnostic_plot_bm.png', dpi=200, bbox_inches='tight')\n",
    "\n",
    "# Enable inline plotting for Jupyter notebooks\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "---\n",
    "### I.A.1. Mean Wave Conditions\n",
    "\n",
    "Please download the variables corresponding to the significant wave height, mean wave period (Tm02), and mean wave direction. Then plot the time series of these variables during the 26-year period from 1994 to 2020, and calculate the mean significant wave height, period, and direction over the entire available time series."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "### Chosen Study Site\n",
    "\n",
    "**Site:** Bretagne Sud 1\n",
    "**Coordinates:** $(47.5882, -3.3215)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = resourcecode.Client()\n",
    "# load the resourcecode dataset from Bretagne Sud 1\n",
    "# find the closest point to the coordinates\n",
    "lat = 47.5882\n",
    "long = -3.3215\n",
    "point_id, dist_m = resourcecode.data.get_closest_point(latitude=lat, longitude=long)\n",
    "print(point_id, dist_m)\n",
    "\n",
    "# get the data from the closest point\n",
    "data = client.get_dataframe_from_criteria(\n",
    "    \"\"\"\n",
    "{\n",
    "    \"node\": 126096,\n",
    "    \"start\": 0,\n",
    "    \"end\": 99999903600,\n",
    "    \"parameter\": [\"hs\",\"t02\",\"dir\",\"uwnd\",\"vwnd\",\"ucur\",\"vcur\",\"dpt\"]\n",
    "}\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "### Data Source\n",
    "\n",
    "The analysis will use long-term (1994-2020) hindcast simulations from the **ResourceCode wave database**.\n",
    "\n",
    "**Variables to download**:\n",
    "* Significant wave height ($H_{m0}$)\n",
    "* Mean wave period ($T_{m02}$)\n",
    "* Mean wave direction\n",
    "* Wind velocity\n",
    "* Current velocity\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Derive only what ResourceCode does not already provide\n",
    "# Assumes your download included: hs, t02, dir, uwnd, vwnd (and optionally ucur, vcur, dpt)\n",
    "\n",
    "# Wind: speed (m/s) and coming-from direction (deg)\n",
    "data[\"wspd\"], data[\"wdir\"] = resourcecode.utils.zmcomp2metconv(data[\"uwnd\"], data[\"vwnd\"])\n",
    "\n",
    "# Currents (optional)\n",
    "if {\"ucur\", \"vcur\"}.issubset(data.columns):\n",
    "    data[\"cspd\"], data[\"cdir\"] = resourcecode.utils.zmcomp2metconv(data[\"ucur\"], data[\"vcur\"])\n",
    "\n",
    "# Waves: use provided mean zero-crossing period\n",
    "if \"t02\" in data.columns:\n",
    "    data[\"Tm02\"] = data[\"t02\"]\n",
    "else:\n",
    "    raise KeyError(\"Missing 't02' in the request. Add 't02' to parameter list.\")\n",
    "\n",
    "# Keep dataset wave direction as-is; document convention once in the notebook.\n",
    "# Do NOT overwrite 'dir' or try to recompute Tm02 from hs/dir.\n",
    "\n",
    "data = data.sort_index()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "### Variables: definitions and units\n",
    "\n",
    "**Core met-ocean time series**\n",
    "\n",
    "| name   | meaning                                   | units |\n",
    "|--------|-------------------------------------------|-------|\n",
    "| `hs`   | significant wave height $H_{m0}=4\\sqrt{m_0}$ | m     |\n",
    "| `t02`  | mean zero-crossing period $T_{m02}=2\\pi\\sqrt{m_0/m_2}$ | s     |\n",
    "| `dir`  | mean wave direction                       | °     |\n",
    "| `spr`  | directional spreading                     | °     |\n",
    "| `fp`   | spectral peak frequency                   | Hz    |\n",
    "| `Tp`   | peak period $=1/fp$                     | s     |\n",
    "| `uwnd` | eastward wind component                   | m·s⁻¹ |\n",
    "| `vwnd` | northward wind component                  | m·s⁻¹ |\n",
    "| `wspd` | wind speed $\\sqrt{uwnd^2+vwnd^2}$       | m·s⁻¹ |\n",
    "| `wdir` | wind direction                            | °     |\n",
    "| `ucur` | eastward surface current                  | m·s⁻¹ |\n",
    "| `vcur` | northward surface current                 | m·s⁻¹ |\n",
    "| `cspd` | current speed $\\sqrt{ucur^2+vcur^2}$    | m·s⁻¹ |\n",
    "| `cdir` | current direction                         | °     |\n",
    "| `dpt`  | water depth                               | m     |\n",
    "\n",
    "**Spectral moments**\n",
    "\n",
    "| name | meaning                               | units  |\n",
    "|------|----------------------------------------|--------|\n",
    "| `m0` | zeroth moment $\\int S(\\omega)\\,d\\omega$ | m²     |\n",
    "| `m1` | first moment $\\int \\omega S(\\omega)\\,d\\omega$ | m²·s⁻¹ |\n",
    "| `m2` | second moment $\\int \\omega^2 S(\\omega)\\,d\\omega$ | m²·s⁻² |\n",
    "\n",
    "**Extreme value analysis (pyextremes)**\n",
    "\n",
    "| item     | meaning                                  |\n",
    "|----------|------------------------------------------|\n",
    "| BM       | block-maxima extraction                  |\n",
    "| POT      | peaks-over-threshold with declustering   |\n",
    "| GEV $\\mu,\\sigma,\\xi$ | location, scale, shape for BM     |\n",
    "| GPD $\\sigma,\\xi$     | scale, shape for POT at a threshold |\n",
    "| `r`      | min time separation between clusters     |\n",
    "| `alpha`  | confidence level for intervals           |\n",
    "| $z_T$  | return level for period $T$ years      |\n",
    "\n",
    "**Direction conventions**\n",
    "\n",
    "All directions are expressed **clockwise from North**.\n",
    "\n",
    "| Variable | Convention | Notes |\n",
    "|-----------|-------------|-------|\n",
    "| `wdir` | *coming-from* | Derived from (`uwnd`, `vwnd`) using `resourcecode.utils.zmcomp2metconv`. |\n",
    "| `dir_from` | *coming-from* | Use if dataset `dir` is *going-to*: convert by `dir_from = (dir + 180) % 360`. |\n",
    "| `cdir_to` | *going-to* | Derived from (`ucur`, `vcur`); use as-is for current flow direction. |\n",
    "| `cdir_from` | *coming-from* (optional) | For comparison with wave/wind directions, compute `cdir_from = (cdir_to + 180) % 360`. |\n",
    "\n",
    "> Always state the convention in figure captions and keep it consistent across the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IA.1 — Mean wave conditions (1994–2020): time series, means, linear trends\n",
    "\n",
    "def circmean_deg(x_deg):\n",
    "    \"\"\"Circular mean of degrees in [0, 360).\"\"\"\n",
    "    x = pd.Series(x_deg).dropna().values\n",
    "    if x.size == 0:\n",
    "        return np.nan\n",
    "    r = np.deg2rad(x)\n",
    "    s = np.sin(r).sum()\n",
    "    c = np.cos(r).sum()\n",
    "    return (np.degrees(np.arctan2(s, c)) + 360.0) % 360.0\n",
    "\n",
    "def verdict(p):\n",
    "    return \"significant\" if p < 0.05 else \"not significant\"\n",
    "\n",
    "# helper\n",
    "def wrap360(a):\n",
    "    return (a % 360.0 + 360.0) % 360.0\n",
    "\n",
    "# Select analysis window\n",
    "start = pd.Timestamp(\"1994-01-01\")\n",
    "end   = pd.Timestamp(\"2020-12-31 23:59:59\")\n",
    "needed = [\"hs\", \"Tm02\", \"dir\"]\n",
    "missing = [v for v in needed if v not in data.columns]\n",
    "if missing:\n",
    "    raise KeyError(f\"Missing variables for IA.1: {missing}\")\n",
    "\n",
    "df = data.loc[start:end, needed].copy()\n",
    "\n",
    "# Monthly means (direction handled circularly)\n",
    "monthly = pd.DataFrame({\n",
    "    \"hs\":   df[\"hs\"].resample(\"M\").mean(),\n",
    "    \"Tm02\": df[\"Tm02\"].resample(\"M\").mean(),\n",
    "})\n",
    "monthly[\"dir\"] = df[\"dir\"].resample(\"M\").apply(circmean_deg)\n",
    "\n",
    "# Overall means (direction: circular mean)\n",
    "mean_hs   = df[\"hs\"].mean()\n",
    "mean_tm02 = df[\"Tm02\"].mean()\n",
    "mean_dir  = circmean_deg(df[\"dir\"])\n",
    "\n",
    "# Linear trends on monthly means\n",
    "t_years = (monthly.index - monthly.index[0]).days / 365.2425\n",
    "\n",
    "# Hs trend\n",
    "hs_ok = monthly[\"hs\"].dropna()\n",
    "t_hs = t_years[hs_ok.index.get_indexer(hs_ok.index)]\n",
    "hs_reg = stats.linregress(t_hs, hs_ok.values)\n",
    "hs_slope_dec = hs_reg.slope * 10.0      # m per decade\n",
    "hs_delta_30  = hs_reg.slope * 30.0      # m over 30 years\n",
    "\n",
    "# Tm02 trend\n",
    "tm_ok = monthly[\"Tm02\"].dropna()\n",
    "t_tm = t_years[tm_ok.index.get_indexer(tm_ok.index)]\n",
    "tm_reg = stats.linregress(t_tm, tm_ok.values)\n",
    "tm_slope_dec = tm_reg.slope * 10.0      # s per decade\n",
    "tm_delta_30  = tm_reg.slope * 30.0      # s over 30 years\n",
    "\n",
    "# Direction trend: unwrap, regress, report slope in deg/dec\n",
    "dir_ok = monthly[\"dir\"].dropna()\n",
    "t_dir = t_years[dir_ok.index.get_indexer(dir_ok.index)]\n",
    "dir_unwrap = np.degrees(np.unwrap(np.deg2rad(dir_ok.values)))\n",
    "dir_reg = stats.linregress(t_dir, dir_unwrap)\n",
    "dir_slope_dec = dir_reg.slope * 10.0    # deg per decade\n",
    "dir_delta_30  = dir_reg.slope * 30.0    # deg over 30 years\n",
    "\n",
    "# Plot monthly series (1994–2020)\n",
    "fig, axes = plt.subplots(3, 1, figsize=(12, 9), sharex=True)\n",
    "\n",
    "# Hs with fitted line\n",
    "axes[0].plot(monthly.index, monthly[\"hs\"], lw=0.8)\n",
    "yhat_hs = hs_reg.intercept + hs_reg.slope * t_years\n",
    "axes[0].plot(monthly.index, yhat_hs, lw=1.2)\n",
    "axes[0].set_ylabel(\"Hs (m)\")\n",
    "axes[0].grid(alpha=0.3)\n",
    "axes[0].set_title(f\"Hs monthly mean | {hs_slope_dec:.3f} m/dec, p={hs_reg.pvalue:.3f} ({verdict(hs_reg.pvalue)})\")\n",
    "\n",
    "# Tm02 with fitted line\n",
    "axes[1].plot(monthly.index, monthly[\"Tm02\"], lw=0.8)\n",
    "yhat_tm = tm_reg.intercept + tm_reg.slope * t_years\n",
    "axes[1].plot(monthly.index, yhat_tm, lw=1.2)\n",
    "axes[1].set_ylabel(\"Tm02 (s)\")\n",
    "axes[1].grid(alpha=0.3)\n",
    "axes[1].set_title(f\"Tm02 monthly mean | {tm_slope_dec:.3f} s/dec, p={tm_reg.pvalue:.3f} ({verdict(tm_reg.pvalue)})\")\n",
    "\n",
    "# Direction (circular monthly mean) with fitted line\n",
    "axes[2].plot(monthly.index, monthly[\"dir\"], lw=0.8)\n",
    "yhat_dir_unwrap = dir_reg.intercept + dir_reg.slope * t_years\n",
    "yhat_dir = wrap360(yhat_dir_unwrap)\n",
    "axes[2].plot(monthly.index, yhat_dir, lw=1.2)  # add fit\n",
    "axes[2].set_ylabel(\"Dir (deg, coming-from)\")\n",
    "axes[2].grid(alpha=0.3)\n",
    "axes[2].set_title(\n",
    "    f\"Direction monthly circular mean | {dir_slope_dec:.2f}°/dec, \"\n",
    "    f\"p={dir_reg.pvalue:.3f} ({verdict(dir_reg.pvalue)})\"\n",
    ")\n",
    "axes[2].set_xlabel(\"Year\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"fig/IA1_mean_wave_conditions_timeseries.png\", dpi=200, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "# Printed summary for the report\n",
    "print(\"IA.1 — Mean conditions over 1994–2020\")\n",
    "print(f\"  Mean Hs   : {mean_hs:.3f} m\")\n",
    "print(f\"  Mean Tm02 : {mean_tm02:.3f} s\")\n",
    "print(f\"  Mean Dir  : {mean_dir:.1f}° (coming-from)\")\n",
    "\n",
    "print(\"\\nLinear trends on monthly means (least squares):\")\n",
    "print(f\"  Hs   : {hs_slope_dec:.3f} m/dec  (p={hs_reg.pvalue:.3f}, n={hs_ok.size}), Δ30y={hs_delta_30:.3f} m\")\n",
    "print(f\"  Tm02 : {tm_slope_dec:.3f} s/dec  (p={tm_reg.pvalue:.3f}, n={tm_ok.size}), Δ30y={tm_delta_30:.3f} s\")\n",
    "print(f\"  Dir  : {dir_slope_dec:.2f} °/dec (p={dir_reg.pvalue:.3f}, n={dir_ok.size}), Δ30y={dir_delta_30:.2f} °\")\n",
    "\n",
    "print(\"\\nInterpretation rule-of-thumb: treat p<0.05 as evidence of a trend. Use Δ30y to state expected change over a turbine lifetime.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_yearly = data.resample('Y').mean()\n",
    "result_hs  = mk.original_test(hs_ok.values, alpha=0.05)\n",
    "result_period = mk.original_test(tm_ok.values, alpha=0.050)\n",
    "result_direction = mk.original_test(dir_ok.values, alpha=0.05)\n",
    "\n",
    "print(\"\\nResults for Significant Wave Height (Hs):\")\n",
    "print(f\"  Trend: {result_hs.trend}\")\n",
    "print(f\"  H (Test Statistic): {result_hs.h}\")\n",
    "print(f\"  P-value: {result_hs.p:.4f}\")\n",
    "print(f\"  Z-Score: {result_hs.z:.4f}\")\n",
    "print(f\"  Tau: {result_hs.Tau:.4f}\")\n",
    "print(f\"  Sen's Slope: {result_hs.slope:.4f}\")\n",
    "print(f\"  Intercept: {result_hs.intercept:.4f}\")\n",
    "\n",
    "print(\"\\nResults for Wave Period (Tm02):\")\n",
    "print(f\"  Trend: {result_period.trend}\")\n",
    "print(f\"  H (Test Statistic): {result_period.h}\")\n",
    "print(f\"  P-value: {result_period.p:.4f}\")\n",
    "print(f\"  Z-Score: {result_period.z:.4f}\")\n",
    "print(f\"  Tau: {result_period.Tau:.4f}\")\n",
    "print(f\"  Sen's Slope: {result_period.slope:.4f}\")\n",
    "print(f\"  Intercept: {result_period.intercept:.4f}\")\n",
    "\n",
    "print(\"\\nResults for Wave Direction:\")\n",
    "print(f\"  Trend: {result_direction.trend}\")\n",
    "print(f\"  H (Test Statistic): {result_direction.h}\")\n",
    "print(f\"  P-value: {result_direction.p:.4f}\")\n",
    "print(f\"  Z-Score: {result_direction.z:.4f}\")\n",
    "print(f\"  Tau: {result_direction.Tau:.4f}\")\n",
    "print(f\"  Sen's Slope: {result_direction.slope:.4f}\")\n",
    "print(f\"  Intercept: {result_direction.intercept:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "**Q: Do any trends in the wave height, period, or direction exist over the 26 year time period? Do you expect there to be changes in the mean conditions during the 30-year lifetime of the wind turbine? If so, why?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "**Answer:** No statistically significant trends were detected in wave height ($H_s$), period ($T_{m02}$), or direction using either Ordinary Least Squares (OLS) or the Mann-Kendall (MK) test on monthly mean data. Expected 30-year changes in mean conditions appear negligible relative to natural variability.\n",
    "\n",
    "---\n",
    "### Mean Conditions and Trend Analysis (1994–2020)\n",
    "\n",
    "**Mean conditions**\n",
    "-   $\\overline{H_s} = 1.273\\ \\text{m}$\n",
    "-   $\\overline{T_{m02}} = 4.573\\ \\text{s}$\n",
    "-   Mean direction $= 244.7^\\circ$ (coming from WSW)\n",
    "\n",
    "---\n",
    "**Trend Analysis Methods**\n",
    "-   Aggregate hourly data to monthly means to reduce noise while retaining seasonal information influence.\n",
    "-   **Method 1: Ordinary Least Squares (OLS)**: Perform regression vs time in years. Direction handled with circular monthly mean, then unwrapped.\n",
    "-   **Method 2: Mann-Kendall (MK) Test**: Apply the non-parametric test to detect monotonic trends in the monthly mean time series.\n",
    "-   Significance for both methods assessed at $\\alpha=0.05$.\n",
    "\n",
    "---\n",
    "**OLS Results** (slope per decade; $\\Delta 30\\text{y}$ is implied 30-year change)\n",
    "-   $H_s$: $-0.005\\ \\text{m/dec}$, $p=0.894$, $\\Delta 30\\text{y}=-0.014\\ \\text{m}$. (No significant trend)\n",
    "-   $T_{m02}$: $+0.054\\ \\text{s/dec}$, $p=0.307$, $\\Delta 30\\text{y}=+0.163\\ \\text{s}$. (No significant trend)\n",
    "-   Direction: $+0.73^\\circ/\\text{dec}$, $p=0.384$, $\\Delta 30\\text{y}=+2.20^\\circ$. (No significant trend)\n",
    "\n",
    "---\n",
    "**MK Results (on Monthly Means)**\n",
    "-   $H_s$: $p=0.8114$. (No significant trend) Sen's Slope $\\approx -0.0001$ m/month ($\\approx -0.012$ m/decade).\n",
    "-   $T_{m02}$: $p=0.4926$. (No significant trend) Sen's Slope $\\approx +0.0003$ s/month ($\\approx +0.036$ s/decade).\n",
    "-   Direction: $p=0.4849$. (No significant trend) Sen's Slope $\\approx +0.0045$ deg/month ($\\approx +0.54$ deg/decade).\n",
    "\n",
    "*(Note: Sen's slopes converted approximately from per-month to per-decade for comparison with OLS results)*\n",
    "\n",
    "---\n",
    "**Interpretation**\n",
    "-   Both OLS and Mann-Kendall analyses performed on monthly mean data consistently indicate no statistically significant secular trends in mean $H_s$, $T_{m02}$, or direction over the 1994–2020 period.\n",
    "-   The magnitudes of the calculated slopes (both OLS and Sen's slope) are very small, suggesting that any potential underlying linear or monotonic change over the 26 years is minimal compared to the observed variability.\n",
    "-   Expected 30-year changes based on these negligible trends are small compared to the substantial seasonal and interannual variability present in the data.\n",
    "-   For design purposes over the next 30 years, emphasis should likely remain on characterizing the existing variability (seasonal, interannual) and extreme conditions rather than adjusting significantly for potential drifts in mean conditions.\n",
    "\n",
    "---\n",
    "*Figure:* `fig/IA1_mean_wave_conditions_timeseries.png`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "### I.A.2. Most Common Wave Conditions\n",
    "\n",
    "To identify the most common operating conditions, we will create a 2D histogram (scatter diagram) of significant wave height ($H_{m0}$) versus mean wave period ($T_{m02}$). We will also plot a wave rose to identify the most common wave incidence direction(s).\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "plt.hist2d(data['hs'], data['t02'], bins=100, cmap='plasma', density=True)\n",
    "plt.colorbar(label='Density')\n",
    "plt.xlabel('Significant Wave Height $H_s$ [m]')\n",
    "plt.ylabel('Mean Wave Period $T_{m02}$ [s]')\n",
    "plt.title('Wave Height vs Period Density Plot')\n",
    "plt.savefig('graphs/wave_height_period_density.png')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "**Q: What is the water depth at this location? Indicate on the histrogram for what wave conditions the waves are considered deep water waves? linear waves?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data['dpt'].std())\n",
    "\n",
    "mean_water_depth = data['dpt'].mean()\n",
    "print(f'mean water depth at location (lat, long) = ({lat}, {long}) is {mean_water_depth:.2f} m')\n",
    "\n",
    "# Calculating wave length using the linear wave theory\n",
    "# wave length = g * T^2 / (2 * pi)\n",
    "g = 9.81 # m/s^2\n",
    "wave_length = g * (data['t02']**2) / (2 * np.pi)\n",
    "water_depth = data['dpt']\n",
    "\n",
    "# check condition for deep water waves\n",
    "deep_water_length_condition = 2 * mean_water_depth\n",
    "transition_water_length_condition = 25 * mean_water_depth\n",
    "\n",
    "deep_water_condition = wave_length < deep_water_length_condition\n",
    "# calculate the percentage of deep water waves\n",
    "deep_water_percentage = deep_water_condition.mean()\n",
    "print(f'percentage of deep water waves: {deep_water_percentage:.2%}')\n",
    "\n",
    "# Compute corresponding period for deep water waves\n",
    "deep_water_period_condition = 4 * np.sqrt(mean_water_depth / g)\n",
    "transition_water_period_condition = 25 * np.sqrt(mean_water_depth / g)\n",
    "\n",
    "print(f'deep water period: {deep_water_period_condition:.2f} s')\n",
    "# check condition for linear waves\n",
    "#linear_waves_condition = wave_length > 20 * mean_water_depth\n",
    "\n",
    "### plot the wave length distribution ###\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Corrected plt.hist call: remove wave_length.count\n",
    "plt.hist(wave_length, bins=50, density=True, alpha=0.7, label='Wave Length Distribution')\n",
    "\n",
    "# Add the threshold line (assuming L < 2h for deep water)\n",
    "plt.axvline(x=deep_water_length_condition, color='r', linestyle='--',\n",
    "            label=f'Deep Water Threshold (L < {deep_water_length_condition:.1f}m)')\n",
    "plt.axvline(x=transition_water_length_condition, color='g', linestyle='--',\n",
    "            label=f'Upper Transition Threshold to Linear Waves (L < {transition_water_length_condition:.1f}m)')\n",
    "plt.xlabel('Wave Length (m)')\n",
    "plt.ylabel('Density') # Changed label to Density since density=True\n",
    "plt.title('Wave Length Distribution')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "plt.close() # Close after showing\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "### plot the wave period distribution ###\n",
    "plt.hist(data['t02'], bins=50, density=True, alpha=0.7, label='Wave Length Distribution')\n",
    "\n",
    "# Add the threshold line (assuming L < 2h for deep water)\n",
    "plt.axvline(x=deep_water_period_condition, color='r', linestyle='--',\n",
    "            label=f'Deep Water Threshold (T < {deep_water_period_condition:.1f}s)')\n",
    "plt.axvline(x=transition_water_period_condition, color='g', linestyle='--',\n",
    "            label=f'Transition to Linear Waves (T < {transition_water_period_condition:.1f}s)')\n",
    "plt.xlabel('Wave Length (m)')\n",
    "plt.xscale('log')\n",
    "plt.ylabel('Density') # Changed label to Density since density=True\n",
    "plt.title('Wave Length Distribution')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# --- 6. Result Summary ---\n",
    "print(\"\\n--- Result Summary ---\")\n",
    "print(f\"Analysis based on Mean Depth h = {mean_water_depth:.2f} m\")\n",
    "\n",
    "print(\"\\nThresholds:\")\n",
    "print(f\"  Deep Water:     L < {deep_water_length_condition:.1f} m   |   T < {deep_water_period_condition:.2f} s\")\n",
    "print(f\"  Intersection of Deep and Shallow Water:  L > {transition_water_length_condition:.1f} m  |   T > {transition_water_period_condition:.2f} s\")\n",
    "\n",
    "# Compute the percentage of deep water waves based on the approximate wavelength\n",
    "is_deep_water_wave = wave_length < deep_water_length_condition\n",
    "is_transition_zone_wave = (\n",
    "    (deep_water_length_condition < wave_length) &\n",
    "    (wave_length < transition_water_length_condition)\n",
    ")\n",
    "\n",
    "is_deep_water_period = data['t02'] < deep_water_period_condition\n",
    "is_transition_zone_period = (\n",
    "    (deep_water_period_condition < data['t02']) &\n",
    "    (data['t02'] < transition_water_period_condition)\n",
    ")\n",
    "# get a percentage of the boolean series of true and false\n",
    "deep_water_percentage_L_approx = is_deep_water_wave.mean()\n",
    "transition_percentage_L_approx = is_transition_zone_wave.mean()\n",
    "deep_water_percentage_T_approx = is_deep_water_period.mean()\n",
    "transition_percentage_T_approx = is_transition_zone_period.mean()\n",
    "\n",
    "print(\"\\nClassification based on Approximate Wavelength (L_approx = gT² / 2π):\")\n",
    "print(f\"  Percentage Deep Water Wave Lenghts: {deep_water_percentage_L_approx:.2%}\")\n",
    "print(f\"  Percentage Transition Zone Wave Lenghts: {transition_percentage_L_approx:.2%}\")\n",
    "\n",
    "# Characterizing the transition band for T\n",
    "print\n",
    "print(\"\\nClassification based on Approximate Wavelength (L_approx = gT² / 2π):\")\n",
    "print(f\"  Percentage Deep Water Wave Periods: {deep_water_percentage_T_approx:.2%}\")\n",
    "print(f\"  Percentage Transition Zone Wave Periods: {transition_percentage_T_approx:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "### Wave Regime Classification\n",
    "\n",
    "**Method**\n",
    "-   The wave conditions represented by the hourly significant wave height ($H_s$) and mean period ($T_{m02}$) were classified into deep, transitional, and shallow water regimes.\n",
    "-   Classification was based on standard non-dimensional criteria involving water depth ($h$), wavelength ($L$), and period ($T$).\n",
    "-   A **mean water depth of $h = 31.50$ m** was used for calculating the thresholds. This simplification is justified by the low standard deviation observed in the depth data ($\\sigma_h = 1.2$ m), indicating relatively consistent depth at the site.\n",
    "-   Wavelength ($L_{approx}$) was estimated using the deep water approximation $L_{approx} = gT_{m02}^2 / (2\\pi)$ for initial classification.\n",
    "-   Classification was also performed directly using the period $T_{m02}$.\n",
    "\n",
    "---\n",
    "**Thresholds** (based on $h = 31.50$ m)\n",
    "-   **Deep Water:** $h/L > 1/2 \\implies L < 63.0$ m; or $T\\sqrt{g/h} < 4 \\implies T < 7.17$ s.\n",
    "-   **Shallow Water:** $h/L < 1/25 \\implies L > 787.6$ m; or $T\\sqrt{g/h} > 25 \\implies T > 44.80$ s.\n",
    "-   **Transition Zone:** Conditions falling between the deep and shallow water limits.\n",
    "\n",
    "---\n",
    "**Results**\n",
    "-   Using the **period-based classification ($T_{m02}$)**:\n",
    "    -   Deep Water ($T < 7.17$ s): **93.71%**\n",
    "    -   Transition Zone ($7.17 \\text{ s} \\le T \\le 44.81$ s): **6.29%**\n",
    "    -   Shallow Water ($T > 44.81$ s): **0.00%**\n",
    "-   Using the **approximate wavelength classification ($L_{approx}$)**:\n",
    "    -   Deep Water ($L_{approx} < 63.0$ m): **86.70%**\n",
    "    -   Transition Zone ($63.0 \\text{ m} \\le L_{approx} \\le 630.0$ m): **13.30%**\n",
    "    -   Shallow Water ($L_{approx} > 630.0$ m): **0.00%**\n",
    "\n",
    "---\n",
    "**Interpretation**\n",
    "-   The vast majority of wave conditions at this site fall within the **deep water regime** based on both period and approximate wavelength classifications, although the period-based method indicates a higher percentage.\n",
    "-   A smaller fraction (6-13%) operates within the **transition zone**.\n",
    "-   **Shallow water conditions are negligible** according to these criteria and the dataset.\n",
    "-   The difference between the period and approximate wavelength classifications highlights the limitation of using the deep water formula ($L_{approx}$) for all conditions; the period-based classification using $T\\sqrt{g/h}$ is more direct."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "### I.A.3. Seasonal Variability\n",
    "\n",
    "Next, we will evaluate temporal variability by calculating and plotting the mean wave height, period, and direction as a function of the month of the year (e.g., mean for January, February, etc.).\n",
    "\n",
    "**Data and method.** Hourly hindcast at $(47.5882^\\circ\\ \\mathrm{N},\\ 3.3215^\\circ\\ \\mathrm{W})$. Monthly climatology across all years.  \n",
    "- Height and period: arithmetic mean with interquartile range (IQR).  \n",
    "- Direction: circular mean with circular standard deviation, expressed as *coming-from* degrees.  \n",
    "- Angles unwrapped around the overall mean for continuity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- IA.3 Seasonal variability: monthly climatology of Hs, Tm02, and direction (mean ± IQR) ---\n",
    "\n",
    "# inputs\n",
    "start = pd.Timestamp(\"1994-01-01\")\n",
    "end   = pd.Timestamp(\"2020-12-31 23:59:59\")\n",
    "need  = {\"hs\", \"Tm02\", \"dir\"}\n",
    "if not need.issubset(data.columns):\n",
    "    raise KeyError(f\"IA.3 needs columns {sorted(need)} in `data`.\")\n",
    "\n",
    "df3 = data.loc[start:end, [\"hs\", \"Tm02\", \"dir\"]].copy()\n",
    "if not isinstance(df3.index, pd.DatetimeIndex):\n",
    "    raise TypeError(\"`data` index must be a DatetimeIndex.\")\n",
    "\n",
    "# group by calendar month across all years\n",
    "g = df3.groupby(df3.index.month)  # 1..12\n",
    "\n",
    "# numeric climatology for Hs and Tm02\n",
    "hs_mean = g[\"hs\"].mean()\n",
    "hs_q25  = g[\"hs\"].quantile(0.25)\n",
    "hs_q75  = g[\"hs\"].quantile(0.75)\n",
    "\n",
    "tm_mean = g[\"Tm02\"].mean()\n",
    "tm_q25  = g[\"Tm02\"].quantile(0.25)\n",
    "tm_q75  = g[\"Tm02\"].quantile(0.75)\n",
    "\n",
    "n_samples = g.size()\n",
    "\n",
    "# circular climatology for direction (vectorised; stable across pandas versions)\n",
    "dd = df3[[\"dir\"]].copy()\n",
    "m = dd[\"dir\"].notna()\n",
    "dd.loc[m, \"sin\"] = np.sin(np.deg2rad(dd.loc[m, \"dir\"]))\n",
    "dd.loc[m, \"cos\"] = np.cos(np.deg2rad(dd.loc[m, \"dir\"]))\n",
    "\n",
    "dg = dd.groupby(dd.index.month)\n",
    "sin_mean = dg[\"sin\"].mean()\n",
    "cos_mean = dg[\"cos\"].mean()\n",
    "n_dir    = dg[\"dir\"].count()\n",
    "\n",
    "R = np.hypot(sin_mean, cos_mean)                                  # mean resultant length\n",
    "dir_mean = (np.degrees(np.arctan2(sin_mean, cos_mean)) + 360) % 360\n",
    "dir_cstd = np.degrees(np.sqrt(np.maximum(0.0, -2.0 * np.log(np.clip(R, 1e-12, 1.0)))))  # circular std (deg)\n",
    "\n",
    "# unwrap monthly direction around overall circular mean to avoid 0/360 jump\n",
    "sin_all = np.sin(np.deg2rad(df3[\"dir\"].dropna())).mean()\n",
    "cos_all = np.cos(np.deg2rad(df3[\"dir\"].dropna())).mean()\n",
    "overall_dir = (np.degrees(np.arctan2(sin_all, cos_all)) + 360) % 360\n",
    "dir_mean_unwrapped = overall_dir + ((dir_mean - overall_dir + 540.0) % 360.0 - 180.0)\n",
    "\n",
    "# assemble single DataFrame and ensure months 1..12 exist and in order\n",
    "clim = pd.DataFrame({\n",
    "    \"hs_mean\": hs_mean,\n",
    "    \"hs_q25\":  hs_q25,\n",
    "    \"hs_q75\":  hs_q75,\n",
    "    \"Tm02_mean\": tm_mean,\n",
    "    \"Tm02_q25\":  tm_q25,\n",
    "    \"Tm02_q75\":  tm_q75,\n",
    "    \"N_samples\": n_samples,\n",
    "    \"dir_mean\": dir_mean,\n",
    "    \"R\": R,\n",
    "    \"dir_cstd\": dir_cstd,\n",
    "    \"n_dir\": n_dir,\n",
    "    \"dir_mean_unwrapped\": dir_mean_unwrapped,\n",
    "}).reindex(range(1, 13))\n",
    "clim.index.name = \"month\"\n",
    "clim[\"month_name\"] = pd.to_datetime(clim.index, format=\"%m\").month_name().str.slice(0, 3)\n",
    "\n",
    "# save numeric table\n",
    "clim.to_csv(\"fig/IA3_seasonal_climatology.csv\", float_format=\"%.3f\")\n",
    "\n",
    "# plot\n",
    "fig, axes = plt.subplots(3, 1, figsize=(12, 9), sharex=True)\n",
    "x = np.arange(1, 13)\n",
    "labels = clim[\"month_name\"].values\n",
    "\n",
    "# Hs: mean ± IQR\n",
    "ax = axes[0]\n",
    "ax.plot(x, clim[\"hs_mean\"].values, lw=1.8)\n",
    "ax.fill_between(x, clim[\"hs_q25\"].values, clim[\"hs_q75\"].values, alpha=0.25)\n",
    "ax.set_ylabel(\"Hs (m)\")\n",
    "ax.grid(alpha=0.3)\n",
    "ax.set_title(\"Monthly climatology: Hs (mean ± IQR)\")\n",
    "\n",
    "# Tm02: mean ± IQR\n",
    "ax = axes[1]\n",
    "ax.plot(x, clim[\"Tm02_mean\"].values, lw=1.8)\n",
    "ax.fill_between(x, clim[\"Tm02_q25\"].values, clim[\"Tm02_q75\"].values, alpha=0.25)\n",
    "ax.set_ylabel(\"Tm02 (s)\")\n",
    "ax.grid(alpha=0.3)\n",
    "ax.set_title(\"Monthly climatology: Tm02 (mean ± IQR)\")\n",
    "\n",
    "# Direction: circular mean ± circular std (unwrapped for continuity)\n",
    "ax = axes[2]\n",
    "y = clim[\"dir_mean_unwrapped\"].values\n",
    "yerr = clim[\"dir_cstd\"].values\n",
    "ax.errorbar(x, y, yerr=yerr, fmt=\"-o\", lw=1.5, capsize=3)\n",
    "pad = 5.0\n",
    "ymin, ymax = np.nanmin(y - yerr), np.nanmax(y + yerr)\n",
    "ax.set_ylim(ymin - pad, ymax + pad)\n",
    "ax.set_ylabel(\"Direction (deg, coming-from)\")\n",
    "ax.grid(alpha=0.3)\n",
    "ax.set_title(\"Monthly climatology: wave direction (circular mean ± circular std)\")\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"fig/IA3_seasonal_climatology.png\", dpi=200, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "# quick textual summary\n",
    "hs_max_mo = int(clim[\"hs_mean\"].idxmax())\n",
    "hs_min_mo = int(clim[\"hs_mean\"].idxmin())\n",
    "tm_max_mo = int(clim[\"Tm02_mean\"].idxmax())\n",
    "tm_min_mo = int(clim[\"Tm02_mean\"].idxmin())\n",
    "print(\"IA.3 — Seasonal climatology (1994–2020)\")\n",
    "print(f\"  Hs peaks in {pd.to_datetime(hs_max_mo, format='%m').month_name()} \"\n",
    "      f\"and is lowest in {pd.to_datetime(hs_min_mo, format='%m').month_name()}.\")\n",
    "print(f\"  Tm02 peaks in {pd.to_datetime(tm_max_mo, format='%m').month_name()} \"\n",
    "      f\"and is lowest in {pd.to_datetime(tm_min_mo, format='%m').month_name()}.\")\n",
    "print(f\"  Direction mean (overall) ≈ {overall_dir:.1f}° (coming-from).\")\n",
    "print(\"  Saved: fig/IA3_seasonal_climatology.png and fig/IA3_seasonal_climatology.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "\n",
    "**Q: Do you observe any seasonal trends in wave height, period, or direction? If so, why?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "### Results\n",
    "\n",
    "**Significant wave height, $H_s$.** Clear winter maximum and summer minimum. IQR widens in winter and narrows in summer.  \n",
    "**Interpretation.** Boreal-winter extratropical cyclones increase wind speed and fetch over the open North Atlantic, augmenting wind-sea and incoming swell towards south Brittany. Summer conditions are dominated by weaker winds and shorter fetch, so mean $H_s$ decreases and variability contracts. Because wave energy density scales as\n",
    "$$\n",
    "E=\\tfrac{1}{8}\\,\\rho g\\,H_s^2,\n",
    "$$\n",
    "higher winter $H_s$ implies markedly greater wave energy arriving at the site.\n",
    "\n",
    "**Mean zero-crossing period, $T_{m02}$.** Co-varies with $H_s$: longer in winter, shorter in summer.  \n",
    "**Interpretation.** Winter storms generate longer-period swell over long fetches. Deep-water dispersion $\\big(L\\approx gT^2/2\\pi,\\ c_g \\approx gT/4\\pi\\big)$ favours the far-field propagation of longer-period energy into the Bay of Biscay. In summer, local wind-sea contribution increases and typical periods shorten.\n",
    "\n",
    "### Wave direction (coming-from, clockwise from North)\n",
    "\n",
    "**Convention.** $0^\\circ=\\mathrm{N},\\ 90^\\circ=\\mathrm{E},\\ 180^\\circ=\\mathrm{S},\\ 270^\\circ=\\mathrm{W}$.\n",
    "\n",
    "**Seasonal pattern.** The monthly circular mean increases from winter ($\\sim 240^\\circ$) to summer ($\\sim 255^\\circ$), then decreases again in autumn.\n",
    "\n",
    "**Interpretation** Larger angles imply a more westerly approach. Thus, waves are slightly more **W–WSW** in summer and shift a little toward **SW** in winter.\n",
    "\n",
    "**Regional context.** Along the southern Brittany–Bay of Biscay sector, the summer expansion of the Azores High favours a more zonal (westerly) approach at the shelf break. In winter, frequent lows entering the Bay introduce a modest southerly component in the incident swell, yielding the observed decrease in direction angle.\n",
    "\n",
    "**Dispersion note.** The vertical bars are circular standard deviations (spread of hourly directions), not standard errors. They are of similar magnitude across months, so the dataset does **not** support a strong seasonal change in directional spread.\n",
    "\n",
    "## Implications\n",
    "\n",
    "- **Operations.** Highest loads and sea states occur in winter months; scheduling for installation or maintenance is more feasible in late spring–summer.  \n",
    "- **Variability.** Broad winter IQRs indicate stronger interannual modulation of sea states; design and planning should not rely on a single “typical” winter value.  \n",
    "- **Directionality.** The prevailing W–WSW approach is stable enough to justify directional binning around that sector for further analyses and for extreme value modelling in Part II.\n",
    "\n",
    "## Notes and caveats\n",
    "\n",
    "- Monthly means smooth synoptic extremes; use EVA for design loads.  \n",
    "- Direction statistics use circular metrics; reported means reflect modal approach rather than arithmetic averages near $0/360^\\circ$.  \n",
    "- The site is predominantly deep water, so seasonal patterns reflect atmospheric forcing and basin geometry rather than depth-limited effects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "### I.A.4. Mean Wind and Current Conditions\n",
    "\n",
    "We will also evaluate the wind and current conditions by plotting rose diagrams of their respective velocities and directions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- IA.4 Mean wind and current conditions: roses + means (overall, seasonal) ---\n",
    "# -----------------------\n",
    "# Config\n",
    "# -----------------------\n",
    "# Calm thresholds used for ROSES only (kept in means table for reference)\n",
    "CALM_WIND = 0.5    # m/s\n",
    "CALM_CURR = 0.05   # m/s\n",
    "\n",
    "# Speed bins\n",
    "# Wind: [0.5–2), 2–4, 4–6, …, ≥16 m/s\n",
    "WIND_BINS = np.r_[0.5, np.arange(2, 18, 2), np.inf]\n",
    "# Currents: [0.05–0.1), 0.1–0.2, 0.2–0.3, 0.3–0.5, ≥0.5 m/s\n",
    "CURR_BINS = np.array([0.05, 0.07, 0.09, 0.11, 0.13, np.inf])\n",
    "\n",
    "# Direction sectors\n",
    "WIND_SECTORS = 16   # 22.5°\n",
    "CURR_SECTORS = 36   # 10°\n",
    "\n",
    "# Date window to match the project\n",
    "start = pd.Timestamp(\"1994-01-01\")\n",
    "end   = pd.Timestamp(\"2020-12-31 23:59:59\")\n",
    "\n",
    "# -----------------------\n",
    "# Helpers\n",
    "# -----------------------\n",
    "def circmean_deg(x_deg):\n",
    "    \"\"\"Circular mean in degrees [0, 360).\"\"\"\n",
    "    x = pd.Series(x_deg).dropna().values\n",
    "    if x.size == 0:\n",
    "        return np.nan\n",
    "    r = np.deg2rad(x)\n",
    "    s = np.sin(r).sum()\n",
    "    c = np.cos(r).sum()\n",
    "    return (np.degrees(np.arctan2(s, c)) + 360.0) % 360.0\n",
    "\n",
    "def season_label(month):\n",
    "    # DJF, MAM, JJA, SON\n",
    "    if month in (12, 1, 2): return \"DJF\"\n",
    "    if month in (3, 4, 5):  return \"MAM\"\n",
    "    if month in (6, 7, 8):  return \"JJA\"\n",
    "    return \"SON\"\n",
    "\n",
    "def rose_counts(dir_deg, spd, spd_bins, sectors=16, calm_thresh=0.0):\n",
    "    \"\"\"\n",
    "    Return stacked counts per direction sector and speed bin, plus metadata.\n",
    "    Directions: degrees, 0°=N, clockwise positive.\n",
    "    Excludes values with spd <= calm_thresh.\n",
    "    \"\"\"\n",
    "    mask = np.isfinite(dir_deg) & np.isfinite(spd) & (spd > calm_thresh)\n",
    "    d = np.asarray(dir_deg)[mask] % 360.0\n",
    "    s = np.asarray(spd)[mask]\n",
    "\n",
    "    if d.size == 0:\n",
    "        counts = np.zeros((sectors, len(spd_bins)-1), dtype=int)\n",
    "        return counts, np.array([]), 0\n",
    "\n",
    "    width = 360.0 / sectors\n",
    "    sector_idx = np.floor(d / width).astype(int)\n",
    "    sector_idx[sector_idx == sectors] = sectors - 1\n",
    "\n",
    "    bin_idx = np.digitize(s, spd_bins) - 1\n",
    "    bin_idx = np.clip(bin_idx, 0, len(spd_bins)-2)\n",
    "\n",
    "    counts = np.zeros((sectors, len(spd_bins)-1), dtype=int)\n",
    "    for k in range(d.size):\n",
    "        counts[sector_idx[k], bin_idx[k]] += 1\n",
    "\n",
    "    return counts, mask, d.size  # d.size = included samples after calm filter\n",
    "\n",
    "def plot_rose(dir_deg, spd, spd_bins, fname, title, calm_thresh=0.0, sectors=16):\n",
    "    \"\"\"\n",
    "    Polar stacked-bar rose. Heights are percentages of included samples.\n",
    "    Direction convention: 0° at North, clockwise positive.\n",
    "    \"\"\"\n",
    "    counts, mask, n_used = rose_counts(dir_deg, spd, spd_bins, sectors, calm_thresh)\n",
    "    if n_used == 0:\n",
    "        print(f\"{title}: no data above calm threshold.\")\n",
    "        return\n",
    "\n",
    "    sector_totals = counts.sum(axis=1).astype(float)\n",
    "    sector_totals[sector_totals == 0] = 1.0\n",
    "    frac = counts / sector_totals[:, None]\n",
    "    pct_sector = 100.0 * counts.sum(axis=1) / n_used\n",
    "\n",
    "    theta = np.deg2rad(np.arange(0, 360, 360/sectors))\n",
    "    width = 2.0 * np.pi / sectors\n",
    "\n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "    ax = plt.subplot(111, polar=True)\n",
    "    ax.set_theta_zero_location(\"N\")\n",
    "    ax.set_theta_direction(-1)\n",
    "\n",
    "    bottoms = np.zeros(sectors)\n",
    "    labels = []\n",
    "    for j in range(len(spd_bins)-1):\n",
    "        label = f\"{spd_bins[j]:g}–{spd_bins[j+1]:g} m/s\" if np.isfinite(spd_bins[j+1]) else f\"{spd_bins[j]:g}+ m/s\"\n",
    "        labels.append(label)\n",
    "        heights = pct_sector * frac[:, j]\n",
    "        ax.bar(theta, heights, width=width, bottom=bottoms, align=\"edge\",\n",
    "               edgecolor=\"black\", linewidth=0.3)\n",
    "        bottoms += heights\n",
    "\n",
    "    ax.set_rlabel_position(225)\n",
    "    rmax = max(5.0, np.ceil(bottoms.max() / 5.0) * 5.0)\n",
    "    ax.set_ylim(0, rmax)\n",
    "    ax.set_yticks(np.linspace(0, rmax, 5))\n",
    "    ax.set_yticklabels([f\"{v:.0f}%\" for v in np.linspace(0, rmax, 5)])\n",
    "\n",
    "    ax.set_title(title + f\"\\n(calms ≤ {calm_thresh} m/s excluded; n={n_used})\",\n",
    "                 va=\"bottom\", fontsize=11)\n",
    "    ax.legend(labels, loc=\"lower left\", bbox_to_anchor=(0.9, -0.02),\n",
    "              frameon=True, fontsize=9)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(fname, dpi=200, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "def mean_table(dir_deg, spd, label, calm_thresh=None):\n",
    "    \"\"\"\n",
    "    Mean speed (arithmetic) and mean direction (circular) overall and by season.\n",
    "    Directions in degrees [0, 360).\n",
    "    calm_thresh listed for reference; does not alter means.\n",
    "    \"\"\"\n",
    "    idx = data.loc[start:end].index\n",
    "    df = pd.DataFrame({\"spd\": spd.loc[idx], \"dir\": dir_deg.loc[idx]})\n",
    "    df[\"season\"] = df.index.month.map(season_label)\n",
    "\n",
    "    def agg(g):\n",
    "        return pd.Series({\n",
    "            \"mean_speed_mps\": g[\"spd\"].mean(),\n",
    "            \"mean_dir_deg\": circmean_deg(g[\"dir\"]),\n",
    "            \"n\": g[\"dir\"].count()\n",
    "        })\n",
    "\n",
    "    overall = agg(df)\n",
    "    by_season = df.groupby(\"season\", sort=False).apply(agg)\n",
    "\n",
    "    overall.name = label\n",
    "    out = {\"overall\": overall.to_frame().T, \"season\": by_season}\n",
    "    out[\"meta\"] = {\"calm_threshold_listed_only_mps\": calm_thresh}\n",
    "    return out\n",
    "\n",
    "# -----------------------\n",
    "# Prepare series and conventions\n",
    "# -----------------------\n",
    "# Wind: already \"coming-from\" via zmcomp2metconv\n",
    "wspd = data[\"wspd\"].copy()\n",
    "wdir_from = data[\"wdir\"].copy()  # coming-from, 0°=N, clockwise\n",
    "\n",
    "# Currents: convert to \"going-to\" for the rose\n",
    "if {\"cspd\", \"cdir\"}.issubset(data.columns):\n",
    "    cspd = data[\"cspd\"].copy()\n",
    "    cdir_to = (data[\"cdir\"] + 180.0) % 360.0\n",
    "else:\n",
    "    cspd = None\n",
    "    cdir_to = None\n",
    "\n",
    "# Restrict to analysis window\n",
    "sel = slice(start, end)\n",
    "wspd = wspd.loc[sel]\n",
    "wdir_from = wdir_from.loc[sel]\n",
    "if cspd is not None:\n",
    "    cspd = cspd.loc[sel]\n",
    "    cdir_to = cdir_to.loc[sel]\n",
    "\n",
    "# -----------------------\n",
    "# 1) Full-period roses\n",
    "# -----------------------\n",
    "plot_rose(\n",
    "    dir_deg=wdir_from, spd=wspd, spd_bins=WIND_BINS,\n",
    "    fname=\"fig/IA4_wind_rose.png\",\n",
    "    title=\"Wind rose (coming-from; 0°=N, clockwise)\",\n",
    "    calm_thresh=CALM_WIND, sectors=WIND_SECTORS\n",
    ")\n",
    "\n",
    "if cspd is not None:\n",
    "    plot_rose(\n",
    "        dir_deg=cdir_to, spd=cspd, spd_bins=CURR_BINS,\n",
    "        fname=\"fig/IA4_current_rose.png\",\n",
    "        title=\"Current rose (going-to; 0°=N, clockwise)\",\n",
    "        calm_thresh=CALM_CURR, sectors=CURR_SECTORS\n",
    "    )\n",
    "\n",
    "# -----------------------\n",
    "# 2) Seasonal roses (DJF, MAM, JJA, SON)\n",
    "# -----------------------\n",
    "def plot_rose_seasons(dir_series, spd_series, spd_bins, calm_thresh, sectors, title_base, fname):\n",
    "    seasons = [\"DJF\", \"MAM\", \"JJA\", \"SON\"]\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 10), subplot_kw=dict(polar=True))\n",
    "    axes = axes.ravel()\n",
    "    for i, s in enumerate(seasons):\n",
    "        sel = dir_series.index.map(lambda t: season_label(t.month) == s)\n",
    "        d = dir_series[sel]\n",
    "        v = spd_series[sel]\n",
    "        counts, mask, n_used = rose_counts(d.values, v.values, spd_bins, sectors, calm_thresh)\n",
    "        theta = np.deg2rad(np.arange(0, 360, 360/sectors))\n",
    "        width = 2.0 * np.pi / sectors\n",
    "\n",
    "        ax = axes[i]\n",
    "        ax.set_theta_zero_location(\"N\")\n",
    "        ax.set_theta_direction(-1)\n",
    "\n",
    "        if n_used == 0:\n",
    "            ax.set_title(f\"{s} (n=0)\")\n",
    "            continue\n",
    "\n",
    "        sector_totals = counts.sum(axis=1).astype(float)\n",
    "        sector_totals[sector_totals == 0] = 1.0\n",
    "        frac = counts / sector_totals[:, None]\n",
    "        pct_sector = 100.0 * counts.sum(axis=1) / n_used\n",
    "\n",
    "        bottoms = np.zeros(sectors)\n",
    "        for j in range(len(spd_bins)-1):\n",
    "            heights = pct_sector * frac[:, j]\n",
    "            ax.bar(theta, heights, width=width, bottom=bottoms, align=\"edge\",\n",
    "                   edgecolor=\"black\", linewidth=0.3)\n",
    "            bottoms += heights\n",
    "\n",
    "        ax.set_rlabel_position(225)\n",
    "        rmax = max(5.0, np.ceil(bottoms.max() / 5.0) * 5.0)\n",
    "        ax.set_ylim(0, rmax)\n",
    "        ax.set_yticks(np.linspace(0, rmax, 5))\n",
    "        ax.set_yticklabels([f\"{v:.0f}%\" for v in np.linspace(0, rmax, 5)])\n",
    "        ax.set_title(f\"{s} (calms ≤ {calm_thresh} m/s; n={n_used})\", fontsize=10)\n",
    "\n",
    "    fig.suptitle(title_base, y=0.98)\n",
    "    plt.tight_layout(rect=[0, 0.02, 1, 0.95])\n",
    "    plt.savefig(fname, dpi=200, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "plot_rose_seasons(\n",
    "    wdir_from, wspd, WIND_BINS, CALM_WIND, WIND_SECTORS,\n",
    "    \"Wind roses by season (coming-from; 0°=N, clockwise)\",\n",
    "    \"fig/IA4_wind_rose_seasons.png\"\n",
    ")\n",
    "\n",
    "if cspd is not None:\n",
    "    plot_rose_seasons(\n",
    "        cdir_to, cspd, CURR_BINS, CALM_CURR, CURR_SECTORS,\n",
    "        \"Current roses by season (going-to; 0°=N, clockwise)\",\n",
    "        \"fig/IA4_current_rose_seasons.png\"\n",
    "    )\n",
    "\n",
    "# -----------------------\n",
    "# 3) Mean conditions tables and CSV\n",
    "# -----------------------\n",
    "wind_stats = mean_table(wdir_from, wspd, label=\"wind\", calm_thresh=CALM_WIND)\n",
    "if cspd is not None:\n",
    "    curr_stats = mean_table(cdir_to, cspd, label=\"current\", calm_thresh=CALM_CURR)\n",
    "\n",
    "frames = []\n",
    "wind_overall = wind_stats[\"overall\"].assign(kind=\"wind\")\n",
    "wind_season  = wind_stats[\"season\"].assign(kind=\"wind\", level=\"season\").reset_index().rename(columns={\"season\":\"group\"})\n",
    "frames += [wind_overall.assign(level=\"overall\", group=\"all\"), wind_season]\n",
    "\n",
    "if cspd is not None:\n",
    "    curr_overall = curr_stats[\"overall\"].assign(kind=\"current\")\n",
    "    curr_season  = curr_stats[\"season\"].assign(kind=\"current\", level=\"season\").reset_index().rename(columns={\"season\":\"group\"})\n",
    "    frames += [curr_overall.assign(level=\"overall\", group=\"all\"), curr_season]\n",
    "\n",
    "stats_df = pd.concat(frames, ignore_index=True)\n",
    "stats_df = stats_df[[\"kind\", \"level\", \"group\", \"mean_speed_mps\", \"mean_dir_deg\", \"n\"]]\n",
    "stats_df.to_csv(\"fig/IA4_mean_wind_current_stats.csv\", index=False, float_format=\"%.3f\")\n",
    "\n",
    "# Print seasonal values for wind and current\n",
    "from pandas.api.types import CategoricalDtype\n",
    "\n",
    "season_order = CategoricalDtype([\"DJF\", \"MAM\", \"JJA\", \"SON\"], ordered=True)\n",
    "\n",
    "def print_seasonals(kind_label, dir_note):\n",
    "    df = stats_df.query(\"kind == @kind_label and level == 'season'\").copy()\n",
    "    df[\"group\"] = df[\"group\"].astype(season_order)\n",
    "    df = df.sort_values(\"group\")\n",
    "    print(f\"\\nIA.4 — Seasonal means, {kind_label} ({dir_note})\")\n",
    "    print(df[[\"group\", \"mean_speed_mps\", \"mean_dir_deg\", \"n\"]]\n",
    "          .rename(columns={\"group\": \"season\"})\n",
    "          .to_string(index=False,\n",
    "                     formatters={\n",
    "                         \"mean_speed_mps\": lambda v: f\"{v:.3f}\",\n",
    "                         \"mean_dir_deg\":  lambda v: f\"{v:.1f}\",\n",
    "                         \"n\":             lambda v: f\"{int(v)}\"\n",
    "                     }))\n",
    "\n",
    "print_seasonals(\"wind\", \"coming-from\")\n",
    "print_seasonals(\"current\", \"going-to\")\n",
    "\n",
    "print(\"IA.4 — Mean conditions (1994–2020)\")\n",
    "print(stats_df.query(\"level == 'overall'\"))\n",
    "print(\"\\nSaved figures:\")\n",
    "print(\"  fig/IA4_wind_rose.png\")\n",
    "if cspd is not None:\n",
    "    print(\"  fig/IA4_current_rose.png\")\n",
    "print(\"  fig/IA4_wind_rose_seasons.png\")\n",
    "if cspd is not None:\n",
    "    print(\"  fig/IA4_current_rose_seasons.png\")\n",
    "print(\"Saved table: fig/IA4_mean_wind_current_stats.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "**Q: What are the mean conditions (e.g. velocity and direction)? (if you have time: do you observe any seasonal variability?)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "### IA.4 — Interpretation of wind and current conditions\n",
    "\n",
    "**Answer.** Winds are W–WNW year-round and strongest in winter (mean 7.64 m/s). Currents are weak and dominantly tidal, reversing along a NE–SW axis; the overall mean direction is not meaningful for currents.\n",
    "\n",
    "---\n",
    "\n",
    "### Data basis and conventions\n",
    "\n",
    "- Period analysed: 1994–2020.  \n",
    "- Calms excluded in roses: wind $<0.5$ m/s, current $<0.05$ m/s.  \n",
    "- Wind: **coming-from**; Current: **going-to**; $0^\\circ=\\text{N}$, clockwise.  \n",
    "- Bins used: wind speeds $[0.5,2),[2,4),\\ldots,\\ge 16$ m/s; current speeds $[0.05,0.07),[0.07,0.09),[0.09,0.11),[0.11,0.13),\\ge 0.13$ m/s; wind sectors $22.5^\\circ$; current sectors $10^\\circ$.\n",
    "\n",
    "---\n",
    "\n",
    "### Summary statistics\n",
    "\n",
    "**Overall means (1994–2020)**\n",
    "\n",
    "| Variable | Mean speed | Mean direction |\n",
    "|---|---:|---:|\n",
    "| Wind (coming-from) | 6.45 m/s | 291.2° |\n",
    "| Current (going-to) | 0.067 m/s | 181.3°* |\n",
    "\n",
    "\\*For reversing tidal currents, a single circular mean direction is not physically informative.\n",
    "\n",
    "**Seasonal means**\n",
    "\n",
    "| Season | Wind speed (m/s) | Wind dir (°) | Current speed (m/s) | Current dir (°)* |\n",
    "|---|---:|---:|---:|---:|\n",
    "| DJF | 7.638 | 267.0 | 0.067 | 265.3 |\n",
    "| MAM | 6.243 | 316.3 | 0.067 | 131.1 |\n",
    "| JJA | 5.409 | 294.4 | 0.067 | 197.9 |\n",
    "| SON | 6.513 | 284.7 | 0.067 | 68.9 |\n",
    "\n",
    "\\*Seasonal current “means” are shown for completeness but the roses indicate a bidirectional tidal regime.\n",
    "\n",
    "---\n",
    "\n",
    "### Wind climate: what the roses show\n",
    "\n",
    "- **Directionality.** Dominant **W–WNW** approach. Seasonal veer is modest: closer to **W** in winter (DJF $\\sim267^\\circ$), rotating towards **WNW** in spring–summer (MAM–JJA $\\sim316$–$294^\\circ$), then easing back in autumn (SON $\\sim285^\\circ$).\n",
    "- **Intensity.** Clear seasonal cycle: **DJF > SON ≈ MAM > JJA** by mean speed. The full-period rose shows substantial occupancy in **4–10 m/s** bins, with winter contributing the higher 8–14 m/s fractions.\n",
    "- **Variability.** Sectoral spread is wider in MAM/SON than DJF/JJA.\n",
    "\n",
    "---\n",
    "\n",
    "### Current climate: what the roses show\n",
    "\n",
    "- **Regime.** Two narrow, opposing **going-to** headings dominate, approximately **NE (∼45°)** and **SW (∼225°)**. This is a classic reversing **tidal** signal.\n",
    "- **Magnitudes.** Most occurrences lie **below 0.3 m/s**; the highest occupied bin is typically **0.11–0.13 m/s**, with rarer excursions beyond. The mean speed of **0.067 m/s** reflects the prevalence of weak flows.\n",
    "- **Seasonality.** The **axis does not shift** with season, and the speed distribution changes little between DJF and JJA in the roses. This supports a tide-dominated current with weak seasonal modulation.\n",
    "\n",
    "---\n",
    "\n",
    "### Site context notes\n",
    "\n",
    "- The study area is **south of Lorient (southern Brittany)**, exposed to the **open North Atlantic**. The prevailing **W–WNW** winds align with the basin-scale westerlies and frequent winter cyclones.  \n",
    "- The **NE–SW** tidal current axis is consistent with a coastal geometry that channels reversing flows; without detailed bathymetry/harmonic analysis, treat this as a qualitative inference from the roses.\n",
    "\n",
    "---\n",
    "\n",
    "### Caveats and suggested refinements\n",
    "\n",
    "- **Currents:** Do not use circular means for direction. Prefer a **principal axis** metric and report the **two modal headings** with their shares.  \n",
    "- **Quantiles:** Add $P_{50}$, $P_{90}$, $P_{95}$ for wind and current speeds to complement the means (e.g., “$P_{90}$ wind speed $\\approx$ x m/s”).  \n",
    "- **Calms:** Roses exclude calms by design; if calm frequency is relevant to operations, report the calm fraction separately.  \n",
    "- **Next step:** If needed for design or logistics, compute a tidal ellipse or principal-component axis for the currents, and provide **hour-of-tide** roses to expose phase dependence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "### I.A.5. Comparison to Wave Buoy Measurements\n",
    "\n",
    "We can validate the ResourceCode hindcast data against observations from a nearby wave buoy, for example, from the Candhis website.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "**Q: Comparing the hindcast data from ResourceCode to the observations during the time period with overlapping data, what is the RMSD in the wave height, period, and direction between the observations and simulations?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "## I.B. Estimating the extreme wave conditions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "### Block Maxima (BM) Method\n",
    "\n",
    "**Approach:**  \n",
    "This approach involves dividing the long-term time series of significant wave heights into non-overlapping blocks of equal duration, typically one year.\n",
    "\n",
    "**Process:**  \n",
    "The single highest significant wave height (Hₘ₀) is taken from each block (e.g., the annual maximum).\n",
    "\n",
    "**Distribution:**  \n",
    "These maximum values are then fitted to a *Generalized Extreme Value (GEV)* distribution.\n",
    "\n",
    "**Outcome:**  \n",
    "This model allows you to estimate the wave height corresponding to a specific return period, such as the 1-year or 50-year storm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resample the data into 1 year blocks and extract the maximum value from each block by using pyextremes\n",
    "model = EVA(data.hs)\n",
    "model.get_extremes(\n",
    "    method=\"BM\",\n",
    "    extremes_type=\"high\",\n",
    "    block_size=\"365.2425D\",\n",
    "    errors=\"raise\",\n",
    "    min_last_block=0.9,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {},
   "source": [
    "Lets check the directions of the extreme heights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets find the directions of the extremes from the data\n",
    "data_extreme_directions = data.loc[model.extremes.index, \"dir\"]\n",
    "data_extreme_tm02 = data.loc[model.extremes.index, \"Tm02\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.extremes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual plotting of extremes using matplotlib\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10))\n",
    "\n",
    "# Plot 1: Time series with extremes highlighted\n",
    "ax1.plot(data.index, data.hs, 'b-', alpha=0.3, linewidth=0.5, label='Full time series')\n",
    "ax1.scatter(model.extremes.index, model.extremes.values, color='red', s=20, alpha=0.8, label='Extremes (Block Maxima)')\n",
    "ax1.set_xlabel('Date')\n",
    "ax1.set_ylabel('Significant Wave Height (m)')\n",
    "ax1.set_title('Time Series with One-year Block Extremes')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Histogram of extremes\n",
    "ax2.hist(model.extremes.values, bins=15, alpha=0.7, color='red', edgecolor='black')\n",
    "ax2.set_xlabel('Extreme Wave Height (m)')\n",
    "ax2.set_ylabel('Frequency')\n",
    "ax2.set_title('Distribution of Block Maxima Extremes')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print some statistics about the extremes\n",
    "print(f\"Number of extremes: {len(model.extremes)}\")\n",
    "print(f\"Mean extreme value: {model.extremes.mean():.3f} m\")\n",
    "print(f\"Maximum extreme value: {model.extremes.max():.3f} m\")\n",
    "print(f\"Minimum extreme value: {model.extremes.min():.3f} m\")\n",
    "print(f\"Standard deviation: {model.extremes.std():.3f} m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# More detailed manual plotting of extremes\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 4))\n",
    "\n",
    "# Plot the full time series\n",
    "ax.plot(data.index, data.hs, 'b-', alpha=0.2, linewidth=0.3, label='Full time series')\n",
    "\n",
    "# Highlight extremes with different colors based on magnitude\n",
    "extremes = model.extremes\n",
    "colors = plt.cm.Reds(np.linspace(0.3, 1, len(extremes)))\n",
    "scatter = ax.scatter(extremes.index, extremes.values, c=extremes.values, \n",
    "                    cmap='Reds', s=30, alpha=0.8, edgecolors='black', linewidth=0.5)\n",
    "\n",
    "# Add colorbar\n",
    "cbar = plt.colorbar(scatter, ax=ax)\n",
    "cbar.set_label('Wave Height (m)')\n",
    "\n",
    "# Customize the plot\n",
    "ax.set_xlabel('Date', fontsize=12)\n",
    "ax.set_ylabel('Significant Wave Height (m)', fontsize=12)\n",
    "ax.set_title('Block Maxima Extremes Over Time\\n(Red dots show annual maximum wave heights)', fontsize=14)\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets execute GEV fit on the extremes\n",
    "model.fit_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets save the diagnostic plot to folder graphs in the current directory   \n",
    "model.plot_diagnostic(alpha=0.95)\n",
    "plt.savefig('graphs/diagnostic_plot.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets create one concise dataframe with the extremes and the corresponding directions and periods\n",
    "# Create a DataFrame with extremes and their timestamps\n",
    "extremes_df = pd.DataFrame({\n",
    "    'hs': model.extremes.values,\n",
    "    'timestamp': model.extremes.index\n",
    "})\n",
    "\n",
    "# Get corresponding values from original data\n",
    "extremes_df['dir'] = data.loc[extremes_df.timestamp, 'dir']\n",
    "extremes_df['wspd'] = data.loc[extremes_df.timestamp, 'wspd']\n",
    "extremes_df['Tm02'] = data.loc[extremes_df.timestamp, 'Tm02']\n",
    "\n",
    "# Sort by wave height in descending order\n",
    "extremes_df = extremes_df.sort_values('hs', ascending=False)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(\"\\nExtreme Events Summary:\")\n",
    "print(\"=\" * 80)\n",
    "print(extremes_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40",
   "metadata": {},
   "source": [
    "### Modelling univariate time series: Block maxima + GEVD (Generalized Extreme Value Distribution)\n",
    "\n",
    "We show as an example here a **BM** (block maxima) model fitted to the $H_s$ time series. In this approach, the maximum value is identified within a \"block\" or fixed period in time, and then a GEVP distribution is fit to the data to estimate the return values.  \n",
    "\n",
    "The same plot can readily be obtained for the other sea-state parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIXED VERSION: COMPREHENSIVE SEASONAL ANALYSIS OF EXTREME WAVE HEIGHTS\n",
    "# All-in-one cell for complete seasonality extraction (with DatetimeIndex fix)\n",
    "\n",
    "def rayleigh_test(theta_rad):\n",
    "    \"\"\"Rayleigh test for non-uniformity on angles in radians.\n",
    "    Returns (Z, p).\"\"\"\n",
    "    x = np.asarray(theta_rad, dtype=float)\n",
    "    x = x[~np.isnan(x)]\n",
    "    n = x.size\n",
    "    if n < 5:\n",
    "        return np.nan, np.nan\n",
    "    C = np.sum(np.cos(x))\n",
    "    S = np.sum(np.sin(x))\n",
    "    R = np.hypot(C, S)\n",
    "    Rbar = R / n\n",
    "    Z = n * Rbar**2\n",
    "    # p-value with small-sample correction\n",
    "    p = np.exp(-Z) * (1 + (2*Z - Z**2)/(4*n)\n",
    "                      - (24*Z - 132*Z**2 + 76*Z**3 - 9*Z**4)/(288*n**2))\n",
    "    return Z, float(np.clip(p, 0.0, 1.0))\n",
    "\n",
    "# Extract seasonal information from the extremes - FIXED VERSION\n",
    "# Ensure we have a proper DataFrame with DatetimeIndex\n",
    "extremes_df = pd.DataFrame({'hs': model.extremes.values}, index=model.extremes.index)\n",
    "extremes_df.index = pd.to_datetime(extremes_df.index)  # Ensure it's a DatetimeIndex\n",
    "\n",
    "extremes_df['month'] = extremes_df.index.month\n",
    "extremes_df['season'] = extremes_df['month'].map({\n",
    "    12: 'Winter', 1: 'Winter', 2: 'Winter',\n",
    "    3: 'Spring', 4: 'Spring', 5: 'Spring',\n",
    "    6: 'Summer', 7: 'Summer', 8: 'Summer',\n",
    "    9: 'Autumn', 10: 'Autumn', 11: 'Autumn'\n",
    "})\n",
    "extremes_df['year'] = extremes_df.index.year\n",
    "\n",
    "# Calculate monthly statistics\n",
    "monthly_counts = extremes_df['month'].value_counts().sort_index()\n",
    "monthly_means = extremes_df.groupby('month')['hs'].mean()\n",
    "monthly_maxs = extremes_df.groupby('month')['hs'].max()\n",
    "monthly_std = extremes_df.groupby('month')['hs'].std()\n",
    "\n",
    "months = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun',\n",
    "          'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "\n",
    "# Circular statistics for seasonality\n",
    "monthly_angles = (extremes_df['month'] - 1) * 2 * np.pi / 12\n",
    "circular_mean = np.arctan2(np.sin(monthly_angles).sum(), np.cos(monthly_angles).sum())\n",
    "circular_mean_month = (circular_mean * 12 / (2 * np.pi) + 1) % 12\n",
    "if circular_mean_month == 0:\n",
    "    circular_mean_month = 12\n",
    "\n",
    "R = np.sqrt(np.sin(monthly_angles).sum()**2 + np.cos(monthly_angles).sum()**2) / len(monthly_angles)\n",
    "circular_variance = 1 - R\n",
    "\n",
    "# Rayleigh test for uniformity\n",
    "rayleigh_Z, rayleigh_p = rayleigh_test(monthly_angles)\n",
    "\n",
    "# Create comprehensive plots\n",
    "fig = plt.figure(figsize=(20, 16))\n",
    "\n",
    "# Plot 1: Monthly distribution with dual y-axis\n",
    "ax1 = plt.subplot(3, 3, 1)\n",
    "bars = ax1.bar(monthly_counts.index, monthly_counts.values, alpha=0.7, color='skyblue', \n",
    "               edgecolor='black', label='Count of Extremes')\n",
    "ax1.set_xlabel('Month')\n",
    "ax1.set_ylabel('Number of Extremes', color='blue')\n",
    "ax1.set_title('Monthly Distribution of Extreme Wave Heights', fontsize=12, fontweight='bold')\n",
    "ax1.set_xticks(range(1, 13))\n",
    "ax1.set_xticklabels(months)\n",
    "ax1.tick_params(axis='y', labelcolor='blue')\n",
    "\n",
    "# Add mean values as line plot\n",
    "ax1_twin = ax1.twinx()\n",
    "ax1_twin.plot(monthly_means.index, monthly_means.values, 'ro-', linewidth=2, markersize=6, \n",
    "              color='red', label='Mean Height')\n",
    "ax1_twin.set_ylabel('Mean Wave Height (m)', color='red')\n",
    "ax1_twin.tick_params(axis='y', labelcolor='red')\n",
    "\n",
    "# Combine legends\n",
    "lines1, labels1 = ax1.get_legend_handles_labels()\n",
    "lines2, labels2 = ax1_twin.get_legend_handles_labels()\n",
    "ax1.legend(lines1 + lines2, labels1 + labels2, loc='upper right')\n",
    "\n",
    "# Plot 2: Seasonal box plots\n",
    "ax2 = plt.subplot(3, 3, 2)\n",
    "seasonal_data = [extremes_df[extremes_df['season'] == season]['hs'].values \n",
    "                 for season in ['Winter', 'Spring', 'Summer', 'Autumn']]\n",
    "\n",
    "box_plot = ax2.boxplot(seasonal_data, labels=['Winter', 'Spring', 'Summer', 'Autumn'], \n",
    "                       patch_artist=True, showfliers=True)\n",
    "colors = ['lightblue', 'lightgreen', 'orange', 'brown']\n",
    "for patch, color in zip(box_plot['boxes'], colors):\n",
    "    patch.set_facecolor(color)\n",
    "    patch.set_alpha(0.7)\n",
    "\n",
    "ax2.set_ylabel('Wave Height (m)')\n",
    "ax2.set_title('Seasonal Distribution of Extreme Wave Heights', fontsize=12, fontweight='bold')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Add statistical annotations\n",
    "for i, season in enumerate(['Winter', 'Spring', 'Summer', 'Autumn']):\n",
    "    season_data = extremes_df[extremes_df['season'] == season]['hs']\n",
    "    if len(season_data) > 0:\n",
    "        ax2.text(i+1, season_data.max() + 0.1, f'n={len(season_data)}', \n",
    "                ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# Plot 3: Time series with seasonal coloring\n",
    "ax3 = plt.subplot(3, 3, 3)\n",
    "scatter = ax3.scatter(extremes_df.index, extremes_df['hs'], \n",
    "                     c=extremes_df['month'], cmap='tab20', s=50, alpha=0.8, edgecolors='black')\n",
    "ax3.set_xlabel('Year')\n",
    "ax3.set_ylabel('Wave Height (m)')\n",
    "ax3.set_title('Extreme Wave Heights Over Time (Colored by Month)', fontsize=12, fontweight='bold')\n",
    "cbar = plt.colorbar(scatter, ax=ax3)\n",
    "cbar.set_label('Month')\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 4: Circular histogram (rose plot)\n",
    "ax4 = plt.subplot(3, 3, 4, projection='polar')\n",
    "monthly_counts_polar = monthly_counts.reindex(range(1, 13), fill_value=0)\n",
    "theta = np.linspace(0, 2*np.pi, 13)[:-1]  # 12 months\n",
    "width = 2*np.pi/12\n",
    "bars = ax4.bar(theta, monthly_counts_polar.values, width=width, alpha=0.7, \n",
    "               color=plt.cm.viridis(monthly_counts_polar.values / monthly_counts_polar.max()))\n",
    "ax4.set_theta_zero_location('N')  # January at top\n",
    "ax4.set_theta_direction(-1)  # Clockwise\n",
    "ax4.set_xticks(theta)\n",
    "ax4.set_xticklabels(months)\n",
    "ax4.set_title('Circular Distribution of Extremes\\n(Rose Plot)', fontsize=12, fontweight='bold', pad=20)\n",
    "\n",
    "# Add circular mean arrow\n",
    "ax4.arrow(circular_mean, monthly_counts_polar.max() * 0.8, 0, monthly_counts_polar.max() * 0.2, \n",
    "          head_width=0.2, head_length=0.1, fc='red', ec='red', linewidth=3)\n",
    "ax4.text(circular_mean + 0.3, monthly_counts_polar.max() * 0.9, 'Mean', \n",
    "         fontsize=10, fontweight='bold', color='red')\n",
    "\n",
    "# Plot 5: Monthly trend analysis with error bars\n",
    "ax5 = plt.subplot(3, 3, 5)\n",
    "ax5.errorbar(monthly_means.index, monthly_means.values, \n",
    "             yerr=monthly_std.values, fmt='o-', capsize=5, capthick=2,\n",
    "             linewidth=2, markersize=8, color='darkblue', alpha=0.8)\n",
    "ax5.fill_between(monthly_means.index, \n",
    "                 monthly_means.values - monthly_std.values,\n",
    "                 monthly_means.values + monthly_std.values,\n",
    "                 alpha=0.3, color='blue')\n",
    "ax5.set_xlabel('Month')\n",
    "ax5.set_ylabel('Mean Wave Height (m)')\n",
    "ax5.set_title('Monthly Mean Wave Heights with Error Bars', fontsize=12, fontweight='bold')\n",
    "ax5.set_xticks(range(1, 13))\n",
    "ax5.set_xticklabels(months)\n",
    "ax5.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 6: Seasonal intensity heatmap\n",
    "ax6 = plt.subplot(3, 3, 6)\n",
    "yearly_monthly_counts = extremes_df.groupby(['year', 'month']).size().unstack(fill_value=0)\n",
    "yearly_monthly_counts = yearly_monthly_counts.reindex(columns=range(1, 13), fill_value=0)\n",
    "\n",
    "im = ax6.imshow(yearly_monthly_counts.T, cmap='YlOrRd', aspect='auto', interpolation='nearest')\n",
    "ax6.set_xlabel('Year')\n",
    "ax6.set_ylabel('Month')\n",
    "ax6.set_title('Extreme Events Heatmap\\n(Year vs Month)', fontsize=12, fontweight='bold')\n",
    "ax6.set_yticks(range(12))\n",
    "ax6.set_yticklabels(months)\n",
    "ax6.set_xticks(range(0, len(yearly_monthly_counts), max(1, len(yearly_monthly_counts)//10)))\n",
    "ax6.set_xticklabels(yearly_monthly_counts.index[::max(1, len(yearly_monthly_counts)//10)])\n",
    "\n",
    "cbar = plt.colorbar(im, ax=ax6)\n",
    "cbar.set_label('Number of Extremes')\n",
    "\n",
    "# Plot 7: Monthly autocorrelation analysis\n",
    "ax7 = plt.subplot(3, 3, 7)\n",
    "monthly_series = extremes_df.groupby(extremes_df.index.to_period('M'))['hs'].max()\n",
    "monthly_series = monthly_series.reindex(pd.date_range(monthly_series.index[0].start_time, \n",
    "                                                      monthly_series.index[-1].end_time, \n",
    "                                                      freq='M'), fill_value=np.nan)\n",
    "\n",
    "lags = range(1, 13)  # 12 months\n",
    "autocorr = [monthly_series.autocorr(lag=lag) for lag in lags]\n",
    "\n",
    "ax7.bar(lags, autocorr, alpha=0.7, color='green', edgecolor='black')\n",
    "ax7.axhline(y=0, color='black', linestyle='-', alpha=0.5)\n",
    "ax7.axhline(y=0.2, color='red', linestyle='--', alpha=0.7, label='Significance threshold')\n",
    "ax7.axhline(y=-0.2, color='red', linestyle='--', alpha=0.7)\n",
    "ax7.set_xlabel('Lag (months)')\n",
    "ax7.set_ylabel('Autocorrelation')\n",
    "ax7.set_title('Monthly Autocorrelation of Extreme Heights', fontsize=12, fontweight='bold')\n",
    "ax7.legend()\n",
    "ax7.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 8: Seasonal statistics summary table\n",
    "ax8 = plt.subplot(3, 3, 8)\n",
    "ax8.axis('off')\n",
    "ax8.set_title('Seasonal Statistics Summary', fontsize=12, fontweight='bold', pad=20)\n",
    "\n",
    "seasonal_stats = extremes_df.groupby('season')['hs'].agg(['count', 'mean', 'std', 'min', 'max']).round(3)\n",
    "seasonal_stats = seasonal_stats.reindex(['Winter', 'Spring', 'Summer', 'Autumn'])\n",
    "\n",
    "table_data = []\n",
    "for season in ['Winter', 'Spring', 'Summer', 'Autumn']:\n",
    "    if season in seasonal_stats.index:\n",
    "        stats = seasonal_stats.loc[season]\n",
    "        table_data.append([\n",
    "            season,\n",
    "            f\"{stats['count']:.0f}\",\n",
    "            f\"{stats['mean']:.3f}\",\n",
    "            f\"{stats['std']:.3f}\",\n",
    "            f\"{stats['min']:.3f}\",\n",
    "            f\"{stats['max']:.3f}\"\n",
    "        ])\n",
    "\n",
    "table = ax8.table(cellText=table_data,\n",
    "                  colLabels=['Season', 'Count', 'Mean (m)', 'Std (m)', 'Min (m)', 'Max (m)'],\n",
    "                  cellLoc='center',\n",
    "                  loc='center',\n",
    "                  bbox=[0, 0, 1, 1])\n",
    "\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(9)\n",
    "table.scale(1, 1.5)\n",
    "\n",
    "# Style the table\n",
    "for i in range(len(table_data) + 1):\n",
    "    for j in range(6):\n",
    "        cell = table[(i, j)]\n",
    "        if i == 0:  # Header\n",
    "            cell.set_facecolor('#4CAF50')\n",
    "            cell.set_text_props(weight='bold', color='white')\n",
    "        else:\n",
    "            cell.set_facecolor('#f0f0f0' if i % 2 == 0 else 'white')\n",
    "\n",
    "# Plot 9: Density plot of extremes by season\n",
    "ax9 = plt.subplot(3, 3, 9)\n",
    "for i, season in enumerate(['Winter', 'Spring', 'Summer', 'Autumn']):\n",
    "    season_data = extremes_df[extremes_df['season'] == season]['hs']\n",
    "    if len(season_data) > 0:\n",
    "        x_range = np.linspace(extremes_df['hs'].min()*0.8, extremes_df['hs'].max()*1.2, 1000)\n",
    "        density = stats.gaussian_kde(season_data)\n",
    "        y_density = density(x_range)\n",
    "        ax9.plot(x_range, y_density, linewidth=2, label=f'{season} (n={len(season_data)})', alpha=0.8)\n",
    "\n",
    "ax9.set_xlabel('Wave Height (m)')\n",
    "ax9.set_ylabel('Density')\n",
    "ax9.set_title('Seasonal Density Distributions', fontsize=12, fontweight='bold')\n",
    "ax9.legend()\n",
    "ax9.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print comprehensive analysis results\n",
    "print(\"=\"*80)\n",
    "print(\"COMPREHENSIVE SEASONAL ANALYSIS OF EXTREME WAVE HEIGHTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\nDATA SUMMARY:\")\n",
    "print(f\"Total number of extremes: {len(extremes_df)}\")\n",
    "print(f\"Date range: {extremes_df.index.min().strftime('%Y-%m-%d')} to {extremes_df.index.max().strftime('%Y-%m-%d')}\")\n",
    "\n",
    "print(f\"\\nCIRCULAR STATISTICS:\")\n",
    "print(f\"Circular mean month: {months[int(circular_mean_month)-1]} (month {circular_mean_month:.1f})\")\n",
    "print(f\"Circular variance: {circular_variance:.4f}\")\n",
    "print(f\"Rayleigh test p-value: {rayleigh_p:.6f}\")\n",
    "if rayleigh_p < 0.05:\n",
    "    print(\"→ Significant seasonal clustering (p < 0.05)\")\n",
    "else:\n",
    "    print(\"→ No significant seasonal clustering (p ≥ 0.05)\")\n",
    "\n",
    "print(f\"\\nSEASONAL PATTERN SUMMARY:\")\n",
    "print(f\"Most extreme-prone month: {months[monthly_counts.idxmax()-1]} ({monthly_counts.max()} events)\")\n",
    "print(f\"Least extreme-prone month: {months[monthly_counts.idxmin()-1]} ({monthly_counts.min()} events)\")\n",
    "print(f\"Season with most extremes: {extremes_df['season'].value_counts().index[0]}\")\n",
    "print(f\"Season with highest mean: {extremes_df.groupby('season')['hs'].mean().idxmax()}\")\n",
    "print(f\"Circular concentration: {R:.3f} (1.0 = perfect clustering, 0.0 = uniform)\")\n",
    "\n",
    "print(f\"\\nDETAILED SEASONAL STATISTICS:\")\n",
    "for season in ['Winter', 'Spring', 'Summer', 'Autumn']:\n",
    "    season_data = extremes_df[extremes_df['season'] == season]['hs']\n",
    "    if len(season_data) > 0:\n",
    "        print(f\"\\n{season.upper()}:\")\n",
    "        print(f\"  Number of extremes: {len(season_data)}\")\n",
    "        print(f\"  Mean height: {season_data.mean():.3f} m\")\n",
    "        print(f\"  Standard deviation: {season_data.std():.3f} m\")\n",
    "        print(f\"  Minimum: {season_data.min():.3f} m\")\n",
    "        print(f\"  Maximum: {season_data.max():.3f} m\")\n",
    "        print(f\"  Percentage of total extremes: {len(season_data)/len(extremes_df)*100:.1f}%\")\n",
    "    else:\n",
    "        print(f\"\\n{season.upper()}: No extremes recorded\")\n",
    "\n",
    "# Calculate seasonal risk assessment\n",
    "winter_risk = len(extremes_df[extremes_df['season'] == 'Winter']) / len(extremes_df) * 100\n",
    "summer_risk = len(extremes_df[extremes_df['season'] == 'Summer']) / len(extremes_df) * 100\n",
    "spring_risk = len(extremes_df[extremes_df['season'] == 'Spring']) / len(extremes_df) * 100\n",
    "autumn_risk = len(extremes_df[extremes_df['season'] == 'Autumn']) / len(extremes_df) * 100\n",
    "\n",
    "print(f\"\\nRISK ASSESSMENT:\")\n",
    "print(f\"Winter risk: {winter_risk:.1f}% of all extremes\")\n",
    "print(f\"Spring risk: {spring_risk:.1f}% of all extremes\")\n",
    "print(f\"Summer risk: {summer_risk:.1f}% of all extremes\")\n",
    "print(f\"Autumn risk: {autumn_risk:.1f}% of all extremes\")\n",
    "\n",
    "if summer_risk > 0:\n",
    "    print(f\"Risk ratio (Winter/Summer): {winter_risk/summer_risk:.2f}\")\n",
    "if spring_risk > 0:\n",
    "    print(f\"Risk ratio (Winter/Spring): {winter_risk/spring_risk:.2f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ANALYSIS COMPLETE - All seasonal patterns extracted and visualized!\")\n",
    "print(\"=\"*80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42",
   "metadata": {},
   "source": [
    "After loading the data, apply the block method approach with a block size of 1 year (365.2425 days), where each data block must be at least 90% full to take into account in the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EVA(data.hs)\n",
    "model.get_extremes(method=\"BM\", block_size=\"365.2425D\", min_last_block=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.extremes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.plot_extremes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47",
   "metadata": {},
   "source": [
    "The parameter alpha specifies the confidence limits (default = 0.95)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.plot_diagnostic(alpha=0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49",
   "metadata": {},
   "source": [
    "The parameter n_samples indicates the number of bootstrap samples used to estimate the confidence bounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = model.get_summary(\n",
    "        return_period=[1, 2, 5, 10, 25, 50, 100, 250, 500, 1000],\n",
    "        alpha=0.95,\n",
    "        n_samples=1000,\n",
    "    )\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51",
   "metadata": {},
   "source": [
    "### Modelling univariate time series: Peaks over threshold (POT) + GPD (Generalized Pareto Distribution)\n",
    "\n",
    "We show as example here a **POT** (peaks over threshold) model fitted to the $H_s$ time series. This analysis first finds values over a specified threshold and then declusters these values using a predefined clustering distance, and finally finds the maximum value within each cluster. \n",
    "\n",
    "The same plot can readily be obtained for the other sea-state parameters.\n",
    "\n",
    "We first can have a look at the quality of the fitted model, and to the corresponding return levels as a function of the selected wave height threshold. The parameters r and alpha specify the minimum time distance (duration) between adjacent clusters and the confidence limits (default = 0.95), respectively.\n",
    "\n",
    "The shape and modified scale parameters define the Generalized Pareto Distribution, and they depend on the threshold value, but should be stable within a range of valid thresholds (e.g. less than ~3m here)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_parameter_stability(ts=data.hs,r='72H',alpha=.95);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53",
   "metadata": {},
   "source": [
    "The mean residual life plots the average excess value over a given threshold, and it should be approcimately linear above the threshold for which the GPD model is valid (e.g. <~3m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mean_residual_life(data.hs);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55",
   "metadata": {},
   "source": [
    "The analysis is completed for both Hs and the wind speed, specifying a window of 72 hours and a quantile of 0.98 for determining the threshold to specify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {},
   "outputs": [],
   "source": [
    "quant=0.98\n",
    "models = get_fitted_models(data[[\"hs\",\"wspd\"]],quantile=quant,r=\"72H\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57",
   "metadata": {},
   "outputs": [],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {},
   "outputs": [],
   "source": [
    "models[0].plot_diagnostic(alpha=0.95);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59",
   "metadata": {},
   "outputs": [],
   "source": [
    "models[1].plot_diagnostic(alpha=0.95);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(get_gpd_parameters(models),columns=[\"mu\",\"sigma\",\"xi\"],index=[\"Hs\",\"Wspd\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_Hs = models[0].get_summary(\n",
    "    return_period=[1, 2, 5, 10, 25, 50, 100],\n",
    "    alpha=0.95,\n",
    "    n_samples=1000,\n",
    ")\n",
    "summary_Wspd = models[1].get_summary(\n",
    "    return_period=[1, 2, 5, 10, 25, 50, 100],\n",
    "    alpha=0.95,\n",
    "    n_samples=1000,\n",
    ")\n",
    "print(summary_Hs)\n",
    "print(summary_Wspd)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Modelling Extreme values for the Wind Farm project\n",
    "\n",
    "This notebook is a brief example of the possibilities offered by the toolbox for modeling extreme values, adapted from the tools provided from the ResourceCode website.\n",
    "\n",
    "It relies on the `pyextreme` library which get installed with the Resourcecode toolbox. Here we demonstrate 2 examples of univariate modeling as shown in class. For more information, see https://georgebv.github.io/pyextremes/."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "# 1. Wave Dynamics\n",
    "\n",
    "## 1.1 Characterizing the study site mean wave conditions\n",
    "\n",
    "This notebook covers Part I.A of the wind turbine project: Characterizing the mean wave conditions and seasonal variability at the selected study site. The goal is to analyze long-term hindcast data to understand the typical and seasonal wave climate.\n",
    "\n",
    "---\n",
    "\n",
    "### Import Required Libraries\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pyextremes import (\n",
    "    plot_mean_residual_life,\n",
    "    plot_parameter_stability, \n",
    "    EVA\n",
    ")\n",
    "import resourcecode\n",
    "\n",
    "from resourcecode.eva import (\n",
    "    censgaussfit,\n",
    "    get_fitted_models,\n",
    "    get_gpd_parameters,\n",
    "    run_simulation,\n",
    "    huseby,\n",
    ")\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Enable inline plotting for Jupyter notebooks\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "---\n",
    "### Chosen Study Site\n",
    "\n",
    "**Site:** Bretagne Sud 1\n",
    "**Coordinates:** $(47.5882, -3.3215)$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = resourcecode.Client()\n",
    "# load the resourcecode dataset from Bretagne Sud 1\n",
    "# find the closest point to the coordinates\n",
    "point_id, dist_m = resourcecode.data.get_closest_point(latitude=47.5882, longitude=-3.3215)\n",
    "print(point_id, dist_m)\n",
    "\n",
    "# get the data from the closest point\n",
    "data = client.get_dataframe_from_criteria(\n",
    "    \"\"\"\n",
    "{\n",
    "    \"node\": 126096,\n",
    "    \"start\": 0,\n",
    "    \"end\": 99999903600,\n",
    "    \"parameter\": [\"hs\",\"uwnd\",\"vwnd\"]\n",
    "}\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "### Data Source\n",
    "\n",
    "The analysis will use long-term (1994-2020) hindcast simulations from the **ResourceCode wave database**.\n",
    "\n",
    "**Variables to download**:\n",
    "* Significant wave height ($H_{m0}$)\n",
    "* Mean wave period ($T_{m02}$)\n",
    "* Mean wave direction\n",
    "* Wind velocity\n",
    "* Current velocity\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets investigate the dataset\n",
    "# can we locate our point in the dataset?\n",
    "# lets add direction, signifcant wave period, and wind speed to the dataset\n",
    "data[\"dir\"] = resourcecode.utils.zmcomp2metconv(data.uwnd, data.vwnd)[1]\n",
    "data[\"Tm02\"] = resourcecode.utils.zmcomp2metconv(data.hs, data.dir)[0]\n",
    "data[\"wspd\"] = resourcecode.utils.zmcomp2metconv(data.uwnd, data.vwnd)[0]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "### 1. Mean Wave Conditions\n",
    "\n",
    "First, we will load and plot the 26-year time series (1994-2020) for significant wave height, mean wave period, and mean wave direction. We will also calculate the mean value for each variable over the entire time series.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "### 1.1 Block Maxima (BM) Method\n",
    "\n",
    "**Approach:**  \n",
    "This approach involves dividing the long-term time series of significant wave heights into non-overlapping blocks of equal duration, typically one year.\n",
    "\n",
    "**Process:**  \n",
    "The single highest significant wave height (Hₘ₀) is taken from each block (e.g., the annual maximum).\n",
    "\n",
    "**Distribution:**  \n",
    "These maximum values are then fitted to a *Generalized Extreme Value (GEV)* distribution.\n",
    "\n",
    "**Outcome:**  \n",
    "This model allows you to estimate the wave height corresponding to a specific return period, such as the 1-year or 50-year storm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resample the data into 1 year blocks and extract the maximum value from each block by using pyextremes\n",
    "model = EVA(data.hs)\n",
    "model.get_extremes(\n",
    "    method=\"BM\",\n",
    "    extremes_type=\"high\",\n",
    "    block_size=\"365.2425D\",\n",
    "    errors=\"raise\",\n",
    "    min_last_block=0.9,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "Lets check the directions of the extreme heights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets find the directions of the extremes from the data\n",
    "data_extreme_directions = data.loc[model.extremes.index, \"dir\"]\n",
    "data_extreme_tm02 = data.loc[model.extremes.index, \"Tm02\"]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.extremes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual plotting of extremes using matplotlib\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10))\n",
    "\n",
    "# Plot 1: Time series with extremes highlighted\n",
    "ax1.plot(data.index, data.hs, 'b-', alpha=0.3, linewidth=0.5, label='Full time series')\n",
    "ax1.scatter(model.extremes.index, model.extremes.values, color='red', s=20, alpha=0.8, label='Extremes (Block Maxima)')\n",
    "ax1.set_xlabel('Date')\n",
    "ax1.set_ylabel('Significant Wave Height (m)')\n",
    "ax1.set_title('Time Series with One-year Block Extremes')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Histogram of extremes\n",
    "ax2.hist(model.extremes.values, bins=15, alpha=0.7, color='red', edgecolor='black')\n",
    "ax2.set_xlabel('Extreme Wave Height (m)')\n",
    "ax2.set_ylabel('Frequency')\n",
    "ax2.set_title('Distribution of Block Maxima Extremes')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print some statistics about the extremes\n",
    "print(f\"Number of extremes: {len(model.extremes)}\")\n",
    "print(f\"Mean extreme value: {model.extremes.mean():.3f} m\")\n",
    "print(f\"Maximum extreme value: {model.extremes.max():.3f} m\")\n",
    "print(f\"Minimum extreme value: {model.extremes.min():.3f} m\")\n",
    "print(f\"Standard deviation: {model.extremes.std():.3f} m\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# More detailed manual plotting of extremes\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 4))\n",
    "\n",
    "# Plot the full time series\n",
    "ax.plot(data.index, data.hs, 'b-', alpha=0.2, linewidth=0.3, label='Full time series')\n",
    "\n",
    "# Highlight extremes with different colors based on magnitude\n",
    "extremes = model.extremes\n",
    "colors = plt.cm.Reds(np.linspace(0.3, 1, len(extremes)))\n",
    "scatter = ax.scatter(extremes.index, extremes.values, c=extremes.values, \n",
    "                    cmap='Reds', s=30, alpha=0.8, edgecolors='black', linewidth=0.5)\n",
    "\n",
    "# Add colorbar\n",
    "cbar = plt.colorbar(scatter, ax=ax)\n",
    "cbar.set_label('Wave Height (m)')\n",
    "\n",
    "# Customize the plot\n",
    "ax.set_xlabel('Date', fontsize=12)\n",
    "ax.set_ylabel('Significant Wave Height (m)', fontsize=12)\n",
    "ax.set_title('Block Maxima Extremes Over Time\\n(Red dots show annual maximum wave heights)', fontsize=14)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets execute GEV fit on the extremes\n",
    "model.fit_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets save the diagnostic plot to folder graphs in the current directory   \n",
    "model.plot_diagnostic(alpha=0.95)\n",
    "plt.savefig('graphs/diagnostic_plot.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets create one concise dataframe with the extremes and the corresponding directions and periods\n",
    "# Create a DataFrame with extremes and their timestamps\n",
    "extremes_df = pd.DataFrame({\n",
    "    'hs': model.extremes.values,\n",
    "    'timestamp': model.extremes.index\n",
    "})\n",
    "\n",
    "# Get corresponding values from original data\n",
    "extremes_df['dir'] = data.loc[extremes_df.timestamp, 'dir']\n",
    "extremes_df['wspd'] = data.loc[extremes_df.timestamp, 'wspd']\n",
    "extremes_df['Tm02'] = data.loc[extremes_df.timestamp, 'Tm02']\n",
    "\n",
    "# Sort by wave height in descending order\n",
    "extremes_df = extremes_df.sort_values('hs', ascending=False)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(\"\\nExtreme Events Summary:\")\n",
    "print(\"=\" * 80)\n",
    "print(extremes_df)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "**Q: Do any trends in the wave height, period, or direction exist over the 26 year time period? Do you expect there to be changes in the mean conditions during the 30-year lifetime of the wind turbine? If so, why?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "### 2. Most Common Wave Conditions\n",
    "\n",
    "To identify the most common operating conditions, we will create a 2D histogram (scatter diagram) of significant wave height ($H_{m0}$) versus mean wave period ($T_{m02}$). We will also plot a wave rose to identify the most common wave incidence direction(s).\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "**Q: What is the water depth at this location? Indicate on the histrogram for what wave conditions the waves are considered deep water waves? linear waves?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "### 3. Seasonal Variability\n",
    "\n",
    "Next, we will evaluate temporal variability by calculating and plotting the mean wave height, period, and direction as a function of the month of the year (e.g., mean for January, February, etc.).\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "\n",
    "**Q: Do you observe any seasonal trends in wave height, period, or direction? If so, why?**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "### 4. Mean Wind and Current Conditions\n",
    "\n",
    "We will also evaluate the wind and current conditions by plotting rose diagrams of their respective velocities and directions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "**Q: What are the mean conditions (e.g. velocity and direction)? (if you have time: do you observe any seasonal variability?)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "### 5. Comparison to Wave Buoy Measurements\n",
    "\n",
    "We can validate the ResourceCode hindcast data against observations from a nearby wave buoy, for example, from the Candhis website.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34",
   "metadata": {},
   "source": [
    "**Q: Comparing the hindcast data from ResourceCode to the observations during the time period with overlapping data, what is the RMSD in the wave height, period, and direction between the observations and simulations?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "36",
   "metadata": {},
   "source": [
    "---\n",
    "### Report Submission Note\n",
    "\n",
    "The results from this analysis (Part I.A) and the extreme wave analysis (Part I.B) will be compiled into a concise report due on 24/10/2025."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pyextremes import (\n",
    "    plot_mean_residual_life,\n",
    "    plot_parameter_stability, \n",
    "    EVA\n",
    ")\n",
    "import resourcecode\n",
    "\n",
    "from resourcecode.eva import (\n",
    "    censgaussfit,\n",
    "    get_fitted_models,\n",
    "    get_gpd_parameters,\n",
    "    run_simulation,\n",
    "    huseby,\n",
    ")\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Enable inline plotting for Jupyter notebooks\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38",
   "metadata": {},
   "source": [
    "We first load the data from the Bretagne Sud 1 location `126096` (coordinates: $(47.5882, -3.3215)$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "point_id, dist_m = resourcecode.data.get_closest_point(latitude=47.5882, longitude=-3.3215)\n",
    "print(point_id, dist_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = resourcecode.Client()\n",
    "data = client.get_dataframe_from_criteria(\n",
    "    \"\"\"\n",
    "{\n",
    "    \"node\": 126096,\n",
    "    \"start\": 0,\n",
    "    \"end\": 99999903600,\n",
    "    \"parameter\": [\"hs\",\"uwnd\",\"vwnd\"]\n",
    "}\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42",
   "metadata": {},
   "source": [
    "From the $u$ and $v$ components of the wind, calculate the wind speed and direction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"wspd\"], data[\"wdir\"] = resourcecode.utils.zmcomp2metconv(data.uwnd, data.vwnd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45",
   "metadata": {},
   "source": [
    "### Modelling univariate time series: Block maxima + GEVD (Generalized Extreme Value Distribution)\n",
    "\n",
    "We show as an example here a **BM** (block maxima) model fitted to the $H_s$ time series. In this approach, the maximum value is identified within a \"block\" or fixed period in time, and then a GEVP distribution is fit to the data to estimate the return values.  \n",
    "\n",
    "The same plot can readily be obtained for the other sea-state parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIXED VERSION: COMPREHENSIVE SEASONAL ANALYSIS OF EXTREME WAVE HEIGHTS\n",
    "# All-in-one cell for complete seasonality extraction (with DatetimeIndex fix)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from scipy import stats\n",
    "from statsmodels.tsa.stattools import acf\n",
    "\n",
    "# Extract seasonal information from the extremes - FIXED VERSION\n",
    "# Ensure we have a proper DataFrame with DatetimeIndex\n",
    "extremes_df = pd.DataFrame({'hs': model.extremes.values}, index=model.extremes.index)\n",
    "extremes_df.index = pd.to_datetime(extremes_df.index)  # Ensure it's a DatetimeIndex\n",
    "\n",
    "extremes_df['month'] = extremes_df.index.month\n",
    "extremes_df['season'] = extremes_df['month'].map({\n",
    "    12: 'Winter', 1: 'Winter', 2: 'Winter',\n",
    "    3: 'Spring', 4: 'Spring', 5: 'Spring',\n",
    "    6: 'Summer', 7: 'Summer', 8: 'Summer',\n",
    "    9: 'Autumn', 10: 'Autumn', 11: 'Autumn'\n",
    "})\n",
    "extremes_df['year'] = extremes_df.index.year\n",
    "\n",
    "# Calculate monthly statistics\n",
    "monthly_counts = extremes_df['month'].value_counts().sort_index()\n",
    "monthly_means = extremes_df.groupby('month')['hs'].mean()\n",
    "monthly_maxs = extremes_df.groupby('month')['hs'].max()\n",
    "monthly_std = extremes_df.groupby('month')['hs'].std()\n",
    "\n",
    "months = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun',\n",
    "          'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "\n",
    "# Circular statistics for seasonality\n",
    "monthly_angles = (extremes_df['month'] - 1) * 2 * np.pi / 12\n",
    "circular_mean = np.arctan2(np.sin(monthly_angles).sum(), np.cos(monthly_angles).sum())\n",
    "circular_mean_month = (circular_mean * 12 / (2 * np.pi) + 1) % 12\n",
    "if circular_mean_month == 0:\n",
    "    circular_mean_month = 12\n",
    "\n",
    "R = np.sqrt(np.sin(monthly_angles).sum()**2 + np.cos(monthly_angles).sum()**2) / len(monthly_angles)\n",
    "circular_variance = 1 - R\n",
    "\n",
    "# Rayleigh test for uniformity\n",
    "rayleigh_stat, rayleigh_p = stats.circstats.rayleigh(monthly_angles)\n",
    "\n",
    "# Create comprehensive plots\n",
    "fig = plt.figure(figsize=(20, 16))\n",
    "\n",
    "# Plot 1: Monthly distribution with dual y-axis\n",
    "ax1 = plt.subplot(3, 3, 1)\n",
    "bars = ax1.bar(monthly_counts.index, monthly_counts.values, alpha=0.7, color='skyblue', \n",
    "               edgecolor='black', label='Count of Extremes')\n",
    "ax1.set_xlabel('Month')\n",
    "ax1.set_ylabel('Number of Extremes', color='blue')\n",
    "ax1.set_title('Monthly Distribution of Extreme Wave Heights', fontsize=12, fontweight='bold')\n",
    "ax1.set_xticks(range(1, 13))\n",
    "ax1.set_xticklabels(months)\n",
    "ax1.tick_params(axis='y', labelcolor='blue')\n",
    "\n",
    "# Add mean values as line plot\n",
    "ax1_twin = ax1.twinx()\n",
    "ax1_twin.plot(monthly_means.index, monthly_means.values, 'ro-', linewidth=2, markersize=6, \n",
    "              color='red', label='Mean Height')\n",
    "ax1_twin.set_ylabel('Mean Wave Height (m)', color='red')\n",
    "ax1_twin.tick_params(axis='y', labelcolor='red')\n",
    "\n",
    "# Combine legends\n",
    "lines1, labels1 = ax1.get_legend_handles_labels()\n",
    "lines2, labels2 = ax1_twin.get_legend_handles_labels()\n",
    "ax1.legend(lines1 + lines2, labels1 + labels2, loc='upper right')\n",
    "\n",
    "# Plot 2: Seasonal box plots\n",
    "ax2 = plt.subplot(3, 3, 2)\n",
    "seasonal_data = [extremes_df[extremes_df['season'] == season]['hs'].values \n",
    "                 for season in ['Winter', 'Spring', 'Summer', 'Autumn']]\n",
    "\n",
    "box_plot = ax2.boxplot(seasonal_data, labels=['Winter', 'Spring', 'Summer', 'Autumn'], \n",
    "                       patch_artist=True, showfliers=True)\n",
    "colors = ['lightblue', 'lightgreen', 'orange', 'brown']\n",
    "for patch, color in zip(box_plot['boxes'], colors):\n",
    "    patch.set_facecolor(color)\n",
    "    patch.set_alpha(0.7)\n",
    "\n",
    "ax2.set_ylabel('Wave Height (m)')\n",
    "ax2.set_title('Seasonal Distribution of Extreme Wave Heights', fontsize=12, fontweight='bold')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Add statistical annotations\n",
    "for i, season in enumerate(['Winter', 'Spring', 'Summer', 'Autumn']):\n",
    "    season_data = extremes_df[extremes_df['season'] == season]['hs']\n",
    "    if len(season_data) > 0:\n",
    "        ax2.text(i+1, season_data.max() + 0.1, f'n={len(season_data)}', \n",
    "                ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# Plot 3: Time series with seasonal coloring\n",
    "ax3 = plt.subplot(3, 3, 3)\n",
    "scatter = ax3.scatter(extremes_df.index, extremes_df['hs'], \n",
    "                     c=extremes_df['month'], cmap='tab20', s=50, alpha=0.8, edgecolors='black')\n",
    "ax3.set_xlabel('Year')\n",
    "ax3.set_ylabel('Wave Height (m)')\n",
    "ax3.set_title('Extreme Wave Heights Over Time (Colored by Month)', fontsize=12, fontweight='bold')\n",
    "cbar = plt.colorbar(scatter, ax=ax3)\n",
    "cbar.set_label('Month')\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 4: Circular histogram (rose plot)\n",
    "ax4 = plt.subplot(3, 3, 4, projection='polar')\n",
    "monthly_counts_polar = monthly_counts.reindex(range(1, 13), fill_value=0)\n",
    "theta = np.linspace(0, 2*np.pi, 13)[:-1]  # 12 months\n",
    "width = 2*np.pi/12\n",
    "bars = ax4.bar(theta, monthly_counts_polar.values, width=width, alpha=0.7, \n",
    "               color=plt.cm.viridis(monthly_counts_polar.values / monthly_counts_polar.max()))\n",
    "ax4.set_theta_zero_location('N')  # January at top\n",
    "ax4.set_theta_direction(-1)  # Clockwise\n",
    "ax4.set_xticks(theta)\n",
    "ax4.set_xticklabels(months)\n",
    "ax4.set_title('Circular Distribution of Extremes\\n(Rose Plot)', fontsize=12, fontweight='bold', pad=20)\n",
    "\n",
    "# Add circular mean arrow\n",
    "ax4.arrow(circular_mean, monthly_counts_polar.max() * 0.8, 0, monthly_counts_polar.max() * 0.2, \n",
    "          head_width=0.2, head_length=0.1, fc='red', ec='red', linewidth=3)\n",
    "ax4.text(circular_mean + 0.3, monthly_counts_polar.max() * 0.9, 'Mean', \n",
    "         fontsize=10, fontweight='bold', color='red')\n",
    "\n",
    "# Plot 5: Monthly trend analysis with error bars\n",
    "ax5 = plt.subplot(3, 3, 5)\n",
    "ax5.errorbar(monthly_means.index, monthly_means.values, \n",
    "             yerr=monthly_std.values, fmt='o-', capsize=5, capthick=2,\n",
    "             linewidth=2, markersize=8, color='darkblue', alpha=0.8)\n",
    "ax5.fill_between(monthly_means.index, \n",
    "                 monthly_means.values - monthly_std.values,\n",
    "                 monthly_means.values + monthly_std.values,\n",
    "                 alpha=0.3, color='blue')\n",
    "ax5.set_xlabel('Month')\n",
    "ax5.set_ylabel('Mean Wave Height (m)')\n",
    "ax5.set_title('Monthly Mean Wave Heights with Error Bars', fontsize=12, fontweight='bold')\n",
    "ax5.set_xticks(range(1, 13))\n",
    "ax5.set_xticklabels(months)\n",
    "ax5.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 6: Seasonal intensity heatmap\n",
    "ax6 = plt.subplot(3, 3, 6)\n",
    "yearly_monthly_counts = extremes_df.groupby(['year', 'month']).size().unstack(fill_value=0)\n",
    "yearly_monthly_counts = yearly_monthly_counts.reindex(columns=range(1, 13), fill_value=0)\n",
    "\n",
    "im = ax6.imshow(yearly_monthly_counts.T, cmap='YlOrRd', aspect='auto', interpolation='nearest')\n",
    "ax6.set_xlabel('Year')\n",
    "ax6.set_ylabel('Month')\n",
    "ax6.set_title('Extreme Events Heatmap\\n(Year vs Month)', fontsize=12, fontweight='bold')\n",
    "ax6.set_yticks(range(12))\n",
    "ax6.set_yticklabels(months)\n",
    "ax6.set_xticks(range(0, len(yearly_monthly_counts), max(1, len(yearly_monthly_counts)//10)))\n",
    "ax6.set_xticklabels(yearly_monthly_counts.index[::max(1, len(yearly_monthly_counts)//10)])\n",
    "\n",
    "cbar = plt.colorbar(im, ax=ax6)\n",
    "cbar.set_label('Number of Extremes')\n",
    "\n",
    "# Plot 7: Monthly autocorrelation analysis\n",
    "ax7 = plt.subplot(3, 3, 7)\n",
    "monthly_series = extremes_df.groupby(extremes_df.index.to_period('M'))['hs'].max()\n",
    "monthly_series = monthly_series.reindex(pd.date_range(monthly_series.index[0].start_time, \n",
    "                                                      monthly_series.index[-1].end_time, \n",
    "                                                      freq='M'), fill_value=np.nan)\n",
    "\n",
    "lags = range(1, 13)  # 12 months\n",
    "autocorr = [monthly_series.autocorr(lag=lag) for lag in lags]\n",
    "\n",
    "ax7.bar(lags, autocorr, alpha=0.7, color='green', edgecolor='black')\n",
    "ax7.axhline(y=0, color='black', linestyle='-', alpha=0.5)\n",
    "ax7.axhline(y=0.2, color='red', linestyle='--', alpha=0.7, label='Significance threshold')\n",
    "ax7.axhline(y=-0.2, color='red', linestyle='--', alpha=0.7)\n",
    "ax7.set_xlabel('Lag (months)')\n",
    "ax7.set_ylabel('Autocorrelation')\n",
    "ax7.set_title('Monthly Autocorrelation of Extreme Heights', fontsize=12, fontweight='bold')\n",
    "ax7.legend()\n",
    "ax7.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 8: Seasonal statistics summary table\n",
    "ax8 = plt.subplot(3, 3, 8)\n",
    "ax8.axis('off')\n",
    "ax8.set_title('Seasonal Statistics Summary', fontsize=12, fontweight='bold', pad=20)\n",
    "\n",
    "seasonal_stats = extremes_df.groupby('season')['hs'].agg(['count', 'mean', 'std', 'min', 'max']).round(3)\n",
    "seasonal_stats = seasonal_stats.reindex(['Winter', 'Spring', 'Summer', 'Autumn'])\n",
    "\n",
    "table_data = []\n",
    "for season in ['Winter', 'Spring', 'Summer', 'Autumn']:\n",
    "    if season in seasonal_stats.index:\n",
    "        stats = seasonal_stats.loc[season]\n",
    "        table_data.append([\n",
    "            season,\n",
    "            f\"{stats['count']:.0f}\",\n",
    "            f\"{stats['mean']:.3f}\",\n",
    "            f\"{stats['std']:.3f}\",\n",
    "            f\"{stats['min']:.3f}\",\n",
    "            f\"{stats['max']:.3f}\"\n",
    "        ])\n",
    "\n",
    "table = ax8.table(cellText=table_data,\n",
    "                  colLabels=['Season', 'Count', 'Mean (m)', 'Std (m)', 'Min (m)', 'Max (m)'],\n",
    "                  cellLoc='center',\n",
    "                  loc='center',\n",
    "                  bbox=[0, 0, 1, 1])\n",
    "\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(9)\n",
    "table.scale(1, 1.5)\n",
    "\n",
    "# Style the table\n",
    "for i in range(len(table_data) + 1):\n",
    "    for j in range(6):\n",
    "        cell = table[(i, j)]\n",
    "        if i == 0:  # Header\n",
    "            cell.set_facecolor('#4CAF50')\n",
    "            cell.set_text_props(weight='bold', color='white')\n",
    "        else:\n",
    "            cell.set_facecolor('#f0f0f0' if i % 2 == 0 else 'white')\n",
    "\n",
    "# Plot 9: Density plot of extremes by season\n",
    "ax9 = plt.subplot(3, 3, 9)\n",
    "for i, season in enumerate(['Winter', 'Spring', 'Summer', 'Autumn']):\n",
    "    season_data = extremes_df[extremes_df['season'] == season]['hs']\n",
    "    if len(season_data) > 0:\n",
    "        x_range = np.linspace(extremes_df['hs'].min()*0.8, extremes_df['hs'].max()*1.2, 1000)\n",
    "        density = stats.gaussian_kde(season_data)\n",
    "        y_density = density(x_range)\n",
    "        ax9.plot(x_range, y_density, linewidth=2, label=f'{season} (n={len(season_data)})', alpha=0.8)\n",
    "\n",
    "ax9.set_xlabel('Wave Height (m)')\n",
    "ax9.set_ylabel('Density')\n",
    "ax9.set_title('Seasonal Density Distributions', fontsize=12, fontweight='bold')\n",
    "ax9.legend()\n",
    "ax9.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print comprehensive analysis results\n",
    "print(\"=\"*80)\n",
    "print(\"COMPREHENSIVE SEASONAL ANALYSIS OF EXTREME WAVE HEIGHTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\nDATA SUMMARY:\")\n",
    "print(f\"Total number of extremes: {len(extremes_df)}\")\n",
    "print(f\"Date range: {extremes_df.index.min().strftime('%Y-%m-%d')} to {extremes_df.index.max().strftime('%Y-%m-%d')}\")\n",
    "\n",
    "print(f\"\\nCIRCULAR STATISTICS:\")\n",
    "print(f\"Circular mean month: {months[int(circular_mean_month)-1]} (month {circular_mean_month:.1f})\")\n",
    "print(f\"Circular variance: {circular_variance:.4f}\")\n",
    "print(f\"Rayleigh test p-value: {rayleigh_p:.6f}\")\n",
    "if rayleigh_p < 0.05:\n",
    "    print(\"→ Significant seasonal clustering (p < 0.05)\")\n",
    "else:\n",
    "    print(\"→ No significant seasonal clustering (p ≥ 0.05)\")\n",
    "\n",
    "print(f\"\\nSEASONAL PATTERN SUMMARY:\")\n",
    "print(f\"Most extreme-prone month: {months[monthly_counts.idxmax()-1]} ({monthly_counts.max()} events)\")\n",
    "print(f\"Least extreme-prone month: {months[monthly_counts.idxmin()-1]} ({monthly_counts.min()} events)\")\n",
    "print(f\"Season with most extremes: {extremes_df['season'].value_counts().index[0]}\")\n",
    "print(f\"Season with highest mean: {extremes_df.groupby('season')['hs'].mean().idxmax()}\")\n",
    "print(f\"Circular concentration: {R:.3f} (1.0 = perfect clustering, 0.0 = uniform)\")\n",
    "\n",
    "print(f\"\\nDETAILED SEASONAL STATISTICS:\")\n",
    "for season in ['Winter', 'Spring', 'Summer', 'Autumn']:\n",
    "    season_data = extremes_df[extremes_df['season'] == season]['hs']\n",
    "    if len(season_data) > 0:\n",
    "        print(f\"\\n{season.upper()}:\")\n",
    "        print(f\"  Number of extremes: {len(season_data)}\")\n",
    "        print(f\"  Mean height: {season_data.mean():.3f} m\")\n",
    "        print(f\"  Standard deviation: {season_data.std():.3f} m\")\n",
    "        print(f\"  Minimum: {season_data.min():.3f} m\")\n",
    "        print(f\"  Maximum: {season_data.max():.3f} m\")\n",
    "        print(f\"  Percentage of total extremes: {len(season_data)/len(extremes_df)*100:.1f}%\")\n",
    "    else:\n",
    "        print(f\"\\n{season.upper()}: No extremes recorded\")\n",
    "\n",
    "# Calculate seasonal risk assessment\n",
    "winter_risk = len(extremes_df[extremes_df['season'] == 'Winter']) / len(extremes_df) * 100\n",
    "summer_risk = len(extremes_df[extremes_df['season'] == 'Summer']) / len(extremes_df) * 100\n",
    "spring_risk = len(extremes_df[extremes_df['season'] == 'Spring']) / len(extremes_df) * 100\n",
    "autumn_risk = len(extremes_df[extremes_df['season'] == 'Autumn']) / len(extremes_df) * 100\n",
    "\n",
    "print(f\"\\nRISK ASSESSMENT:\")\n",
    "print(f\"Winter risk: {winter_risk:.1f}% of all extremes\")\n",
    "print(f\"Spring risk: {spring_risk:.1f}% of all extremes\")\n",
    "print(f\"Summer risk: {summer_risk:.1f}% of all extremes\")\n",
    "print(f\"Autumn risk: {autumn_risk:.1f}% of all extremes\")\n",
    "\n",
    "if summer_risk > 0:\n",
    "    print(f\"Risk ratio (Winter/Summer): {winter_risk/summer_risk:.2f}\")\n",
    "if spring_risk > 0:\n",
    "    print(f\"Risk ratio (Winter/Spring): {winter_risk/spring_risk:.2f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ANALYSIS COMPLETE - All seasonal patterns extracted and visualized!\")\n",
    "print(\"=\"*80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55",
   "metadata": {},
   "source": [
    "After loading the data, apply the block method approach with a block size of 1 year (365.2425 days), where each data block must be at least 90% full to take into account in the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EVA(data.hs)\n",
    "model.get_extremes(method=\"BM\", block_size=\"365.2425D\", min_last_block=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.extremes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.plot_extremes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64",
   "metadata": {},
   "source": [
    "The parameter alpha specifies the confidence limits (default = 0.95)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.plot_diagnostic(alpha=0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66",
   "metadata": {},
   "source": [
    "The parameter n_samples indicates the number of bootstrap samples used to estimate the confidence bounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = model.get_summary(\n",
    "        return_period=[1, 2, 5, 10, 25, 50, 100, 250, 500, 1000],\n",
    "        alpha=0.95,\n",
    "        n_samples=1000,\n",
    "    )\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68",
   "metadata": {},
   "source": [
    "### Modelling univariate time series: Peaks over threshold (POT) + GPD (Generalized Pareto Distribution)\n",
    "\n",
    "We show as example here a **POT** (peaks over threshold) model fitted to the $H_s$ time series. This analysis first finds values over a specified threshold and then declusters these values using a predefined clustering distance, and finally finds the maximum value within each cluster. \n",
    "\n",
    "The same plot can readily be obtained for the other sea-state parameters.\n",
    "\n",
    "We first can have a look at the quality of the fitted model, and to the corresponding return levels as a function of the selected wave height threshold. The parameters r and alpha specify the minimum time distance (duration) between adjacent clusters and the confidence limits (default = 0.95), respectively.\n",
    "\n",
    "The shape and modified scale parameters define the Generalized Pareto Distribution, and they depend on the threshold value, but should be stable within a range of valid thresholds (e.g. less than ~3m here)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_parameter_stability(ts=data.hs,r='72H',alpha=.95);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70",
   "metadata": {},
   "source": [
    "The mean residual life plots the average excess value over a given threshold, and it should be approcimately linear above the threshold for which the GPD model is valid (e.g. <~3m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mean_residual_life(data.hs);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72",
   "metadata": {},
   "source": [
    "The analysis is completed for both Hs and the wind speed, specifying a window of 72 hours and a quantile of 0.98 for determining the threshold to specify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73",
   "metadata": {},
   "outputs": [],
   "source": [
    "quant=0.98\n",
    "models = get_fitted_models(data[[\"hs\",\"wspd\"]],quantile=quant,r=\"72H\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74",
   "metadata": {},
   "outputs": [],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75",
   "metadata": {},
   "outputs": [],
   "source": [
    "models[0].plot_diagnostic(alpha=0.95);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76",
   "metadata": {},
   "outputs": [],
   "source": [
    "models[1].plot_diagnostic(alpha=0.95);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(get_gpd_parameters(models),columns=[\"mu\",\"sigma\",\"xi\"],index=[\"Hs\",\"Wspd\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_Hs = models[0].get_summary(\n",
    "    return_period=[1, 2, 5, 10, 25, 50, 100],\n",
    "    alpha=0.95,\n",
    "    n_samples=1000,\n",
    ")\n",
    "summary_Wspd = models[1].get_summary(\n",
    "    return_period=[1, 2, 5, 10, 25, 50, 100],\n",
    "    alpha=0.95,\n",
    "    n_samples=1000,\n",
    ")\n",
    "print(summary_Hs)\n",
    "print(summary_Wspd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
